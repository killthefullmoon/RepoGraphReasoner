{
  "tasks": [
    {
      "task_title": "åˆ—å‡ºå¯ç”¨çš„TTSæ¨¡å‹",
      "task_description": "ä½¿ç”¨TTS APIåˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ã€‚",
      "example_code": "print(TTS().list_models())",
      "running_command": null,
      "expected_input": null,
      "expected_output": "å¯ç”¨æ¨¡å‹åˆ—è¡¨"
    },
    {
      "task_title": "æ–‡æœ¬è½¬è¯­éŸ³",
      "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼Œå¹¶è¾“å‡ºä¸ºéŸ³é¢‘æ³¢å½¢æ•°æ®ã€‚",
      "example_code": "wav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")",
      "running_command": null,
      "expected_input": "Hello world!",
      "expected_output": "éŸ³é¢‘æ³¢å½¢æ•°æ®"
    },
    {
      "task_title": "æ–‡æœ¬è½¬è¯­éŸ³å¹¶ä¿å­˜åˆ°æ–‡ä»¶",
      "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ°æŒ‡å®šçš„éŸ³é¢‘æ–‡ä»¶ä¸­ã€‚",
      "example_code": "tts.tts_to_file(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": "Hello world!",
      "expected_output": "ä¿å­˜åˆ°output.wavçš„éŸ³é¢‘æ–‡ä»¶"
    },
    {
      "task_title": "ä½¿ç”¨ç‰¹å®šæ¨¡å‹è¿›è¡Œæ–‡æœ¬è½¬è¯­éŸ³",
      "task_description": "ä½¿ç”¨æŒ‡å®šçš„TTSæ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜åˆ°æ–‡ä»¶ã€‚",
      "example_code": "tts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False).to(device)\ntts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)",
      "running_command": null,
      "expected_input": "Ich bin eine Testnachricht.",
      "expected_output": "ä¿å­˜åˆ°OUTPUT_PATHçš„éŸ³é¢‘æ–‡ä»¶"
    },
    {
      "task_title": "å¤šè¯­è¨€è¯­éŸ³å…‹éš†",
      "task_description": "ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹è¿›è¡Œè¯­éŸ³å…‹éš†ï¼Œå°†ä¸åŒè¯­è¨€çš„æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜åˆ°æ–‡ä»¶ã€‚",
      "example_code": "tts.tts_to_file(\"This is voice cloning.\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")\ntts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")\ntts.tts_to_file(\"Isso Ã© clonagem de voz.\", speaker_wav=\"my/cloning/audio.wav\", language=\"pt-br\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": [
        "This is voice cloning.",
        "C'est le clonage de la voix.",
        "Isso Ã© clonagem de voz."
      ],
      "expected_output": "ä¿å­˜åˆ°output.wavçš„éŸ³é¢‘æ–‡ä»¶"
    },
    {
      "task_title": "è¯­éŸ³è½¬æ¢",
      "task_description": "å°†æºéŸ³é¢‘è½¬æ¢ä¸ºç›®æ ‡éŸ³é¢‘ï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šçš„æ–‡ä»¶ä¸­ã€‚",
      "example_code": "tts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": "my/source.wav, my/target.wav",
      "expected_output": "ä¿å­˜åˆ°output.wavçš„éŸ³é¢‘æ–‡ä»¶"
    },
    {
      "task_title": "å¸¦æœ‰è¯­éŸ³è½¬æ¢çš„æ–‡æœ¬è½¬è¯­éŸ³",
      "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼ŒåŒæ—¶åº”ç”¨è¯­éŸ³è½¬æ¢ï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶ã€‚",
      "example_code": "tts.tts_with_vc_to_file(\"Wie sage ich auf Italienisch, dass ich dich liebe?\", speaker_wav=\"target/speaker.wav\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": "Wie sage ich auf Italienisch, dass ich dich liebe?",
      "expected_output": "ä¿å­˜åˆ°output.wavçš„éŸ³é¢‘æ–‡ä»¶"
    }
  ],
  "setup": {
    "setup_commands": [
      "pip install TTS",
      "git clone https://github.com/coqui-ai/TTS\npip install -e .[all,dev,notebooks]  # Select the relevant extras"
    ],
    "docker_commands": [
      "docker run --rm -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu\npython3 TTS/server/server.py --list_models #To get the list of available models\npython3 TTS/server/server.py --model_name tts_models/en/vctk/vits # To start a server"
    ],
    "docker_files": {
      "Dockerfile": "ARG BASE=nvidia/cuda:11.8.0-base-ubuntu22.04\nFROM ${BASE}\n\nRUN apt-get update && apt-get upgrade -y\nRUN apt-get install -y --no-install-recommends gcc g++ make python3 python3-dev python3-pip python3-venv python3-wheel espeak-ng libsndfile1-dev && rm -rf /var/lib/apt/lists/*\nRUN pip3 install llvmlite --ignore-installed\n\n# Install Dependencies:\nRUN pip3 install torch torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\nRUN rm -rf /root/.cache/pip\n\n# Copy TTS repository contents:\nWORKDIR /root\nCOPY . /root\n\nRUN make install\n\nENTRYPOINT [\"tts\"]\nCMD [\"--help\"]\n",
      ".dockerignore": ".git/\nDockerfile\nbuild/\ndist/\nTTS.egg-info/\ntests/outputs/*\ntests/train_outputs/*\n__pycache__/\n*.pyc"
    },
    "docker_setup_descriptions": {
      "Dockerfile": "### Building and Running Docker for Coqui-AI TTS\n\nTo build and run the Docker container using the provided `Dockerfile` from the `coqui-ai/TTS` repository, follow these steps:\n\n#### 1. **Understanding the Dockerfile**\n\n- **Base Image**: The Dockerfile starts with an ARG directive that sets the base image to `nvidia/cuda:11.8.0-base-ubuntu22.04`, which is suitable for GPU-accelerated applications.\n  \n- **System Updates and Dependencies**: It updates the package lists and installs essential build tools (`gcc`, `g++`, `make`) and Python-related packages (`python3`, `python3-dev`, `python3-pip`, etc.) necessary for running the TTS application. It also installs `espeak-ng` and `libsndfile1-dev`, which are required for audio processing.\n\n- **Python Package Installation**: The Dockerfile installs `torch` and `torchaudio` from the PyTorch repository with CUDA support, followed by cleaning up the pip cache to reduce image size.\n\n- **Copying Application Code**: It sets the working directory to `/root` and copies the contents of the current directory into the container.\n\n- **Installation Command**: The `make install` command is executed to install the TTS application.\n\n- **Entrypoint and Command**: The container is configured to run the `tts` command by default, with `--help` as the default argument, allowing users to see available options when the container starts.\n\n#### 2. **Building the Docker Image**\n\nRun the following command in the terminal from the directory containing the `Dockerfile`:\n\n```bash\ndocker build -t coqui-tts .\n```\n\nThis command builds the Docker image and tags it as `coqui-tts`.\n\n#### 3. **Running the Docker Container**\n\nTo run the container interactively and access the TTS server, use:\n\n```bash\ndocker run --rm -it -p 5002:5002 coqui-tts\n```\n\nThis command starts the container, removes it after exit (`--rm`), and maps port 5002 from the container to the host, allowing access to the TTS server.\n\n#### 4. **Starting the TTS Server**\n\nOnce inside the container, you can list available models with:\n\n```bash\npython3 TTS/server/server.py --list_models\n```\n\nTo start the TTS server with a specific model, use:\n\n```bash\npython3 TTS/server/server.py --model_name tts_models/en/vctk/vits\n```\n\nThis command initializes the TTS server using the specified model.\n\n### Summary\n\nBy following these steps, you can successfully build and run the Coqui-AI TTS Docker container, allowing you to utilize the text-to-speech capabilities provided by the application.",
      ".dockerignore": "### Building and Running Docker with `.dockerignore` in Coqui-AI/TTS\n\n#### Overview of `.dockerignore`\nThe `.dockerignore` file is used to specify which files and directories should be excluded from the Docker build context. This helps to reduce the size of the context sent to the Docker daemon, improving build performance and security by preventing unnecessary files from being included in the Docker image.\n\n#### Contents of `.dockerignore`\nThe provided `.dockerignore` file includes the following entries:\n\n- **`.git/`**: Excludes the entire Git repository, preventing version control files from being included.\n- **`Dockerfile`**: Excludes the Dockerfile itself from the build context.\n- **`build/`**: Excludes the build directory, which may contain compiled artifacts.\n- **`dist/`**: Excludes the distribution directory, typically used for packaged releases.\n- **`TTS.egg-info/`**: Excludes metadata files generated by Python package installations.\n- **`tests/outputs/*`**: Excludes all output files from the tests directory.\n- **`tests/train_outputs/*`**: Excludes all training output files from the tests directory.\n- **`__pycache__/`**: Excludes Python cache files, which are not needed for the build.\n- **`*.pyc`**: Excludes all compiled Python files.\n\n#### Actionable Steps to Build and Run Docker\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/coqui-ai/TTS.git\n   cd TTS\n   ```\n\n2. **Build the Docker Image**:\n   Use the following command to build the Docker image, ensuring you are in the root directory of the cloned repository:\n   ```bash\n   docker build -t coqui-tts .\n   ```\n\n3. **Run the Docker Container**:\n   Execute the following command to run the Docker container interactively, mapping port 5002:\n   ```bash\n   docker run --rm -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu\n   ```\n\n4. **List Available Models**:\n   Inside the running container, use the following command to list available models:\n   ```bash\n   python3 TTS/server/server.py --list_models\n   ```\n\n5. **Start the TTS Server**:\n   To start the TTS server with a specific model, run:\n   ```bash\n   python3 TTS/server/server.py --model_name tts_models/en/vctk/vits\n   ```\n\nBy following these steps, you will successfully build and run the Docker container for the Coqui-AI TTS project while adhering to the exclusions specified in the `.dockerignore` file."
    }
  },
  "input_to_gpt": {
    "repo_name": "coqui-ai/TTS",
    "num_code_blocks": 6,
    "total_length": 2187,
    "code_blocks": [
      "$ make system-deps  # intended to be used on Ubuntu (Debian). Let us know if you have a different OS.\n$ make install",
      "import torch\nfrom TTS.api import TTS\n\n# Get device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# List available ğŸ¸TTS models\nprint(TTS().list_models())\n\n# Init TTS\ntts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n\n# Run TTS\n# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\n# Text to speech list of amplitude values as output\nwav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")\n# Text to speech to a file\ntts.tts_to_file(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")",
      "# Init TTS with the target model name\ntts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False).to(device)\n\n# Run TTS\ntts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)\n\n# Example voice cloning with YourTTS in English, French and Portuguese\ntts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=False).to(device)\ntts.tts_to_file(\"This is voice cloning.\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")\ntts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")\ntts.tts_to_file(\"Isso Ã© clonagem de voz.\", speaker_wav=\"my/cloning/audio.wav\", language=\"pt-br\", file_path=\"output.wav\")",
      "tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False).to(\"cuda\")\ntts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")",
      "\ntts = TTS(\"tts_models/de/thorsten/tacotron2-DDC\")\ntts.tts_with_vc_to_file(\n    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n    speaker_wav=\"target/speaker.wav\",\n    file_path=\"output.wav\"\n)",
      "# TTS with on the fly voice conversion\napi = TTS(\"tts_models/deu/fairseq/vits\")\napi.tts_with_vc_to_file(\n    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n    speaker_wav=\"target/speaker.wav\",\n    file_path=\"output.wav\"\n)"
    ]
  }
}