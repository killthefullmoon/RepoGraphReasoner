{
  "tasks": [
    {
      "task_title": "Transcribe audio file",
      "task_description": "使用模型'turbo'将音频文件转换为文本。",
      "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\nresult = model.transcribe(\"audio.mp3\")\nprint(result[\"text\"])",
      "running_command": null,
      "expected_input": "audio.mp3",
      "expected_output": "Transcribed text from audio"
    },
    {
      "task_title": "Detect language from audio",
      "task_description": "加载音频文件并检测其中的语言。",
      "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\naudio = whisper.load_audio(\"audio.mp3\")\naudio = whisper.pad_or_trim(audio)\nmel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")",
      "running_command": null,
      "expected_input": "audio.mp3",
      "expected_output": "Detected language: <language>"
    },
    {
      "task_title": "Translate audio to text",
      "task_description": "使用模型'medium'将音频文件翻译为文本，指定语言为Japanese。",
      "example_code": null,
      "running_command": "whisper japanese.wav --model medium --language Japanese --task translate",
      "expected_input": "japanese.wav",
      "expected_output": "Translated text from audio"
    },
    {
      "task_title": "Convert audio formats",
      "task_description": "将音频文件从一种格式转换为另一种格式，使用模型'turbo'。",
      "example_code": null,
      "running_command": "whisper audio.flac audio.mp3 audio.wav --model turbo",
      "expected_input": "audio.flac, audio.mp3, audio.wav",
      "expected_output": "Converted audio formats"
    },
    {
      "task_title": "Display help information",
      "task_description": "显示whisper命令行工具的帮助信息。",
      "example_code": null,
      "running_command": "whisper --help",
      "expected_input": null,
      "expected_output": "Help information for whisper command"
    }
  ],
  "setup": {
    "setup_commands": [
      "# on Ubuntu or Debian\nsudo apt update && sudo apt install ffmpeg\n\n# on Arch Linux\nsudo pacman -S ffmpeg\n\n# on MacOS using Homebrew (https://brew.sh/)\nbrew install ffmpeg\n\n# on Windows using Chocolatey (https://chocolatey.org/)\nchoco install ffmpeg\n\n# on Windows using Scoop (https://scoop.sh/)\nscoop install ffmpeg",
      "pip install setuptools-rust"
    ],
    "docker_commands": [],
    "docker_files": {}
  },
  "input_to_gpt": {
    "repo_name": "openai/whisper",
    "num_code_blocks": 6,
    "total_length": 926,
    "code_blocks": [
      "whisper audio.flac audio.mp3 audio.wav --model turbo",
      "whisper japanese.wav --language Japanese",
      "whisper japanese.wav --model medium --language Japanese --task translate",
      "whisper --help",
      "import whisper\n\nmodel = whisper.load_model(\"turbo\")\nresult = model.transcribe(\"audio.mp3\")\nprint(result[\"text\"])",
      "import whisper\n\nmodel = whisper.load_model(\"turbo\")\n\n# load audio and pad/trim it to fit 30 seconds\naudio = whisper.load_audio(\"audio.mp3\")\naudio = whisper.pad_or_trim(audio)\n\n# make log-Mel spectrogram and move to the same device as the model\nmel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n\n# detect the spoken language\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")\n\n# decode the audio\noptions = whisper.DecodingOptions()\nresult = whisper.decode(model, mel, options)\n\n# print the recognized text\nprint(result.text)"
    ]
  }
}