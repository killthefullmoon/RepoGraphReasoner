{
  "tasks": [
    {
      "task_title": "Build for ROCm",
      "task_description": "Compile the PyTorch library specifically for the ROCm platform.",
      "example_code": null,
      "running_command": "python tools/amd_build/build_amd.py",
      "expected_input": null,
      "expected_output": null
    },
    {
      "task_title": "Build Docker Images",
      "task_description": "Build Docker images for PyTorch using the provided Makefile.",
      "example_code": null,
      "running_command": "make -f docker.Makefile",
      "expected_input": null,
      "expected_output": "images are tagged as docker.io/${your_docker_username}/pytorch"
    },
    {
      "task_title": "Build Docker Images Again",
      "task_description": "Another command to build Docker images for PyTorch using the Makefile.",
      "example_code": null,
      "running_command": "make -f docker.Makefile",
      "expected_input": null,
      "expected_output": null
    },
    {
      "task_title": "Generate LaTeX PDF",
      "task_description": "Generate a PDF document from LaTeX files for PyTorch documentation.",
      "example_code": null,
      "running_command": "make latexpdf",
      "expected_input": null,
      "expected_output": null
    },
    {
      "task_title": "Generate LaTeX PDF with Nonstop Mode",
      "task_description": "Generate a PDF document from LaTeX files with nonstop mode enabled.",
      "example_code": null,
      "running_command": "make LATEXOPTS=\"-interaction=nonstopmode\"",
      "expected_input": null,
      "expected_output": null
    }
  ],
  "setup": {
    "setup_commands": [
      "$ source <CONDA_INSTALL_DIR>/bin/activate\n$ conda create -y -n <CONDA_NAME>\n$ conda activate <CONDA_NAME>",
      "$ source <CONDA_INSTALL_DIR>\\Scripts\\activate.bat\n$ conda create -y -n <CONDA_NAME>\n$ conda activate <CONDA_NAME>\n$ call \"C:\\Program Files\\Microsoft Visual Studio\\<VERSION>\\Community\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64",
      "git clone https://github.com/pytorch/pytorch\ncd pytorch\n# if you are updating an existing checkout\ngit submodule sync\ngit submodule update --init --recursive",
      "# Run this command from the PyTorch directory after cloning the source code using the “Get the PyTorch Source“ section above\npip install --group dev",
      "pip install mkl-static mkl-include\n# CUDA only: Add LAPACK support for the GPU if needed\n# magma installation: run with active conda environment. specify CUDA version to install\n.ci/docker/common/install_magma_conda.sh 12.4\n\n# (optional) If using torch.compile with inductor/triton, install the matching version of triton\n# Run from the pytorch directory after cloning\n# For Intel GPU support, please explicitly `export USE_XPU=1` before running command.\nmake triton",
      "# Add this package on intel x86 processor machines only\npip install mkl-static mkl-include\n# Add these packages if torch.distributed is needed\nconda install pkg-config libuv",
      "pip install mkl-static mkl-include\n# Add these packages if torch.distributed is needed.\n# Distributed package support on Windows is a prototype feature and is subject to changes.\nconda install -c conda-forge libuv=1.51",
      "export CMAKE_PREFIX_PATH=\"${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}\"\npython -m pip install --no-build-isolation -v -e .",
      "python -m pip install --no-build-isolation -v -e .",
      "python -m pip install --no-build-isolation -v -e .",
      "cmd\n\n:: Set the environment variables after you have downloaded and unzipped the mkl package,\n:: else CMake would throw an error as `Could NOT find OpenMP`.\nset CMAKE_INCLUDE_PATH={Your directory}\\mkl\\include\nset LIB={Your directory}\\mkl\\lib;%LIB%\n\n:: Read the content in the previous section carefully before you proceed.\n:: [Optional] If you want to override the underlying toolset used by Ninja and Visual Studio with CUDA, please run the following script block.\n:: \"Visual Studio 2019 Developer Command Prompt\" will be run automatically.\n:: Make sure you have CMake >= 3.12 before you do this when you use the Visual Studio generator.\nset CMAKE_GENERATOR_TOOLSET_VERSION=14.27\nset DISTUTILS_USE_SDK=1\nfor /f \"usebackq tokens=*\" %i in (`\"%ProgramFiles(x86)%\\Microsoft Visual Studio\\Installer\\vswhere.exe\" -version [15^,17^) -products * -latest -property installationPath`) do call \"%i\\VC\\Auxiliary\\Build\\vcvarsall.bat\" x64 -vcvars_ver=%CMAKE_GENERATOR_TOOLSET_VERSION%\n\n:: [Optional] If you want to override the CUDA host compiler\nset CUDAHOSTCXX=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.27.29110\\bin\\HostX64\\x64\\cl.exe\n\npython -m pip install --no-build-isolation -v -e .",
      ":: CMD Commands:\n:: Set the CMAKE_PREFIX_PATH to help find corresponding packages\n:: %CONDA_PREFIX% only works after `conda activate custom_env`\n\nif defined CMAKE_PREFIX_PATH (\n    set \"CMAKE_PREFIX_PATH=%CONDA_PREFIX%\\Library;%CMAKE_PREFIX_PATH%\"\n) else (\n    set \"CMAKE_PREFIX_PATH=%CONDA_PREFIX%\\Library\"\n)\n\npython -m pip install --no-build-isolation -v -e .",
      "export CMAKE_PREFIX_PATH=\"${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}\"\nCMAKE_ONLY=1 python setup.py build\nccmake build  # or cmake-gui build",
      "export CMAKE_PREFIX_PATH=\"${CONDA_PREFIX:-'$(dirname $(which conda))/../'}:${CMAKE_PREFIX_PATH}\"\nMACOSX_DEPLOYMENT_TARGET=11.0 CMAKE_ONLY=1 python setup.py build\nccmake build  # or cmake-gui build",
      "cd docs/\npip install -r requirements.txt\nmake html\nmake serve",
      "brew install --cask mactex"
    ],
    "docker_commands": [
      "docker run --gpus all --rm -ti --ipc=host pytorch/pytorch:latest"
    ],
    "docker_files": {
      "Dockerfile": "# syntax=docker/dockerfile:1\n\n# NOTE: Building this image require's docker version >= 23.0.\n#\n# For reference:\n# - https://docs.docker.com/build/dockerfile/frontend/#stable-channel\n\nARG BASE_IMAGE=ubuntu:22.04\nARG PYTHON_VERSION=3.11\n\nFROM ${BASE_IMAGE} as dev-base\nRUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n        build-essential \\\n        ca-certificates \\\n        ccache \\\n        cmake \\\n        curl \\\n        git \\\n        libjpeg-dev \\\n        libpng-dev && \\\n    rm -rf /var/lib/apt/lists/*\nRUN /usr/sbin/update-ccache-symlinks\nRUN mkdir /opt/ccache && ccache --set-config=cache_dir=/opt/ccache\nENV PATH /opt/conda/bin:$PATH\n\nFROM dev-base as conda\nARG PYTHON_VERSION=3.11\n# Automatically set by buildx\nARG TARGETPLATFORM\n# translating Docker's TARGETPLATFORM into miniconda arches\nRUN case ${TARGETPLATFORM} in \\\n         \"linux/arm64\")  MINICONDA_ARCH=aarch64  ;; \\\n         *)              MINICONDA_ARCH=x86_64   ;; \\\n    esac && \\\n    curl -fsSL -v -o ~/miniconda.sh -O  \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-${MINICONDA_ARCH}.sh\"\nCOPY requirements.txt requirements-build.txt .\n# Manually invoke bash on miniconda script per https://github.com/conda/conda/issues/10431\nRUN chmod +x ~/miniconda.sh && \\\n    bash ~/miniconda.sh -b -p /opt/conda && \\\n    rm ~/miniconda.sh && \\\n    /opt/conda/bin/conda install -y python=${PYTHON_VERSION} cmake conda-build pyyaml numpy ipython && \\\n    /opt/conda/bin/python -mpip install -r requirements.txt && \\\n    /opt/conda/bin/conda clean -ya\n\nFROM dev-base as submodule-update\nWORKDIR /opt/pytorch\nCOPY . .\nRUN git submodule update --init --recursive\n\nFROM conda as conda-installs\nARG PYTHON_VERSION=3.11\nARG CUDA_PATH=cu121\nARG INSTALL_CHANNEL=whl/nightly\n# Automatically set by buildx\n# pinning version of conda here see: https://github.com/pytorch/pytorch/issues/164574\nRUN /opt/conda/bin/conda install -y python=${PYTHON_VERSION} conda=25.7.0\n\nARG TARGETPLATFORM\n\n# INSTALL_CHANNEL whl - release, whl/nightly - nightly, whl/test - test channels\nRUN case ${TARGETPLATFORM} in \\\n         \"linux/arm64\")  pip install --extra-index-url https://download.pytorch.org/whl/cpu/ torch torchvision torchaudio ;; \\\n         *)              pip install --index-url https://download.pytorch.org/${INSTALL_CHANNEL}/${CUDA_PATH#.}/ torch torchvision torchaudio ;; \\\n    esac && \\\n    /opt/conda/bin/conda clean -ya\nRUN /opt/conda/bin/pip install torchelastic\nRUN IS_CUDA=$(python -c 'import torch ; print(torch.cuda._is_compiled())'); \\\n    echo \"Is torch compiled with cuda: ${IS_CUDA}\"; \\\n    if test \"${IS_CUDA}\" != \"True\" -a ! -z \"${CUDA_VERSION}\"; then \\\n        exit 1; \\\n    fi\n\nFROM ${BASE_IMAGE} as official\nARG PYTORCH_VERSION\nARG TRITON_VERSION\nARG TARGETPLATFORM\nARG CUDA_VERSION\nLABEL com.nvidia.volumes.needed=\"nvidia_driver\"\nRUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends \\\n        ca-certificates \\\n        libjpeg-dev \\\n        libpng-dev \\\n        && rm -rf /var/lib/apt/lists/*\nCOPY --from=conda-installs /opt/conda /opt/conda\nRUN if test -n \"${TRITON_VERSION}\" -a \"${TARGETPLATFORM}\" != \"linux/arm64\"; then \\\n        DEBIAN_FRONTEND=noninteractive apt install -y --no-install-recommends gcc; \\\n        rm -rf /var/lib/apt/lists/*; \\\n    fi\nENV PATH /opt/conda/bin:$PATH\nENV NVIDIA_VISIBLE_DEVICES all\nENV NVIDIA_DRIVER_CAPABILITIES compute,utility\nENV LD_LIBRARY_PATH /usr/local/nvidia/lib:/usr/local/nvidia/lib64\nENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:$PATH\nENV PYTORCH_VERSION ${PYTORCH_VERSION}\nWORKDIR /workspace\n\nFROM official as dev\n# Should override the already installed version from the official-image stage\nCOPY --from=conda /opt/conda /opt/conda\nCOPY --from=submodule-update /opt/pytorch /opt/pytorch\n",
      ".dockerignore": "# READ THIS BEFORE YOU REFACTOR ME\n#\n# setup.py uses the list of patterns in this file to decide\n# what to delete, but it's not 100% sound.  So, for example,\n# if you delete aten/build/ because it's redundant with build/,\n# aten/build/ will stop being cleaned.  So be careful when\n# refactoring this file!\n\n## PyTorch\n\n.coverage\ncoverage.xml\n.dmypy.json\n.gradle\n.hypothesis\n.mypy_cache\n.additional_ci_files\n.lintrunner.private.toml\n/.extracted_scripts/\n**/.pytorch_specified_test_cases.csv\n**/.pytorch-disabled-tests.json\n*/*.pyc\n*/*.so*\n*/**/__pycache__\n*/**/*.dylib*\n*/**/*.pyc\n*/**/*.pyd\n*/**/*.so*\n*/**/**/*.pyc\n*/**/**/**/*.pyc\n*/**/**/**/**/*.pyc\naten/build/\naten/src/ATen/Config.h\naten/src/ATen/cuda/CUDAConfig.h\naten/src/ATen/hip/HIPConfig.h\nbenchmarks/.data\ncaffe2/cpp_test/\ndist/\ndocs/build/\ndocs/cpp/src\ndocs/src/**/*\ndocs/cpp/build\ndocs/cpp/source/api\ndocs/cpp/source/html/\ndocs/cpp/source/latex/\ndocs/source/compile/generated/\ndocs/source/generated/\ndocs/source/compile/generated/\nlog\nusage_log.txt\nusage_log*\ntest-reports/\ntest/*.bak\ntest/**/*.bak\ntest/.coverage\ntest/.hypothesis/\ntest/cpp/api/mnist\ntest/custom_operator/model.pt\ntest/debug/\ntest/jit_hooks/*.pt\ntest/data/legacy_modules.t7\ntest/data/*.pt\ntest/forward_backward_compatibility/nightly_schemas.txt\ndropout_model.pt\ntest/generated_type_hints_smoketest.py\ntest/htmlcov\ntest/cpp_extensions/**/install\ntest/kernel.errors.txt\nthird_party/build/\nthird_party/nccl/\ntools/coverage_plugins_package/pip-wheel-metadata/\ntools/shared/_utils_internal.py\ntools/fast_nvcc/wrap_nvcc.sh\ntools/fast_nvcc/wrap_nvcc.bat\ntools/fast_nvcc/tmp/\ntorch.egg-info/\ntorch/_C/__init__.pyi\ntorch/_C/_nn.pyi\ntorch/_C/_VariableFunctions.pyi\ntorch/_VF.pyi\ntorch/return_types.pyi\ntorch/nn/functional.pyi\ntorch/utils/data/datapipes/datapipe.pyi\ntorch/csrc/autograd/generated/*\ntorch/csrc/functionalization/generated/*\ntorch/csrc/lazy/generated/*.[!m]*\ntorch_compile_debug/\n# Listed manually because some files in this directory are not generated\ntorch/testing/_internal/generated/annotated_fn_args.py\ntorch/testing/_internal/data/*.pt\ntorch/headeronly/version.h\ntorch/csrc/cudnn/cuDNN.cpp\ntorch/csrc/generated\ntorch/csrc/generic/TensorMethods.cpp\ntorch/csrc/inductor/aoti_torch/generated/*.cpp\ntorch/csrc/inductor/aoti_torch/generated/extend/*\ntorch/csrc/jit/generated/*\ntorch/csrc/jit/fuser/config.h\ntorch/csrc/nn/THCUNN.cpp\ntorch/csrc/nn/THCUNN.cwrap\ntorch/bin/\ntorch/cmake/\ntorch/lib/*.a*\ntorch/lib/*.dll*\ntorch/lib/*.exe*\ntorch/lib/*.dylib*\ntorch/lib/*.h\ntorch/lib/*.lib\ntorch/lib/*.pdb\ntorch/lib/*.so*\ntorch/lib/protobuf*.pc\ntorch/lib/build\ntorch/lib/caffe2/\ntorch/lib/cmake\ntorch/lib/include\ntorch/lib/pkgconfig\ntorch/lib/protoc\ntorch/lib/protobuf/\ntorch/lib/tmp_install\ntorch/lib/torch_shm_manager\ntorch/lib/site-packages/\ntorch/lib/python*\ntorch/lib64\ntorch/include/\ntorch/share/\ntorch/test/\ntorch/utils/benchmark/utils/valgrind_wrapper/callgrind.h\ntorch/utils/benchmark/utils/valgrind_wrapper/valgrind.h\ntorch/version.py\nminifier_launcher.py\naten/src/ATen/native/transformers/hip/flash_attn/ck/fmha_fwd_d*\naten/src/ATen/native/transformers/hip/flash_attn/ck/fmha_bwd_d*\naten/src/ATen/native/transformers/hip/flash_attn/ck/fmha_bwd_convert*\naten/src/ATen/native/transformers/hip/flash_attn/ck/fwd_blob*\naten/src/ATen/native/transformers/hip/flash_attn/ck/bwd_blob*\naten/src/ATen/native/transformers/hip/flash_attn/ck/fmha_fwd_api*\naten/src/ATen/native/transformers/hip/flash_attn/ck/fmha_bwd_api*\n# Root level file used in CI to specify certain env configs.\n# E.g., see .circleci/config.yaml\nenv\n.circleci/scripts/COMMIT_MSG\nscripts/release_notes/*.json\nsccache-stats*.json\nlint.json\nmerge_record.json\n\n# These files get copied over on invoking setup.py\ntorchgen/packaged/*\n!torchgen/packaged/README.md\n\n# This file is injected by ROCm build scripts to bootstrap in torch/__init__.py.\ntorch/_rocm_init.py\n\n# IPython notebook checkpoints\n.ipynb_checkpoints\n\n# Editor temporaries\n*.swa\n*.swb\n*.swc\n*.swd\n*.swe\n*.swf\n*.swg\n*.swh\n*.swi\n*.swj\n*.swk\n*.swl\n*.swm\n*.swn\n*.swo\n*.swp\n*~\n.~lock.*\n\n# macOS dir files\n.DS_Store\n\n# Ninja files\n.ninja_deps\n.ninja_log\ncompile_commands.json\n*.egg-info/\ndocs/source/scripts/activation_images/\ndocs/source/scripts/quantization_backend_configs/\ndocs/source/scripts/lr_scheduler_images/\n\n## General\n\n# Compiled Object files\n*.slo\n*.lo\n*.o\n*.cuo\n*.obj\n\n# Compiled Dynamic libraries\n*.so\n*.dylib\n*.dll\n\n# Compiled Static libraries\n*.lai\n*.la\n*.a\n*.lib\n\n# Compiled protocol buffers\n*.pb.h\n*.pb.cc\n*_pb2.py\n\n# Compiled python\n*.pyc\n*.pyd\n\n# Compiled MATLAB\n*.mex*\n\n# NFS handle files\n**/.nfs*\n\n# Sublime Text settings\n*.sublime-workspace\n*.sublime-project\n\n# Eclipse Project settings\n*.*project\n.settings\n\n# QtCreator files\n*.user\n\n# PyCharm files\n.idea\n\n# GDB history\n.gdb_history\n\n## Caffe2\n\n# build, distribute, and bins (+ python proto bindings)\nbuild/\n# Allow tools/build/ for build support.\n!tools/build/\nbuild_host_protoc\nbuild_android\nbuild_ios\n.build_debug/*\n.build_release/*\n.build_profile/*\ndistribute/*\n*.testbin\n*.bin\ncmake_build\n.cmake_build\ngen\n.setuptools-cmake-build\n.pytest_cache\naten/build/*\n\n# Linker scripts for prioritized text optimization\ncmake/linker_script.ld\n\n# Bram\nplsdontbreak\n\n# Generated documentation\ndocs/_site\ndocs/gathered\n_site\ndoxygen\ndocs/dev\n\n# LevelDB files\n*.sst\n*.ldb\nLOCK\nCURRENT\nMANIFEST-*\n\n# generated version file\ncaffe2/version.py\n\n# setup.py intermediates\n.eggs\ncaffe2.egg-info\nMANIFEST\n\n# Atom/Watchman required file\n.watchmanconfig\n.watchman\n\n# Files generated by CLion\ncmake-build-debug\n\n# BEGIN NOT-CLEAN-FILES (setup.py handles this marker. Do not change.)\n#\n# Below files are not deleted by \"setup.py clean\".\n\n# Downloaded bazel\ntools/bazel\n\n# Visual Studio Code files\n.vs\n/.vscode/*\n!/.vscode/extensions.json\n!/.vscode/settings_recommended.json\n\n# YouCompleteMe config file\n.ycm_extra_conf.py\n\n# Files generated when a patch is rejected\n*.orig\n*.rej\n\n# Files generated by ctags\nCTAGS\nGTAGS\nGRTAGS\nGSYMS\nGPATH\ntags\nTAGS\n\n\n# ccls file\n.ccls-cache/\n\n# clang tooling storage location\n.clang-format-bin\n.clang-tidy-bin\n.lintbin\n\n# clangd background index\n.clangd/\n.cache/\n\n# bazel symlinks\nbazel-*\n\n# xla repo\nxla/\n\n# direnv, posh-direnv\n.env\n.envrc\n.psenvrc\n\n# generated shellcheck directories\n.shellcheck_generated*/\n\n# zip archives\n*.zip\n\n# core dump files\n**/core.[1-9]*\n\n# Generated if you use the pre-commit script for clang-tidy\npr.diff\n\n# coverage files\n*/**/.coverage.*\n\n# buck generated files\n.buckd/\n.lsp-buck-out/\n.lsp.buckd/\nbuck-out/\n\n# Downloaded libraries\nthird_party/ruy/\nthird_party/glog/\n\n# Virtualenv\n.venv/\nvenv/\n\n# Log files\n*.log\nsweep/\n\n# Android build artifacts\nandroid/pytorch_android/.cxx\nandroid/pytorch_android_torchvision/.cxx\n\n# Pyre configs (for internal usage)\n.pyre_configuration\n.pyre_configuration.codenav\n.arcconfig\n.stable_pyre_client\n.pyre_client\n\n# Claude Code local configuration\nCLAUDE.local.md\n/test_*.py\n/debug_*.py\nCLAUDE_CONTEXT/\n"
    }
  },
  "input_to_gpt": {
    "repo_name": "pytorch/pytorch",
    "num_code_blocks": 5,
    "total_length": 279,
    "code_blocks": [
      "# Only run this if you're compiling for ROCm\npython tools/amd_build/build_amd.py",
      "make -f docker.Makefile\n# images are tagged as docker.io/${your_docker_username}/pytorch",
      "make -f docker.Makefile",
      "   make latexpdf",
      "   make LATEXOPTS=\"-interaction=nonstopmode\""
    ]
  }
}