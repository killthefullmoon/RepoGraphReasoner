# ğŸ“Š æ¨¡å‹å¯¹æ¯”è¯„ä¼°æŒ‡å— (Model Comparison Guide)

## æ¦‚è¿° (Overview)

è¿™ä¸ªæŒ‡å—å¸®åŠ©æ‚¨å¯¹æ¯”**å¾®è°ƒå‰**å’Œ**å¾®è°ƒå**çš„æ¨¡å‹æ€§èƒ½ã€‚

---

## ğŸš€ å¿«é€Ÿå¼€å§‹ (Quick Start)

### æ­¥éª¤ 1: è¯„ä¼°åŸºç¡€æ¨¡å‹ (æœªå¾®è°ƒ)

```bash
cd /home/sour/LLaMA-Factory
conda activate llama_factory
python eval_base_model.py
```

**è¯´æ˜ï¼š**
- è¯„ä¼° Qwen/Qwen2.5-Coder-0.5B åŸºç¡€æ¨¡å‹ï¼ˆæœªä½¿ç”¨ LoRAï¼‰
- é¢„è®¡æ—¶é—´ï¼šçº¦ 20-30 åˆ†é’Ÿï¼ˆä½¿ç”¨ RTX 4070ï¼‰
- ç»“æœä¿å­˜åˆ°ï¼š`saves/qwen25_0.5B_coder/eval_results_base_model/`

---

### æ­¥éª¤ 2: è¯„ä¼°å¾®è°ƒæ¨¡å‹ (å·²å®Œæˆ)

æ‚¨å·²ç»è¿è¡Œè¿‡äº†ï¼š

```bash
python eval_simple.py
```

**ç»“æœä½ç½®ï¼š**
- `saves/qwen25_0.5B_coder/eval_results_6000/`

---

### æ­¥éª¤ 3: å¯¹æ¯”ç»“æœ

```bash
python compare_results.py
```

**è¾“å‡ºç¤ºä¾‹ï¼š**

```
================================================================================
ğŸ“Š COMPARISON: Base Model vs Finetuned Model (Checkpoint-6000)
================================================================================

ğŸ“ˆ GSM8K
   Base:      10.50%
   Finetuned: 26.52%
   Î”:        +16.02% (+152.6%)

ğŸ“ˆ WINOGRANDE
   Base:      51.20%
   Finetuned: 55.12%
   Î”:         +3.92% (+7.7%)

ğŸ“‰ MMLU_COLLEGE_CHEMISTRY
   Base:      30.00%
   Finetuned: 25.00%
   Î”:         -5.00% (-16.7%)

================================================================================
ğŸ“ˆ SUMMARY
================================================================================

âœ… Improvements (12 tasks):
   â€¢ gsm8k: +16.02%
   â€¢ minerva_math_algebra: +8.45%
   â€¢ winogrande: +3.92%
   ...

âš ï¸  Regressions (3 tasks):
   â€¢ mmlu_college_chemistry: -5.00%
   ...

Average improvement: +6.34%
================================================================================
```

---

## ğŸ“‚ æ–‡ä»¶è¯´æ˜

### è¯„ä¼°è„šæœ¬

1. **`eval_simple.py`** - è¯„ä¼°å¾®è°ƒæ¨¡å‹ (checkpoint-6000)
   - åŠ è½½åŸºç¡€æ¨¡å‹ + LoRA adapter
   - è¯„ä¼° 18 ä¸ªåŸºå‡†æµ‹è¯•
   - ä½¿ç”¨ 20% æ ·æœ¬ï¼Œçº¦ 20-30 åˆ†é’Ÿ

2. **`eval_base_model.py`** - è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆæœªå¾®è°ƒï¼‰
   - åªåŠ è½½åŸºç¡€æ¨¡å‹
   - ç›¸åŒçš„ 18 ä¸ªåŸºå‡†æµ‹è¯•
   - ç›¸åŒçš„ 20% æ ·æœ¬

3. **`compare_results.py`** - å¯¹æ¯”ä¸¤ä¸ªæ¨¡å‹çš„ç»“æœ
   - è‡ªåŠ¨æ‰¾åˆ°æœ€æ–°çš„ç»“æœæ–‡ä»¶
   - æ˜¾ç¤ºæ¯ä¸ªä»»åŠ¡çš„æ”¹è¿›/é€€æ­¥
   - æä¾›æ€»ç»“ç»Ÿè®¡

---

## ğŸ“Š è¯„ä¼°çš„åŸºå‡†æµ‹è¯•

### ä¸»è¦æµ‹è¯• (Main Tests)

| åŸºå‡† | ç±»å‹ | ä¸»è¦æŒ‡æ ‡ |
|------|------|---------|
| **DROP** | é˜…è¯»ç†è§£ | F1 Score |
| **WinoGrande** | å¸¸è¯†æ¨ç† | Accuracy |
| **GSM8K** | å°å­¦æ•°å­¦ | Exact Match |
| **MATH** | é«˜ç­‰æ•°å­¦ | Math Verify |

### MMLU-STEM (14 ä¸ªå­æµ‹è¯•)

- Abstract Algebra
- College Biology/Chemistry/CS/Math/Physics
- Elementary Mathematics
- High School Biology/Chemistry/CS/Math/Physics/Statistics
- Machine Learning

---

## âš™ï¸ é…ç½®é€‰é¡¹

### ä¿®æ”¹é‡‡æ ·ç‡

å¦‚æœæƒ³è¯„ä¼°æ›´å¤šæˆ–æ›´å°‘çš„æ ·æœ¬ï¼Œä¿®æ”¹ `limit` å‚æ•°ï¼š

```python
# åœ¨ eval_base_model.py æˆ– eval_simple.py ä¸­
limit=0.2,  # 20% çš„æ•°æ®
# æ”¹ä¸º
limit=0.5,  # 50% çš„æ•°æ®ï¼ˆæ›´æ…¢ä½†æ›´å‡†ç¡®ï¼‰
limit=0.1,  # 10% çš„æ•°æ®ï¼ˆæ›´å¿«ä½†ä¸å¤ªå‡†ç¡®ï¼‰
```

### ä¿®æ”¹ Batch Size

```python
batch_size=16,  # å½“å‰è®¾ç½®
# å¦‚æœå†…å­˜ä¸è¶³ï¼Œæ”¹ä¸º
batch_size=8,   # æˆ–æ›´å°
```

---

## ğŸ’¡ æç¤º

1. **å…ˆè¿è¡ŒåŸºç¡€æ¨¡å‹è¯„ä¼°**
   - è¿™æ ·å¯ä»¥å»ºç«‹åŸºçº¿
   - äº†è§£å¾®è°ƒå¸¦æ¥çš„å®é™…æå‡

2. **ä¿å­˜è¯„ä¼°ç»“æœ**
   - æ‰€æœ‰ç»“æœéƒ½è‡ªåŠ¨ä¿å­˜ä¸º JSON æ–‡ä»¶
   - å¯ä»¥éšæ—¶ç”¨ `compare_results.py` å¯¹æ¯”

3. **ç†è§£æŒ‡æ ‡**
   - `math_verify` æ¯” `exact_match` æ›´åˆç†ï¼ˆå¯¹ MATHï¼‰
   - `flexible-extract` æ¯” `strict-match` æ›´åˆç†ï¼ˆå¯¹ GSM8Kï¼‰
   - çœ‹æ ‡å‡†è¯¯å·® (`_stderr`) è¯„ä¼°ç»“æœå¯é æ€§

4. **é¢„æœŸæ”¹è¿›**
   - åœ¨è®­ç»ƒæ•°æ®ç›¸å…³çš„ä»»åŠ¡ä¸Šåº”è¯¥æœ‰æ˜æ˜¾æå‡
   - æŸäº›ä»»åŠ¡å¯èƒ½é€€æ­¥ï¼ˆæ­£å¸¸ç°è±¡ï¼Œç‰¹åˆ«æ˜¯å°æ¨¡å‹ï¼‰
   - å…³æ³¨æ•´ä½“è¶‹åŠ¿è€Œä¸æ˜¯ä¸ªåˆ«ä»»åŠ¡

---

## ğŸ¯ é¢„æœŸç»“æœ

å¯¹äº 0.5B æ¨¡å‹åœ¨ tulu_3_sft ä¸Šå¾®è°ƒåï¼š

**é€šå¸¸ä¼šæå‡çš„ï¼š**
- GSM8Kï¼ˆæ•°å­¦æ¨ç†ï¼‰
- éƒ¨åˆ† MATH å­ç±»åˆ«
- WinoGrandeï¼ˆå¸¸è¯†æ¨ç†ï¼‰

**å¯èƒ½ä¸å˜æˆ–ç•¥é™çš„ï¼š**
- æŸäº› MMLU ç§‘ç›®ï¼ˆå¦‚æœè®­ç»ƒæ•°æ®ä¸­è¾ƒå°‘ï¼‰
- DROPï¼ˆå–å†³äºè®­ç»ƒæ•°æ®ï¼‰

---

## ğŸ“ æ•…éšœæ’é™¤

### é—®é¢˜ï¼šæ‰¾ä¸åˆ°ç»“æœæ–‡ä»¶

```bash
# æ£€æŸ¥ç»“æœæ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -la saves/qwen25_0.5B_coder/eval_results_base_model/
ls -la saves/qwen25_0.5B_coder/eval_results_6000/
```

### é—®é¢˜ï¼šå†…å­˜ä¸è¶³

- å‡å° batch_sizeï¼ˆå¦‚æ”¹ä¸º 8 æˆ– 4ï¼‰
- å‡å° limitï¼ˆå¦‚æ”¹ä¸º 0.1ï¼‰

### é—®é¢˜ï¼šè¯„ä¼°å¤ªæ…¢

- å·²ç»ä½¿ç”¨ 20% æ ·æœ¬ï¼Œè¿™æ˜¯é€Ÿåº¦å’Œå‡†ç¡®æ€§çš„å¹³è¡¡
- å¯ä»¥è¿›ä¸€æ­¥é™ä½åˆ° 10%ï¼Œä½†ç»“æœå¯èƒ½ä¸å¤ªç¨³å®š

---

## ğŸ“ ç»“æœæ–‡ä»¶æ ¼å¼

ç»“æœ JSON æ–‡ä»¶åŒ…å«ï¼š

```json
{
  "model": "base_unfinetuned" æˆ– "finetuned",
  "results": {
    "task_name": {
      "metric_name": value,
      "metric_name_stderr": stderr_value
    }
  }
}
```

---

**ç¥è¯„ä¼°é¡ºåˆ©ï¼** ğŸ‰


