{
  "tasks": [
    {
      "task_title": "Transcribe Audio",
      "task_description": "使用预训练模型将音频文件转录为文本。",
      "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\nresult = model.transcribe(\"audio.mp3\")\nprint(result[\"text\"])",
      "running_command": null,
      "expected_input": "audio.mp3",
      "expected_output": "转录后的文本"
    },
    {
      "task_title": "Detect Language",
      "task_description": "加载音频文件并检测其语言。",
      "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\naudio = whisper.load_audio(\"audio.mp3\")\naudio = whisper.pad_or_trim(audio)\nmel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")",
      "running_command": null,
      "expected_input": "audio.mp3",
      "expected_output": "Detected language: 语言名称"
    },
    {
      "task_title": "Translate Audio",
      "task_description": "将音频文件中的语言翻译成目标语言。",
      "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\naudio = whisper.load_audio(\"japanese.wav\")\naudio = whisper.pad_or_trim(audio)\nmel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\noptions = whisper.DecodingOptions()\nresult = whisper.decode(model, mel, options)\nprint(result.text)",
      "running_command": null,
      "expected_input": "japanese.wav",
      "expected_output": "翻译后的文本"
    },
    {
      "task_title": "Use CLI for Transcription",
      "task_description": "通过命令行接口使用模型进行音频转录。",
      "example_code": null,
      "running_command": "whisper audio.flac audio.mp3 audio.wav --model turbo",
      "expected_input": "audio.flac, audio.mp3, audio.wav",
      "expected_output": "转录后的文本"
    },
    {
      "task_title": "Specify Language in CLI",
      "task_description": "在命令行中指定音频文件的语言。",
      "example_code": null,
      "running_command": "whisper japanese.wav --language Japanese",
      "expected_input": "japanese.wav",
      "expected_output": "转录后的文本"
    },
    {
      "task_title": "Translate with CLI",
      "task_description": "在命令行中将音频文件翻译成目标语言。",
      "example_code": null,
      "running_command": "whisper japanese.wav --model medium --language Japanese --task translate",
      "expected_input": "japanese.wav",
      "expected_output": "翻译后的文本"
    },
    {
      "task_title": "Help Command",
      "task_description": "显示命令行工具的帮助信息。",
      "example_code": null,
      "running_command": "whisper --help",
      "expected_input": null,
      "expected_output": "帮助信息"
    }
  ],
  "setup": {
    "setup_commands": [
      "# on Ubuntu or Debian\nsudo apt update && sudo apt install ffmpeg\n\n# on Arch Linux\nsudo pacman -S ffmpeg\n\n# on MacOS using Homebrew (https://brew.sh/)\nbrew install ffmpeg\n\n# on Windows using Chocolatey (https://chocolatey.org/)\nchoco install ffmpeg\n\n# on Windows using Scoop (https://scoop.sh/)\nscoop install ffmpeg",
      "pip install setuptools-rust"
    ],
    "docker_commands": [],
    "docker_files": {},
    "docker_setup_descriptions": null
  },
  "input_to_gpt": {
    "repo_name": "openai/whisper",
    "num_code_blocks": 6,
    "total_length": 926,
    "code_blocks": [
      "whisper audio.flac audio.mp3 audio.wav --model turbo",
      "whisper japanese.wav --language Japanese",
      "whisper japanese.wav --model medium --language Japanese --task translate",
      "whisper --help",
      "import whisper\n\nmodel = whisper.load_model(\"turbo\")\nresult = model.transcribe(\"audio.mp3\")\nprint(result[\"text\"])",
      "import whisper\n\nmodel = whisper.load_model(\"turbo\")\n\n# load audio and pad/trim it to fit 30 seconds\naudio = whisper.load_audio(\"audio.mp3\")\naudio = whisper.pad_or_trim(audio)\n\n# make log-Mel spectrogram and move to the same device as the model\nmel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n\n# detect the spoken language\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")\n\n# decode the audio\noptions = whisper.DecodingOptions()\nresult = whisper.decode(model, mel, options)\n\n# print the recognized text\nprint(result.text)"
    ]
  }
}