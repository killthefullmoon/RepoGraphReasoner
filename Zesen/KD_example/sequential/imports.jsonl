{"path": "v2/generation_functions.py", "module": "v2.generation_functions", "imports": ["typing", "torch", "types", "transformers.utils"], "num_defs": 4, "num_imports": 4, "has_test_flag": false}
{"path": "v2/setup.py", "module": "v2.setup", "imports": ["os", "setuptools", "setuptools"], "num_defs": 0, "num_imports": 3, "has_test_flag": false}
{"path": "v2/app.py", "module": "v2.app", "imports": ["torch", "numpy", "gradio", "torch.nn.functional", "transformers", "time", "random", "types", "generation_functions"], "num_defs": 8, "num_imports": 9, "has_test_flag": false}
{"path": "v2/run_chatbot.py", "module": "v2.run_chatbot", "imports": ["transformers", "torch", "numpy", "random"], "num_defs": 1, "num_imports": 4, "has_test_flag": false}
{"path": "v2/eval.py", "module": "v2.eval", "imports": ["accelerate", "torch", "re", "pathlib", "random", "numpy", "torch.nn.functional", "datasets", "lm_eval.__main__", "lm_eval.api.model", "lm_eval.api.registry", "tqdm", "os", "transformers", "json", "time", "types", "generation_functions"], "num_defs": 15, "num_imports": 18, "has_test_flag": false}
{"path": "v2/train_scripts/finetune.py", "module": "v2.train_scripts.finetune", "imports": ["sys", "os", "transformers", "lmflow.args", "lmflow.datasets.dataset", "lmflow.models.auto_model", "lmflow.pipeline.auto_pipeline"], "num_defs": 1, "num_imports": 7, "has_test_flag": false}
{"path": "v2/src/lmflow/version.py", "module": "v2.src.lmflow.version", "imports": [], "num_defs": 0, "num_imports": 0, "has_test_flag": false}
{"path": "v2/src/lmflow/__init__.py", "module": "v2.src.lmflow.__init__", "imports": ["version", "transformers.utils", "transformers.utils.versions", "lmflow"], "num_defs": 0, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/args.py", "module": "v2.src.lmflow.args", "imports": ["logging", "dataclasses", "pathlib", "typing", "transformers", "transformers.utils.versions", "lmflow.utils.versioning"], "num_defs": 21, "num_imports": 7, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/dpo_aligner.py", "module": "v2.src.lmflow.pipeline.dpo_aligner", "imports": ["os", "pathlib", "typing", "datasets", "peft", "transformers", "lmflow.pipeline.base_aligner", "lmflow.utils.versioning", "trl"], "num_defs": 7, "num_imports": 9, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/iterative_dpo_aligner.py", "module": "v2.src.lmflow.pipeline.iterative_dpo_aligner", "imports": ["copy", "dataclasses", "gc", "json", "logging", "pathlib", "typing", "tqdm", "lmflow.models.hf_text_regression_model", "lmflow.models.hf_decoder_model", "lmflow.datasets.dataset", "lmflow.pipeline.dpov2_aligner", "lmflow.pipeline.rm_inferencer", "lmflow.pipeline.vllm_inferencer", "lmflow.args", "lmflow.utils.common"], "num_defs": 11, "num_imports": 16, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/base_tuner.py", "module": "v2.src.lmflow.pipeline.base_tuner", "imports": ["lmflow.pipeline.base_pipeline"], "num_defs": 4, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/vllm_inferencer.py", "module": "v2.src.lmflow.pipeline.vllm_inferencer", "imports": ["copy", "importlib.resources", "json", "logging", "os", "subprocess", "sys", "functools", "typing", "numpy", "transformers", "lmflow.datasets", "lmflow.pipeline.base_pipeline", "lmflow.models.hf_decoder_model", "lmflow.args", "lmflow.utils.common", "lmflow.utils.constants", "lmflow.utils.data_utils", "lmflow.utils.versioning", "vllm", "ray", "ray.data", "ray.util.scheduling_strategies"], "num_defs": 20, "num_imports": 23, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/inferencer.py", "module": "v2.src.lmflow.pipeline.inferencer", "imports": ["copy", "os", "torch", "wandb", "deepspeed", "sys", "numpy", "datetime", "json", "time", "logging", "typing", "concurrent.futures", "subprocess", "accelerate", "transformers", "torch.distributed", "torch.nn.functional", "lmflow.args", "lmflow.datasets.dataset", "lmflow.pipeline.base_pipeline", "lmflow.models.hf_decoder_model", "lmflow.utils.data_utils", "lmflow.utils.constants"], "num_defs": 19, "num_imports": 24, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/raft_aligner.py", "module": "v2.src.lmflow.pipeline.raft_aligner", "imports": ["logging", "numpy", "os", "sys", "time", "itertools", "torch", "torch.distributed", "transformers", "datasets", "transformers", "transformers.testing_utils", "lmflow.args", "lmflow.datasets.dataset", "lmflow.pipeline.base_aligner", "lmflow.pipeline.utils.raft_trainer", "matplotlib.pyplot", "json", "matplotlib.pyplot", "json"], "num_defs": 13, "num_imports": 20, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/auto_pipeline.py", "module": "v2.src.lmflow.pipeline.auto_pipeline", "imports": ["lmflow.utils.versioning", "lmflow.pipeline.evaluator", "lmflow.pipeline.finetuner", "lmflow.pipeline.inferencer", "lmflow.pipeline.rm_tuner", "lmflow.pipeline.rm_inferencer", "lmflow.pipeline.raft_aligner", "lmflow.pipeline.vllm_inferencer", "lmflow.pipeline.dpo_aligner", "lmflow.pipeline.dpov2_aligner", "lmflow.pipeline.iterative_dpo_aligner"], "num_defs": 2, "num_imports": 11, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/rm_inferencer.py", "module": "v2.src.lmflow.pipeline.rm_inferencer", "imports": ["copy", "os", "torch", "wandb", "deepspeed", "sys", "numpy", "datetime", "json", "time", "logging", "typing", "accelerate", "torch", "tqdm", "transformers", "transformers.modeling_outputs", "torch.distributed", "torch.nn.functional", "lmflow.args", "lmflow.datasets.dataset", "lmflow.models.hf_text_regression_model", "lmflow.pipeline.base_pipeline", "lmflow.utils.data_utils", "lmflow.datasets.dataset", "lmflow.utils.versioning", "ray", "ray.data", "ray.util.scheduling_strategies"], "num_defs": 14, "num_imports": 29, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/rm_tuner.py", "module": "v2.src.lmflow.pipeline.rm_tuner", "imports": ["sys", "logging", "typing", "copy", "numpy", "datasets", "transformers", "transformers", "transformers.utils", "transformers.trainer_callback", "lmflow.datasets", "lmflow.models.hf_text_regression_model", "lmflow.pipeline.finetuner", "lmflow.pipeline.utils.rm_trainer", "lmflow.pipeline.utils.peft_trainer", "lmflow.pipeline.utils.rm_dataprocessor"], "num_defs": 8, "num_imports": 16, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/base_aligner.py", "module": "v2.src.lmflow.pipeline.base_aligner", "imports": ["lmflow.pipeline.base_pipeline"], "num_defs": 4, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/base_pipeline.py", "module": "v2.src.lmflow.pipeline.base_pipeline", "imports": ["abc"], "num_defs": 1, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/dpov2_aligner.py", "module": "v2.src.lmflow.pipeline.dpov2_aligner", "imports": ["copy", "importlib.resources", "logging", "os", "subprocess", "sys", "typing", "numpy", "tqdm", "torch", "transformers", "lmflow.pipeline.utils.dpov2_trainer", "lmflow.pipeline.base_aligner", "lmflow.args", "lmflow.utils.common", "lmflow.models.hf_decoder_model", "lmflow.datasets.dataset", "lmflow.utils.constants"], "num_defs": 13, "num_imports": 18, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/finetuner.py", "module": "v2.src.lmflow.pipeline.finetuner", "imports": ["copy", "logging", "os", "sys", "typing", "datasets", "transformers", "evaluate", "itertools", "transformers", "copy", "transformers", "transformers.trainer_utils", "transformers.trainer_callback", "transformers.utils", "numpy", "lmflow.optim.optimizers", "lmflow.args", "lmflow.datasets.dataset", "lmflow.models.hf_decoder_model", "lmflow.models.hf_encoder_decoder_model", "lmflow.models.hf_text_regression_model", "lmflow.pipeline.base_tuner", "lmflow.pipeline.utils.peft_trainer"], "num_defs": 16, "num_imports": 24, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/evaluator.py", "module": "v2.src.lmflow.pipeline.evaluator", "imports": ["os", "torch", "wandb", "deepspeed", "sys", "numpy", "datetime", "json", "accelerate", "transformers", "torch.distributed", "lmflow.datasets.dataset", "lmflow.pipeline.base_pipeline", "lmflow.models.hf_decoder_model", "lmflow.utils.data_utils"], "num_defs": 10, "num_imports": 15, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py", "module": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor", "imports": ["dataclasses", "logging", "typing", "torch", "torch.nn.utils.rnn", "transformers"], "num_defs": 4, "num_imports": 6, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/rm_dataprocessor.py", "module": "v2.src.lmflow.pipeline.utils.rm_dataprocessor", "imports": ["logging", "dataclasses", "typing", "datasets", "transformers", "transformers.utils"], "num_defs": 2, "num_imports": 6, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/rm_trainer.py", "module": "v2.src.lmflow.pipeline.utils.rm_trainer", "imports": ["numpy", "torch", "torch.nn", "transformers", "peft_trainer"], "num_defs": 6, "num_imports": 5, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/dpov2_trainer.py", "module": "v2.src.lmflow.pipeline.utils.dpov2_trainer", "imports": ["logging", "typing", "datasets", "torch", "torch.nn", "torch.nn.functional", "transformers", "transformers.trainer_callback", "transformers.trainer_utils", "lmflow.pipeline.utils.dpov2_dataprocessor", "lmflow.utils.versioning", "trl"], "num_defs": 5, "num_imports": 12, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/peft_trainer.py", "module": "v2.src.lmflow.pipeline.utils.peft_trainer", "imports": ["__future__", "transformers", "transformers.trainer_utils", "transformers.trainer_callback", "transformers.training_args", "os", "numpy"], "num_defs": 7, "num_imports": 7, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/raft_trainer.py", "module": "v2.src.lmflow.pipeline.utils.raft_trainer", "imports": ["contextlib", "functools", "glob", "inspect", "math", "os", "random", "re", "shutil", "sys", "time", "warnings", "collections.abc", "distutils.util", "pathlib", "typing", "tqdm.auto", "numpy", "torch", "torch.distributed", "huggingface_hub", "packaging", "torch", "torch.utils.data", "torch.utils.data.distributed", "transformers.configuration_utils", "transformers.data.data_collator", "transformers.debug_utils", "transformers.deepspeed", "transformers.dependency_versions_check", "transformers.modelcard", "transformers.modeling_utils", "transformers.models.auto.modeling_auto", "transformers.optimization", "transformers.pytorch_utils", "transformers.tokenization_utils_base", "transformers.trainer_callback", "transformers.trainer_pt_utils", "transformers.trainer_utils", "transformers.training_args", "transformers.utils", "transformers.utils.generic", "transformers.integrations", "transformers.utils.notebook", "apex", "datasets", "torch_xla.core.xla_model", "torch_xla.debug.metrics", "torch_xla.distributed.parallel_loader", "fairscale", "fairscale.nn.data_parallel", "fairscale.nn.data_parallel", "fairscale.nn.wrap", "fairscale.optim", "fairscale.optim.grad_scaler", "smdistributed.modelparallel.torch", "smdistributed.modelparallel", "transformers.trainer_pt_utils", "transformers.trainer_pt_utils", "transformers.integrations", "transformers.hyperparameter_search", "ray", "intel_extension_for_pytorch", "torch.distributed.fsdp.fully_sharded_data_parallel", "transformers.deepspeed", "optuna", "transformers.trainer_utils", "transformers.optimization", "ray", "bitsandbytes", "torch.optim", "torch.distributed.fsdp.fully_sharded_data_parallel", "torch.distributed.fsdp.fully_sharded_data_parallel", "torch.distributed.fsdp.wrap", "ray", "torch_xla.distributed.fsdp", "torch_xla.distributed.fsdp", "torch_xla.distributed.fsdp.wrap", "torch.distributed.fsdp.sharded_grad_scaler", "torch_xla.amp.syncfree", "wandb", "torch_xla.amp", "apex.optimizers", "bitsandbytes.optim", "torchdistx.optimizers"], "num_defs": 71, "num_imports": 85, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/memory_safe_dpov2_align.py", "module": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align", "imports": ["logging", "os", "sys", "copy", "transformers", "lmflow.datasets", "lmflow.models.hf_decoder_model", "lmflow.pipeline.dpov2_aligner", "lmflow.args", "lmflow.utils.common"], "num_defs": 1, "num_imports": 10, "has_test_flag": false}
{"path": "v2/src/lmflow/pipeline/utils/memory_safe_vllm_inference.py", "module": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference", "imports": ["logging", "sys", "os", "typing", "transformers", "lmflow.datasets", "lmflow.models.auto_model", "lmflow.pipeline.vllm_inferencer", "lmflow.args", "lmflow.utils.constants"], "num_defs": 1, "num_imports": 10, "has_test_flag": false}
{"path": "v2/src/lmflow/datasets/multi_modal_dataset.py", "module": "v2.src.lmflow.datasets.multi_modal_dataset", "imports": ["copy", "dataclasses", "json", "PIL", "os.path", "transformers", "torch", "torch.utils.data", "lmflow.args", "lmflow.utils", "lmflow.utils.constants"], "num_defs": 13, "num_imports": 11, "has_test_flag": false}
{"path": "v2/src/lmflow/datasets/__init__.py", "module": "v2.src.lmflow.datasets.__init__", "imports": ["lmflow.utils.versioning", "lmflow.datasets.dataset", "lmflow.datasets.multi_modal_dataset"], "num_defs": 0, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/datasets/dataset.py", "module": "v2.src.lmflow.datasets.dataset", "imports": ["copy", "json", "logging", "pathlib", "cmath", "pathlib", "typing", "datasets", "datasets", "tqdm", "lmflow.args", "lmflow.utils.constants", "lmflow.utils.versioning", "lmflow.utils.data_utils", "multi_modal_dataset"], "num_defs": 21, "num_imports": 15, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/lamb.py", "module": "v2.src.lmflow.optim.lamb", "imports": ["math", "torch", "torch.optim.optimizer"], "num_defs": 3, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adan.py", "module": "v2.src.lmflow.optim.adan", "imports": ["math", "typing", "torch", "torch", "torch.optim.optimizer"], "num_defs": 7, "num_imports": 5, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/lars.py", "module": "v2.src.lmflow.optim.lars", "imports": ["torch", "torch.optim.optimizer"], "num_defs": 4, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adamax.py", "module": "v2.src.lmflow.optim.adamax", "imports": ["torch", "torch.optim.optimizer"], "num_defs": 4, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/sgd_schedule_free.py", "module": "v2.src.lmflow.optim.sgd_schedule_free", "imports": ["torch", "torch.optim"], "num_defs": 5, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adamp.py", "module": "v2.src.lmflow.optim.adamp", "imports": ["math", "torch", "torch.optim.optimizer"], "num_defs": 7, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adabelief.py", "module": "v2.src.lmflow.optim.adabelief", "imports": ["math", "torch", "torch.optim.optimizer"], "num_defs": 5, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adagrad.py", "module": "v2.src.lmflow.optim.adagrad", "imports": ["torch", "torch.optim.optimizer"], "num_defs": 3, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/optimizers.py", "module": "v2.src.lmflow.optim.optimizers", "imports": ["lmflow.optim.dummy", "lmflow.optim.adabelief", "lmflow.optim.adabound", "lmflow.optim.lars", "lmflow.optim.lamb", "lmflow.optim.adamax", "lmflow.optim.nadam", "lmflow.optim.radam", "lmflow.optim.adamp", "lmflow.optim.sgdp", "lmflow.optim.yogi", "lmflow.optim.sophia", "lmflow.optim.adan", "lmflow.optim.novograd", "lmflow.optim.adam", "lmflow.optim.adadelta", "lmflow.optim.adagrad", "lmflow.optim.muon", "lmflow.optim.adamw_schedule_free", "lmflow.optim.sgd_schedule_free"], "num_defs": 0, "num_imports": 20, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/novograd.py", "module": "v2.src.lmflow.optim.novograd", "imports": ["torch", "torch.optim"], "num_defs": 4, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/yogi.py", "module": "v2.src.lmflow.optim.yogi", "imports": ["math", "torch", "torch.nn", "torch.optim.optimizer"], "num_defs": 3, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/radam.py", "module": "v2.src.lmflow.optim.radam", "imports": ["math", "warnings", "torch", "torch.optim.optimizer"], "num_defs": 4, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adam.py", "module": "v2.src.lmflow.optim.adam", "imports": ["torch", "torch.optim.optimizer"], "num_defs": 3, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adamw_schedule_free.py", "module": "v2.src.lmflow.optim.adamw_schedule_free", "imports": ["torch", "torch.optim", "math"], "num_defs": 5, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/sophia.py", "module": "v2.src.lmflow.optim.sophia", "imports": ["torch", "torch.optim.optimizer"], "num_defs": 5, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adabound.py", "module": "v2.src.lmflow.optim.adabound", "imports": ["math", "torch", "torch.optim.optimizer"], "num_defs": 4, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/nadam.py", "module": "v2.src.lmflow.optim.nadam", "imports": ["torch", "math"], "num_defs": 4, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/muon.py", "module": "v2.src.lmflow.optim.muon", "imports": ["torch", "torch.nn", "math", "os", "torch.distributed", "torch.nn", "torch"], "num_defs": 4, "num_imports": 7, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/sgdp.py", "module": "v2.src.lmflow.optim.sgdp", "imports": ["math", "torch", "torch.optim.optimizer"], "num_defs": 7, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/dummy.py", "module": "v2.src.lmflow.optim.dummy", "imports": ["math", "warnings", "typing", "torch", "torch", "torch.optim"], "num_defs": 3, "num_imports": 6, "has_test_flag": false}
{"path": "v2/src/lmflow/optim/adadelta.py", "module": "v2.src.lmflow.optim.adadelta", "imports": ["torch", "torch.optim.optimizer"], "num_defs": 3, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/llava_conversation_lib.py", "module": "v2.src.lmflow.utils.llava_conversation_lib", "imports": ["dataclasses", "enum", "typing", "base64", "io", "PIL", "base64", "io"], "num_defs": 9, "num_imports": 8, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/constants.py", "module": "v2.src.lmflow.utils.constants", "imports": [], "num_defs": 0, "num_imports": 0, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/multimodal.py", "module": "v2.src.lmflow.utils.multimodal", "imports": ["glob", "torch", "transformers", "tqdm"], "num_defs": 3, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/model.py", "module": "v2.src.lmflow.utils.model", "imports": ["logging", "typing", "transformers", "lmflow.args"], "num_defs": 1, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/data_utils.py", "module": "v2.src.lmflow.utils.data_utils", "imports": ["json", "os", "random", "re", "typing", "numpy", "torch"], "num_defs": 10, "num_imports": 7, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/common.py", "module": "v2.src.lmflow.utils.common", "imports": ["logging", "dataclasses", "pathlib", "typing", "lmflow.utils.versioning"], "num_defs": 5, "num_imports": 5, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/versioning.py", "module": "v2.src.lmflow.utils.versioning", "imports": ["importlib", "sys", "logging", "typing", "importlib.metadata", "pkg_resources"], "num_defs": 11, "num_imports": 6, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/chatglm.py", "module": "v2.src.lmflow.utils.conversation_template.chatglm", "imports": ["base"], "num_defs": 0, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/__init__.py", "module": "v2.src.lmflow.utils.conversation_template.__init__", "imports": ["logging", "lmflow.utils.versioning", "base", "chatglm", "chatml", "deepseek", "gemma", "hymba", "internlm", "llama", "phi", "qwen", "yi", "zephyr"], "num_defs": 0, "num_imports": 14, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/chatml.py", "module": "v2.src.lmflow.utils.conversation_template.chatml", "imports": ["base"], "num_defs": 0, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/llama.py", "module": "v2.src.lmflow.utils.conversation_template.llama", "imports": ["logging", "typing", "transformers", "base", "lmflow.utils.constants"], "num_defs": 4, "num_imports": 5, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/qwen.py", "module": "v2.src.lmflow.utils.conversation_template.qwen", "imports": ["typing", "transformers", "base"], "num_defs": 0, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/deepseek.py", "module": "v2.src.lmflow.utils.conversation_template.deepseek", "imports": ["base"], "num_defs": 0, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/yi.py", "module": "v2.src.lmflow.utils.conversation_template.yi", "imports": ["base"], "num_defs": 0, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/zephyr.py", "module": "v2.src.lmflow.utils.conversation_template.zephyr", "imports": ["logging", "typing", "transformers", "base"], "num_defs": 2, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/gemma.py", "module": "v2.src.lmflow.utils.conversation_template.gemma", "imports": ["logging", "dataclasses", "base"], "num_defs": 2, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/internlm.py", "module": "v2.src.lmflow.utils.conversation_template.internlm", "imports": ["base"], "num_defs": 0, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/base.py", "module": "v2.src.lmflow.utils.conversation_template.base", "imports": ["re", "abc", "dataclasses", "typing", "logging", "transformers", "lmflow.utils.constants"], "num_defs": 28, "num_imports": 7, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/hymba.py", "module": "v2.src.lmflow.utils.conversation_template.hymba", "imports": ["base", "typing", "transformers"], "num_defs": 2, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/conversation_template/phi.py", "module": "v2.src.lmflow.utils.conversation_template.phi", "imports": ["base"], "num_defs": 0, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py", "module": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch", "imports": ["functools", "torch", "transformers", "transformers.models.llama.modeling_llama"], "num_defs": 4, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/flash_attention/gpt2_flash_attention.py", "module": "v2.src.lmflow.utils.flash_attention.gpt2_flash_attention", "imports": ["typing", "torch", "torch", "transformers", "transformers.models.llama.modeling_llama", "einops", "flash_attn.bert_padding", "flash_attn.flash_attn_interface", "flash_attn.flash_attn_interface"], "num_defs": 3, "num_imports": 9, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/flash_attention/gpt_neo_flash_attention.py", "module": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention", "imports": ["typing", "torch", "transformers", "einops", "flash_attn.bert_padding", "flash_attn.flash_attn_interface", "flash_attn.flash_attn_interface"], "num_defs": 3, "num_imports": 7, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/flash_attention/bloom_flash_attention.py", "module": "v2.src.lmflow.utils.flash_attention.bloom_flash_attention", "imports": ["typing", "torch", "torch", "torch.nn.functional", "transformers", "transformers.models.bloom.modeling_bloom", "einops", "triton_flash_attention"], "num_defs": 3, "num_imports": 8, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/flash_attention/triton_flash_attention.py", "module": "v2.src.lmflow.utils.flash_attention.triton_flash_attention", "imports": ["math", "torch", "triton", "triton.language"], "num_defs": 17, "num_imports": 4, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/flash_attention/llama_flash_attention.py", "module": "v2.src.lmflow.utils.flash_attention.llama_flash_attention", "imports": ["typing", "torch", "torch", "math", "transformers", "transformers.models.llama.modeling_llama", "einops", "flash_attn.bert_padding", "flash_attn.flash_attn_interface", "flash_attn.flash_attn_interface"], "num_defs": 3, "num_imports": 10, "has_test_flag": false}
{"path": "v2/src/lmflow/utils/debug/profiler.py", "module": "v2.src.lmflow.utils.debug.profiler", "imports": ["time", "pprint"], "num_defs": 7, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/models/hf_encoder_decoder_model.py", "module": "v2.src.lmflow.models.hf_encoder_decoder_model", "imports": ["copy", "logging", "time", "typing", "deepspeed", "torch", "peft", "transformers", "transformers.testing_utils", "lmflow.datasets.dataset", "lmflow.models.encoder_decoder_model", "lmflow.models.interfaces.tunable", "lmflow.models.vision2seq_model", "lmflow.utils.multimodal", "lmflow.utils.versioning", "transformers.integrations.deepspeed", "transformers.deepspeed"], "num_defs": 11, "num_imports": 17, "has_test_flag": false}
{"path": "v2/src/lmflow/models/text_regression_model.py", "module": "v2.src.lmflow.models.text_regression_model", "imports": ["lmflow.models.regression_model", "lmflow.datasets.dataset"], "num_defs": 4, "num_imports": 2, "has_test_flag": false}
{"path": "v2/src/lmflow/models/auto_model.py", "module": "v2.src.lmflow.models.auto_model", "imports": ["lmflow.models.hf_decoder_model", "lmflow.models.hf_text_regression_model", "lmflow.models.hf_encoder_decoder_model"], "num_defs": 2, "num_imports": 3, "has_test_flag": false}
{"path": "v2/src/lmflow/models/hf_decoder_model.py", "module": "v2.src.lmflow.models.hf_decoder_model", "imports": ["hashlib", "logging", "os", "shutil", "typing", "torch", "transformers", "peft", "lmflow.datasets.dataset", "lmflow.models.hf_model_mixin", "lmflow.models.decoder_model", "lmflow.models.interfaces.tunable", "lmflow.utils.constants", "lmflow.utils.conversation_template", "lmflow.utils.data_utils", "lmflow.tokenization.hf_decoder_model", "lmflow.utils.versioning", "flash_attn", "vllm", "ray", "ray.data", "tempfile"], "num_defs": 15, "num_imports": 22, "has_test_flag": false}
{"path": "v2/src/lmflow/models/encoder_decoder_model.py", "module": "v2.src.lmflow.models.encoder_decoder_model", "imports": ["lmflow.models.base_model"], "num_defs": 2, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/models/base_model.py", "module": "v2.src.lmflow.models.base_model", "imports": ["abc"], "num_defs": 2, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/models/hf_text_regression_model.py", "module": "v2.src.lmflow.models.hf_text_regression_model", "imports": ["os", "copy", "hashlib", "logging", "pathlib", "typing", "torch", "peft", "transformers.modeling_outputs", "lmflow.args", "lmflow.datasets.dataset", "lmflow.models.interfaces.tunable", "lmflow.models.hf_model_mixin", "lmflow.models.text_regression_model", "lmflow.tokenization.hf_text_regression_model", "lmflow.utils.conversation_template", "lmflow.utils.constants", "lmflow.utils.data_utils", "lmflow.utils.versioning", "ray", "ray.data", "vllm"], "num_defs": 10, "num_imports": 22, "has_test_flag": false}
{"path": "v2/src/lmflow/models/hf_model_mixin.py", "module": "v2.src.lmflow.models.hf_model_mixin", "imports": ["gc", "os", "logging", "typing", "copy", "torch", "deepspeed", "transformers", "peft", "peft.utils.constants", "lmflow.models.base_model", "lmflow.utils.constants", "lmflow.args", "lmflow.utils.versioning", "vllm", "vllm.distributed.parallel_state", "torch._dynamo", "transformers.integrations", "lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch"], "num_defs": 17, "num_imports": 19, "has_test_flag": false}
{"path": "v2/src/lmflow/models/regression_model.py", "module": "v2.src.lmflow.models.regression_model", "imports": ["lmflow.models.base_model"], "num_defs": 2, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/models/vision2seq_model.py", "module": "v2.src.lmflow.models.vision2seq_model", "imports": ["copy", "logging", "time", "torch", "torch.nn", "typing", "torch.nn", "transformers", "transformers.modeling_outputs", "lmflow.models.base_model", "lmflow.models.vision_encoder", "lmflow.utils.versioning", "transformers.integrations.deepspeed", "transformers.deepspeed"], "num_defs": 14, "num_imports": 14, "has_test_flag": false}
{"path": "v2/src/lmflow/models/decoder_model.py", "module": "v2.src.lmflow.models.decoder_model", "imports": ["lmflow.models.base_model"], "num_defs": 2, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/models/interfaces/tunable.py", "module": "v2.src.lmflow.models.interfaces.tunable", "imports": ["abc"], "num_defs": 1, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/models/vision_encoder/__init__.py", "module": "v2.src.lmflow.models.vision_encoder.__init__", "imports": ["clip_encoder"], "num_defs": 0, "num_imports": 1, "has_test_flag": false}
{"path": "v2/src/lmflow/models/vision_encoder/clip_encoder.py", "module": "v2.src.lmflow.models.vision_encoder.clip_encoder", "imports": ["webbrowser", "torch", "torch.nn", "transformers", "lmflow.utils.constants"], "num_defs": 14, "num_imports": 5, "has_test_flag": false}
{"path": "v2/src/lmflow/tokenization/__init__.py", "module": "v2.src.lmflow.tokenization.__init__", "imports": [], "num_defs": 0, "num_imports": 0, "has_test_flag": false}
{"path": "v2/src/lmflow/tokenization/hf_decoder_model.py", "module": "v2.src.lmflow.tokenization.hf_decoder_model", "imports": ["logging", "typing", "transformers", "transformers", "transformers.testing_utils", "lmflow.args", "lmflow.utils.constants", "lmflow.utils.conversation_template"], "num_defs": 3, "num_imports": 8, "has_test_flag": false}
{"path": "v2/src/lmflow/tokenization/hf_text_regression_model.py", "module": "v2.src.lmflow.tokenization.hf_text_regression_model", "imports": ["logging", "logging", "typing", "transformers", "transformers.testing_utils", "transformers", "lmflow.utils.conversation_template", "lmflow.utils.constants", "lmflow.args"], "num_defs": 7, "num_imports": 9, "has_test_flag": false}
{"path": "llada/eval_llada.py", "module": "llada.eval_llada", "imports": ["accelerate", "torch", "re", "pathlib", "random", "numpy", "torch.nn.functional", "datasets", "lm_eval.__main__", "lm_eval.api.instance", "lm_eval.api.model", "lm_eval.api.registry", "tqdm", "os", "transformers", "generate", "model.modeling_llada", "json", "time"], "num_defs": 14, "num_imports": 19, "has_test_flag": false}
{"path": "llada/postprocess_code.py", "module": "llada.postprocess_code", "imports": ["evaluate", "os", "sys", "sanitize", "json"], "num_defs": 3, "num_imports": 5, "has_test_flag": false}
{"path": "llada/generate.py", "module": "llada.generate", "imports": ["torch", "numpy", "torch.nn.functional", "os", "transformers", "model.modeling_llada", "torch.cuda"], "num_defs": 8, "num_imports": 7, "has_test_flag": false}
{"path": "llada/chat.py", "module": "llada.chat", "imports": ["torch", "argparse", "generate", "transformers", "model.modeling_llada"], "num_defs": 1, "num_imports": 5, "has_test_flag": false}
{"path": "llada/app.py", "module": "llada.app", "imports": ["torch", "numpy", "gradio", "torch.nn.functional", "transformers", "model.modeling_llada", "time", "re"], "num_defs": 12, "num_imports": 8, "has_test_flag": false}
{"path": "llada/sanitize.py", "module": "llada.sanitize", "imports": ["os", "sys", "pathlib", "ast", "traceback", "typing"], "num_defs": 8, "num_imports": 6, "has_test_flag": false}
{"path": "llada/model/__init__.py", "module": "llada.model.__init__", "imports": ["configuration_llada", "modeling_llada"], "num_defs": 0, "num_imports": 2, "has_test_flag": false}
{"path": "llada/model/modeling_llada.py", "module": "llada.model.modeling_llada", "imports": ["__future__", "logging", "math", "sys", "abc", "collections", "functools", "typing", "dataclasses", "typing", "torch", "torch.backends.cuda", "torch.nn", "torch.nn.functional", "torch", "transformers", "transformers.modeling_outputs", "transformers.models.auto", "transformers.cache_utils", "configuration_llada", "torch.nn.attention.flex_attention", "collections.abc", "torch.utils.checkpoint", "typing", "warnings", "flash_attn", "warnings"], "num_defs": 94, "num_imports": 27, "has_test_flag": false}
{"path": "llada/model/configuration_llada.py", "module": "llada.model.configuration_llada", "imports": ["transformers", "enum", "os", "typing", "dataclasses", "glob", "pathlib", "typing"], "num_defs": 15, "num_imports": 8, "has_test_flag": false}
{"path": "dream/postprocess_code.py", "module": "dream.postprocess_code", "imports": ["evaluate", "os", "sys", "sanitize", "json"], "num_defs": 3, "num_imports": 5, "has_test_flag": false}
{"path": "dream/demo_multiturn_chat.py", "module": "dream.demo_multiturn_chat", "imports": ["torch", "transformers", "time", "model.modeling_dream", "types", "model.generation_utils_block"], "num_defs": 1, "num_imports": 6, "has_test_flag": false}
{"path": "dream/eval.py", "module": "dream.eval", "imports": ["logging", "gc", "datetime", "typing", "torch", "torch.nn.functional", "transformers", "accelerate", "datasets", "packaging", "tqdm", "lm_eval", "lm_eval.api.instance", "lm_eval.api.model", "lm_eval.api.registry", "lm_eval.models.utils", "lm_eval.__main__", "model.generation_utils_block", "types", "model.configuration_dream", "model.modeling_dream", "time", "os", "json", "model.generation_utils_block", "model.generation_utils"], "num_defs": 22, "num_imports": 26, "has_test_flag": false}
{"path": "dream/sanitize.py", "module": "dream.sanitize", "imports": ["os", "sys", "pathlib", "ast", "traceback", "typing"], "num_defs": 8, "num_imports": 6, "has_test_flag": false}
{"path": "dream/model/modeling_dream.py", "module": "dream.model.modeling_dream", "imports": ["math", "typing", "os", "torch", "torch.utils.checkpoint", "torch", "transformers.activations", "transformers.cache_utils", "transformers.modeling_outputs", "transformers.modeling_rope_utils", "transformers.modeling_utils", "transformers.utils", "transformers", "configuration_dream", "generation_utils", "transformers.modeling_flash_attention_utils"], "num_defs": 45, "num_imports": 16, "has_test_flag": false}
{"path": "dream/model/__init__.py", "module": "dream.model.__init__", "imports": ["configuration_dream", "modeling_dream"], "num_defs": 0, "num_imports": 2, "has_test_flag": false}
{"path": "dream/model/generation_utils.py", "module": "dream.model.generation_utils", "imports": ["time", "warnings", "copy", "dataclasses", "typing", "torch", "torch.distributions", "torch.nn", "transformers", "transformers.generation.configuration_utils", "transformers.utils"], "num_defs": 16, "num_imports": 11, "has_test_flag": false}
{"path": "dream/model/tokenization_dream.py", "module": "dream.model.tokenization_dream", "imports": ["json", "os", "unicodedata", "functools", "typing", "regex", "transformers.tokenization_utils", "transformers.utils"], "num_defs": 14, "num_imports": 8, "has_test_flag": false}
{"path": "dream/model/generation_utils_block.py", "module": "dream.model.generation_utils_block", "imports": ["warnings", "copy", "dataclasses", "typing", "torch", "torch.distributions", "torch.nn", "transformers", "transformers.generation.configuration_utils", "transformers.utils"], "num_defs": 17, "num_imports": 10, "has_test_flag": false}
{"path": "dream/model/configuration_dream.py", "module": "dream.model.configuration_dream", "imports": ["transformers.configuration_utils", "transformers.modeling_rope_utils", "transformers.utils"], "num_defs": 2, "num_imports": 3, "has_test_flag": false}
