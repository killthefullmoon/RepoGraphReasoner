{"repo_name": "Significant-Gravitas/AutoGPT", "stars": 179345, "language": "Python", "tasks": [{"task_title": "åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†", "task_description": "ä½¿ç”¨agentå‘½ä»¤æ¥åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†ã€‚", "example_code": null, "running_command": "cli.py agent", "expected_input": null, "expected_output": "æ‰§è¡Œä»£ç†ç›¸å…³çš„æ“ä½œ"}, {"task_title": "åŸºå‡†æµ‹è¯•", "task_description": "ä½¿ç”¨benchmarkå‘½ä»¤æ¥å¯åŠ¨åŸºå‡†æµ‹è¯•å¹¶åˆ—å‡ºæµ‹è¯•å’Œç±»åˆ«ã€‚", "example_code": null, "running_command": "cli.py benchmark", "expected_input": null, "expected_output": "åŸºå‡†æµ‹è¯•ç»“æœå’Œæµ‹è¯•ç±»åˆ«åˆ—è¡¨"}, {"task_title": "å®‰è£…ä¾èµ–", "task_description": "ä½¿ç”¨setupå‘½ä»¤æ¥å®‰è£…ç³»ç»Ÿæ‰€éœ€çš„ä¾èµ–ã€‚", "example_code": null, "running_command": "cli.py setup", "expected_input": null, "expected_output": "ä¾èµ–å®‰è£…å®Œæˆçš„ç¡®è®¤ä¿¡æ¯"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T22:53:16.778351"}
{"repo_name": "ytdl-org/youtube-dl", "stars": 138581, "language": "Python", "tasks": [{"task_title": "è·å–è§†é¢‘æ–‡ä»¶å", "task_description": "ä½¿ç”¨youtube-dlè·å–è§†é¢‘çš„æ–‡ä»¶åï¼Œæ”¯æŒç‰¹æ®Šå­—ç¬¦ã€‚", "example_code": null, "running_command": "youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl test video ''_Ã¤â†­ğ•.mp4"}, {"task_title": "é™åˆ¶æ–‡ä»¶åå­—ç¬¦", "task_description": "ä½¿ç”¨youtube-dlè·å–è§†é¢‘æ–‡ä»¶åï¼Œå¹¶é™åˆ¶æ–‡ä»¶åä¸­çš„å­—ç¬¦ã€‚", "example_code": null, "running_command": "youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc --restrict-filenames", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl_test_video_.mp4"}, {"task_title": "ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨", "task_description": "ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨ä¸­çš„è§†é¢‘ï¼Œå¹¶æŒ‰é¡ºåºä¿å­˜åˆ°ä¸åŒç›®å½•ã€‚", "example_code": null, "running_command": "youtube-dl -o '%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_input": "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_output": "ä¸‹è½½çš„æ–‡ä»¶æŒ‰é¡ºåºå­˜å‚¨åœ¨æŒ‡å®šç›®å½•"}, {"task_title": "ä¸‹è½½Udemyè¯¾ç¨‹", "task_description": "ä¸‹è½½Udemyè¯¾ç¨‹å¹¶å°†æ¯ä¸ªç« èŠ‚ä¿å­˜åœ¨ä¸åŒç›®å½•ä¸­ã€‚", "example_code": null, "running_command": "youtube-dl -u user -p password -o '~/MyVideos/%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s' https://www.udemy.com/java-tutorial/", "expected_input": "https://www.udemy.com/java-tutorial/", "expected_output": "ä¸‹è½½çš„è¯¾ç¨‹æ–‡ä»¶æŒ‰ç« èŠ‚å­˜å‚¨åœ¨æŒ‡å®šç›®å½•"}, {"task_title": "ä¸‹è½½ç³»åˆ—å‰§", "task_description": "ä¸‹è½½æ•´ä¸ªç³»åˆ—å­£ï¼Œå¹¶å°†æ¯ä¸ªå­£å’Œæ¯é›†ä¿å­˜åœ¨ä¸åŒç›®å½•ä¸­ã€‚", "example_code": null, "running_command": "youtube-dl -o 'C:/MyVideos/%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s' https://videomore.ru/kino_v_detalayah/5_sezon/367617", "expected_input": "https://videomore.ru/kino_v_detalayah/5_sezon/367617", "expected_output": "ä¸‹è½½çš„ç³»åˆ—å‰§æ–‡ä»¶æŒ‰å­£å’Œé›†å­˜å‚¨åœ¨æŒ‡å®šç›®å½•"}, {"task_title": "æµå¼ä¸‹è½½è§†é¢‘", "task_description": "å°†æ­£åœ¨ä¸‹è½½çš„è§†é¢‘æµå¼ä¼ è¾“åˆ°æ ‡å‡†è¾“å‡ºã€‚", "example_code": null, "running_command": "youtube-dl -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "è§†é¢‘æµè¾“å‡º"}, {"task_title": "ä¸‹è½½æœ€ä½³æ ¼å¼è§†é¢‘", "task_description": "ä¸‹è½½æœ€ä½³å¯ç”¨çš„MP4æ ¼å¼æˆ–å…¶ä»–æœ€ä½³æ ¼å¼ã€‚", "example_code": null, "running_command": "youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³æ ¼å¼è§†é¢‘æ–‡ä»¶"}, {"task_title": "ä¸‹è½½480pä»¥ä¸‹æœ€ä½³æ ¼å¼", "task_description": "ä¸‹è½½æœ€ä½³æ ¼å¼ï¼Œä½†ä¸é«˜äº480pã€‚", "example_code": null, "running_command": "youtube-dl -f 'bestvideo[height<=480]+bestaudio/best[height<=480]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€é«˜480pæ ¼å¼è§†é¢‘æ–‡ä»¶"}, {"task_title": "ä¸‹è½½ç‰¹å®šå¤§å°çš„è§†é¢‘", "task_description": "ä¸‹è½½æœ€ä½³è§†é¢‘æ ¼å¼ï¼Œä½†æ–‡ä»¶å¤§å°ä¸è¶…è¿‡50MBã€‚", "example_code": null, "running_command": "youtube-dl -f 'best[filesize<50M]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æ–‡ä»¶å¤§å°ä¸è¶…è¿‡50MB"}, {"task_title": "ä¸‹è½½æŒ‡å®šæ—¥æœŸåçš„è§†é¢‘", "task_description": "ä¸‹è½½åœ¨è¿‡å»6ä¸ªæœˆå†…ä¸Šä¼ çš„è§†é¢‘ã€‚", "example_code": null, "running_command": "youtube-dl --dateafter now-6months", "expected_input": null, "expected_output": "ä¸‹è½½çš„åœ¨è¿‡å»6ä¸ªæœˆå†…ä¸Šä¼ çš„è§†é¢‘"}, {"task_title": "ä¸‹è½½ç‰¹å®šæ—¥æœŸçš„è§†é¢‘", "task_description": "ä¸‹è½½åœ¨1970å¹´1æœˆ1æ—¥ä¸Šä¼ çš„è§†é¢‘ã€‚", "example_code": null, "running_command": "youtube-dl --date 19700101", "expected_input": null, "expected_output": "ä¸‹è½½çš„åœ¨1970å¹´1æœˆ1æ—¥ä¸Šä¼ çš„è§†é¢‘"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:53:45.120355"}
{"repo_name": "langflow-ai/langflow", "stars": 136412, "language": "Python", "tasks": [{"task_title": "è¿è¡ŒLangflow", "task_description": "ä½¿ç”¨Langflowå·¥å…·è¿è¡Œåº”ç”¨ç¨‹åº", "example_code": null, "running_command": "uv run langflow run", "expected_input": null, "expected_output": "å¯åŠ¨Langflowåº”ç”¨ç¨‹åº"}], "setup": {"setup_commands": ["uv pip install langflow -U"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T22:53:50.764372"}
{"repo_name": "yt-dlp/yt-dlp", "stars": 133008, "language": "Python", "tasks": [{"task_title": "Print filename with correct extension", "task_description": "ä½¿ç”¨æŒ‡å®šæ¨¡æ¿è¾“å‡ºæ–‡ä»¶åï¼Œè·å–è§†é¢‘çš„æ­£ç¡®æ‰©å±•åã€‚", "example_code": null, "running_command": "yt-dlp --print filename -o \"test video.%(ext)s\" BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "test video.webm"}, {"task_title": "Print filename with weird characters", "task_description": "ä½¿ç”¨è§†é¢‘æ ‡é¢˜ä½œä¸ºæ–‡ä»¶åï¼Œå¤„ç†å„ç§å­—ç¬¦ã€‚", "example_code": null, "running_command": "yt-dlp --print filename -o \"%((title)s.%(ext)s\" BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl test video ''_Ã¤â†­ğ•.webm"}, {"task_title": "Restrict filename characters", "task_description": "ä½¿ç”¨--restrict-filenamesé€‰é¡¹ï¼Œé™åˆ¶æ–‡ä»¶åä¸­çš„å­—ç¬¦ã€‚", "example_code": null, "running_command": "yt-dlp --print filename -o \"%((title)s.%(ext)s\" BaW_jenozKc --restrict-filenames", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl_test_video_.webm"}, {"task_title": "Download YouTube playlist videos in separate directory", "task_description": "ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨ä¸­çš„è§†é¢‘ï¼Œå¹¶æŒ‰æ’­æ”¾é¡ºåºåœ¨ä¸åŒç›®å½•ä¸­ä¿å­˜ã€‚", "example_code": null, "running_command": "yt-dlp -o \"%((playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\"", "expected_input": "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_output": "Downloaded videos sorted in directories."}, {"task_title": "Download Udemy course", "task_description": "ä¸‹è½½Udemyè¯¾ç¨‹ï¼ŒæŒ‰ç« èŠ‚åœ¨æŒ‡å®šç›®å½•ä¸‹ä¿å­˜ã€‚", "example_code": null, "running_command": "yt-dlp -u user -p password -P \"~/MyVideos\" -o \"%((playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s\" \"https://www.udemy.com/java-tutorial\"", "expected_input": "user, password, https://www.udemy.com/java-tutorial", "expected_output": "Downloaded Udemy course videos."}, {"task_title": "Download video with subtitles", "task_description": "ä¸‹è½½è§†é¢‘åŠå…¶å­—å¹•ï¼Œå¹¶å°†å…¶åˆ†åˆ«ä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚", "example_code": null, "running_command": "yt-dlp -P \"C:/MyVideos\" -P \"temp:tmp\" -P \"subtitle:subs\" -o \"%((uploader)s/%(title)s.%(ext)s\" BaW_jenozKc --write-subs", "expected_input": "BaW_jenozKc", "expected_output": "Downloaded video and subtitles."}, {"task_title": "Stream video to stdout", "task_description": "å°†ä¸‹è½½çš„è§†é¢‘æµè¾“å‡ºåˆ°æ ‡å‡†è¾“å‡ºã€‚", "example_code": null, "running_command": "yt-dlp -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "Streaming video data..."}, {"task_title": "Download best video and audio formats", "task_description": "ä¸‹è½½æœ€ä½³çš„è§†é¢‘å’ŒéŸ³é¢‘æ ¼å¼ï¼Œå¹¶åˆå¹¶å®ƒä»¬ã€‚", "example_code": null, "running_command": "yt-dlp -f \"bv+ba/b\"", "expected_input": "video URL", "expected_output": "Downloaded and merged best video and audio."}, {"task_title": "Download best format with specific codec", "task_description": "ä¸‹è½½å…·æœ‰ç‰¹å®šç¼–è§£ç å™¨çš„æœ€ä½³æ ¼å¼ã€‚", "example_code": null, "running_command": "yt-dlp -f \"(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)\"", "expected_input": "video URL", "expected_output": "Downloaded best video with specified codec."}, {"task_title": "Parse metadata", "task_description": "è§£æè§†é¢‘å…ƒæ•°æ®å¹¶æ ¼å¼åŒ–ã€‚", "example_code": null, "running_command": "yt-dlp --parse-metadata \"title:%(artist)s - %(title)s\"", "expected_input": "video URL", "expected_output": "Formatted metadata output."}, {"task_title": "Download with custom logger", "task_description": "ä½¿ç”¨è‡ªå®šä¹‰æ—¥å¿—è®°å½•å™¨ä¸‹è½½è§†é¢‘ã€‚", "example_code": null, "running_command": "yt-dlp -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "Logging download progress..."}, {"task_title": "Use custom post-processor", "task_description": "ä½¿ç”¨è‡ªå®šä¹‰åå¤„ç†å™¨å¤„ç†ä¸‹è½½çš„è§†é¢‘ã€‚", "example_code": null, "running_command": "yt-dlp -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "Custom post-processing completed."}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:54:10.901417"}
{"repo_name": "deepseek-ai/DeepSeek-V3", "stars": 100031, "language": "Python", "tasks": [{"task_title": "FP8æƒé‡è½¬æ¢ä¸ºBF16", "task_description": "æ­¤ä»»åŠ¡å°†FP8æ ¼å¼çš„æƒé‡æ–‡ä»¶è½¬æ¢ä¸ºBF16æ ¼å¼ï¼Œä½¿ç”¨äº†æ·±åº¦å­¦ä¹ æ¨¡å‹æƒé‡è½¬æ¢çš„åŠŸèƒ½ã€‚", "example_code": null, "running_command": "python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights", "expected_input": "/path/to/fp8_weights, /path/to/bf16_weights", "expected_output": "è½¬æ¢å®Œæˆçš„BF16æƒé‡æ–‡ä»¶"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:54:22.168603"}
{"repo_name": "nvbn/thefuck", "stars": 94501, "language": "Python", "tasks": [{"task_title": "Fix Git Push Error", "task_description": "Automatically suggests the correct command to push the current branch and set the remote as upstream.", "example_code": null, "running_command": "fuck", "expected_input": "git push", "expected_output": "git push --set-upstream origin master"}, {"task_title": "Fix Misspelled Command", "task_description": "Suggests the correct command when a misspelled command is entered.", "example_code": null, "running_command": "fuck", "expected_input": "puthon", "expected_output": "python"}, {"task_title": "Fix Incorrect Git Command", "task_description": "Suggests the correct git command when an incorrect command is entered.", "example_code": null, "running_command": "fuck", "expected_input": "git brnch", "expected_output": "git branch"}, {"task_title": "Fix Lein Command Error", "task_description": "Suggests the correct Lein command when an unrecognized task is entered.", "example_code": null, "running_command": "fuck", "expected_input": "lein rpl", "expected_output": "lein repl"}, {"task_title": "Enable Experimental Instant Mode", "task_description": "Enables experimental instant mode for thefuck.", "example_code": null, "running_command": "eval $(thefuck --alias --enable-experimental-instant-mode)", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["âœ apt-get install vim\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\nâœ fuck\nsudo apt-get install vim [enter/â†‘/â†“/ctrl+c]\n[sudo] password for nvbn:\nReading package lists... Done\n...", "âœ apt-get install vim\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\nâœ fuck\nsudo apt-get install vim\n[sudo] password for nvbn:\nReading package lists... Done\n...", "brew install thefuck", "pip install thefuck"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:54:31.683805"}
{"repo_name": "comfyanonymous/ComfyUI", "stars": 92190, "language": "Python", "tasks": [{"task_title": "Run ComfyUI for AMD GPUs", "task_description": "è¿è¡ŒComfyUIä»¥æ”¯æŒAMDæ˜¾å¡ï¼Œç‰¹åˆ«æ˜¯ROCmæœªæ­£å¼æ”¯æŒçš„å¡ã€‚", "example_code": null, "running_command": "HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py", "expected_input": null, "expected_output": null}, {"task_title": "Run ComfyUI for RDNA3 AMD GPUs", "task_description": "ä¸ºAMD 7600åŠå…¶ä»–RDNA3æ˜¾å¡è¿è¡ŒComfyUIã€‚", "example_code": null, "running_command": "HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["pip install comfy-cli\ncomfy install"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:54:43.542623"}
{"repo_name": "fastapi/fastapi", "stars": 91264, "language": "Python", "tasks": [{"task_title": "è¯»å–æ ¹è·¯å¾„", "task_description": "åˆ›å»ºä¸€ä¸ªFastAPIåº”ç”¨å¹¶å®šä¹‰ä¸€ä¸ªæ ¹è·¯å¾„çš„GETè¯·æ±‚å¤„ç†å‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªç®€å•çš„JSONå“åº”ã€‚", "example_code": "from typing import Union\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}", "running_command": null, "expected_input": null, "expected_output": "{\"Hello\": \"World\"}"}, {"task_title": "è¯»å–ç‰¹å®šé¡¹", "task_description": "å®šä¹‰ä¸€ä¸ªGETè¯·æ±‚å¤„ç†å‡½æ•°ï¼Œç”¨äºæ ¹æ®item_idä»è·¯å¾„ä¸­æå–å‚æ•°ï¼Œå¹¶å¯é€‰åœ°æ¥æ”¶æŸ¥è¯¢å‚æ•°qï¼Œè¿”å›è¿™äº›å‚æ•°çš„JSONå“åº”ã€‚", "example_code": "from typing import Union\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q}", "running_command": null, "expected_input": {"item_id": 1, "q": "example"}, "expected_output": "{\"item_id\": 1, \"q\": \"example\"}"}, {"task_title": "å¼‚æ­¥è¯»å–æ ¹è·¯å¾„", "task_description": "ä½¿ç”¨å¼‚æ­¥å‡½æ•°å®šä¹‰æ ¹è·¯å¾„çš„GETè¯·æ±‚å¤„ç†ï¼Œè¿”å›ç›¸åŒçš„JSONå“åº”ã€‚", "example_code": "from typing import Union\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"Hello\": \"World\"}", "running_command": null, "expected_input": null, "expected_output": "{\"Hello\": \"World\"}"}, {"task_title": "å¼‚æ­¥è¯»å–ç‰¹å®šé¡¹", "task_description": "ä½¿ç”¨å¼‚æ­¥å‡½æ•°å®šä¹‰GETè¯·æ±‚å¤„ç†ï¼Œç”¨äºæ ¹æ®item_idå’Œå¯é€‰æŸ¥è¯¢å‚æ•°qè¿”å›JSONå“åº”ã€‚", "example_code": "from typing import Union\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q}", "running_command": null, "expected_input": {"item_id": 2, "q": "test"}, "expected_output": "{\"item_id\": 2, \"q\": \"test\"}"}], "setup": {"setup_commands": ["$ pip install \"fastapi[standard]\"\n\n---> 100%"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:54:55.227610"}
{"repo_name": "openai/whisper", "stars": 90052, "language": "Python", "tasks": [{"task_title": "Transcribe audio to text", "task_description": "ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹å°†éŸ³é¢‘æ–‡ä»¶è½¬å½•ä¸ºæ–‡æœ¬ã€‚", "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\nresult = model.transcribe(\"audio.mp3\")\nprint(result[\"text\"])", "running_command": null, "expected_input": "audio.mp3", "expected_output": "Transcribed text from the audio"}, {"task_title": "Detect spoken language", "task_description": "åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶è¯†åˆ«æ‰€è¯´çš„è¯­è¨€ã€‚", "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\naudio = whisper.load_audio(\"audio.mp3\")\naudio = whisper.pad_or_trim(audio)\nmel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")", "running_command": null, "expected_input": "audio.mp3", "expected_output": "Detected language: <language>"}, {"task_title": "Translate audio to text", "task_description": "ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹å’Œè¯­è¨€é€‰é¡¹å°†éŸ³é¢‘æ–‡ä»¶ç¿»è¯‘æˆæ–‡æœ¬ã€‚", "example_code": null, "running_command": "whisper japanese.wav --model medium --language Japanese --task translate", "expected_input": "japanese.wav", "expected_output": "Translated text from the audio"}, {"task_title": "Specify language for transcription", "task_description": "æŒ‡å®šéŸ³é¢‘æ–‡ä»¶çš„è¯­è¨€è¿›è¡Œè½¬å½•ã€‚", "example_code": null, "running_command": "whisper japanese.wav --language Japanese", "expected_input": "japanese.wav", "expected_output": "Transcribed text from the audio"}, {"task_title": "Display help information", "task_description": "æ˜¾ç¤ºå‘½ä»¤è¡Œå·¥å…·çš„å¸®åŠ©ä¿¡æ¯ã€‚", "example_code": null, "running_command": "whisper --help", "expected_input": null, "expected_output": "Help information for the whisper CLI"}], "setup": {"setup_commands": ["# on Ubuntu or Debian\nsudo apt update && sudo apt install ffmpeg\n\n# on Arch Linux\nsudo pacman -S ffmpeg\n\n# on MacOS using Homebrew (https://brew.sh/)\nbrew install ffmpeg\n\n# on Windows using Chocolatey (https://chocolatey.org/)\nchoco install ffmpeg\n\n# on Windows using Scoop (https://scoop.sh/)\nscoop install ffmpeg", "pip install setuptools-rust"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:55:06.917265"}
{"repo_name": "microsoft/markitdown", "stars": 82211, "language": "Python", "tasks": [{"task_title": "Convert PDF to Markdown", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„æ–‡æ¡£ã€‚", "example_code": null, "running_command": "markitdown path-to-file.pdf > document.md", "expected_input": "path-to-file.pdf", "expected_output": "document.mdå†…å®¹"}, {"task_title": "Convert PDF to Markdown with Output File", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownå¹¶æŒ‡å®šè¾“å‡ºæ–‡ä»¶ã€‚", "example_code": null, "running_command": "markitdown path-to-file.pdf -o document.md", "expected_input": "path-to-file.pdf", "expected_output": "document.mdå†…å®¹"}, {"task_title": "Convert PDF from Standard Input", "task_description": "é€šè¿‡æ ‡å‡†è¾“å…¥å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ã€‚", "example_code": null, "running_command": "cat path-to-file.pdf | markitdown", "expected_input": "path-to-file.pdf", "expected_output": "Markdownå†…å®¹"}, {"task_title": "List Available Plugins", "task_description": "åˆ—å‡ºå¯ç”¨çš„æ’ä»¶ã€‚", "example_code": null, "running_command": "markitdown --list-plugins", "expected_input": null, "expected_output": "å¯ç”¨æ’ä»¶åˆ—è¡¨"}, {"task_title": "Use Plugins for Conversion", "task_description": "åœ¨è½¬æ¢è¿‡ç¨‹ä¸­ä½¿ç”¨æ’ä»¶ã€‚", "example_code": null, "running_command": "markitdown --use-plugins path-to-file.pdf", "expected_input": "path-to-file.pdf", "expected_output": "Markdownå†…å®¹ï¼ˆä½¿ç”¨æ’ä»¶å¤„ç†ï¼‰"}, {"task_title": "Convert PDF with Document Intelligence", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownï¼Œå¹¶æŒ‡å®šæ–‡æ¡£æ™ºèƒ½ç«¯ç‚¹ã€‚", "example_code": null, "running_command": "markitdown path-to-file.pdf -o document.md -d -e \"<document_intelligence_endpoint>\"", "expected_input": "path-to-file.pdf, <document_intelligence_endpoint>", "expected_output": "document.mdå†…å®¹"}, {"task_title": "Convert Excel to Markdown without Plugins", "task_description": "å°†Excelæ–‡ä»¶è½¬æ¢ä¸ºMarkdownï¼Œä¸å¯ç”¨æ’ä»¶ã€‚", "example_code": "from markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False)\nresult = md.convert(\"test.xlsx\")\nprint(result.text_content)", "running_command": null, "expected_input": "test.xlsx", "expected_output": "Markdownå†…å®¹"}, {"task_title": "Convert PDF with Document Intelligence Endpoint", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownï¼Œå¹¶æŒ‡å®šæ–‡æ¡£æ™ºèƒ½ç«¯ç‚¹ã€‚", "example_code": "from markitdown import MarkItDown\n\nmd = MarkItDown(docintel_endpoint=\"<document_intelligence_endpoint>\")\nresult = md.convert(\"test.pdf\")\nprint(result.text_content)", "running_command": null, "expected_input": "test.pdf, <document_intelligence_endpoint>", "expected_output": "Markdownå†…å®¹"}, {"task_title": "Convert Image to Markdown with LLM Integration", "task_description": "å°†å›¾åƒæ–‡ä»¶è½¬æ¢ä¸ºMarkdownï¼Œå¹¶é›†æˆLLMå®¢æˆ·ç«¯ã€‚", "example_code": "from markitdown import MarkItDown\nfrom openai import OpenAI\n\nclient = OpenAI()\nmd = MarkItDown(llm_client=client, llm_model=\"gpt-4o\", llm_prompt=\"optional custom prompt\")\nresult = md.convert(\"example.jpg\")\nprint(result.text_content)", "running_command": null, "expected_input": "example.jpg", "expected_output": "Markdownå†…å®¹"}], "setup": {"setup_commands": ["python -m venv .venv\nsource .venv/bin/activate", "uv venv --python=3.12 .venv\nsource .venv/bin/activate\n# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment", "conda create -n markitdown python=3.12\nconda activate markitdown", "git clone git@github.com:microsoft/markitdown.git\ncd markitdown\npip install -e 'packages/markitdown[all]'", "pip install 'markitdown[pdf, docx, pptx]'", "  pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/\n  hatch shell\n  hatch test"], "docker_commands": ["docker build -t markitdown:latest .\ndocker run --rm -i markitdown:latest < ~/your-file.pdf > output.md"], "has_docker_files": true}, "timestamp": "2025-10-28T22:55:30.151734"}
{"repo_name": "3b1b/manim", "stars": 81503, "language": "Python", "tasks": [{"task_title": "Opening Manim Example", "task_description": "This task demonstrates how to run a simple Manim scene using the 'OpeningManimExample' class defined in the 'example_scenes.py' file.", "example_code": null, "running_command": "manimgl example_scenes.py OpeningManimExample", "expected_input": null, "expected_output": "A rendered animation of the Opening Manim Example scene."}], "setup": {"setup_commands": ["# Install manimgl\npip install manimgl\n\n# Try it out\nmanimgl", "# Install manimgl\npip install -e .\n\n# Try it out\nmanimgl example_scenes.py OpeningManimExample\n# or\nmanim-render example_scenes.py OpeningManimExample", "    git clone https://github.com/3b1b/manim.git\n    cd manim\n    pip install -e .\n    manimgl example_scenes.py OpeningManimExample", "    brew install ffmpeg mactex", "    arch -arm64 brew install pkg-config cairo", "    git clone https://github.com/3b1b/manim.git\n    cd manim\n    pip install -e .\n    manimgl example_scenes.py OpeningManimExample (make sure to add manimgl to path first.)"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:55:36.347261"}
{"repo_name": "hacksider/Deep-Live-Cam", "stars": 74220, "language": "Python", "tasks": [{"task_title": "ä½¿ç”¨CUDAæ‰§è¡Œ", "task_description": "ä½¿ç”¨CUDAä½œä¸ºæ‰§è¡Œæä¾›è€…è¿è¡ŒDeep-Live-Camã€‚", "example_code": null, "running_command": "python run.py --execution-provider cuda", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨CoreMLæ‰§è¡Œ", "task_description": "ä½¿ç”¨CoreMLä½œä¸ºæ‰§è¡Œæä¾›è€…è¿è¡ŒDeep-Live-Camã€‚", "example_code": null, "running_command": "python3.10 run.py --execution-provider coreml", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨CoreMLæ‰§è¡Œ", "task_description": "å†æ¬¡ä½¿ç”¨CoreMLä½œä¸ºæ‰§è¡Œæä¾›è€…è¿è¡ŒDeep-Live-Camã€‚", "example_code": null, "running_command": "python run.py --execution-provider coreml", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨DirectMLæ‰§è¡Œ", "task_description": "ä½¿ç”¨DirectMLä½œä¸ºæ‰§è¡Œæä¾›è€…è¿è¡ŒDeep-Live-Camã€‚", "example_code": null, "running_command": "python run.py --execution-provider directml", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨OpenVINOæ‰§è¡Œ", "task_description": "ä½¿ç”¨OpenVINOä½œä¸ºæ‰§è¡Œæä¾›è€…è¿è¡ŒDeep-Live-Camã€‚", "example_code": null, "running_command": "python run.py --execution-provider openvino", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["git clone https://github.com/hacksider/Deep-Live-Cam.git\ncd Deep-Live-Cam", "python -m venv venv\nvenv\\Scripts\\activate\npip install -r requirements.txt", "# Ensure you use the installed Python 3.10\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt", "# Install Python 3.11 (specific version is important)\nbrew install python@3.11\n\n# Install tkinter package (required for the GUI)\nbrew install python-tk@3.10\n\n# Create and activate virtual environment with Python 3.11\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt", "# Deactivate the virtual environment\nrm -rf venv\n\n# Reinstall the virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# install the dependencies again\npip install -r requirements.txt\n\n# gfpgan and basicsrs issue fix\npip install git+https://github.com/xinntao/BasicSR.git@master\npip uninstall gfpgan -y\npip install git+https://github.com/TencentARC/GFPGAN.git@master", "pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\npip uninstall onnxruntime onnxruntime-gpu\npip install onnxruntime-gpu==1.21.0", "pip uninstall onnxruntime onnxruntime-silicon\npip install onnxruntime-silicon==1.13.1", "pip uninstall onnxruntime onnxruntime-coreml\npip install onnxruntime-coreml==1.21.0", "pip uninstall onnxruntime onnxruntime-directml\npip install onnxruntime-directml==1.21.0", "pip uninstall onnxruntime onnxruntime-openvino\npip install onnxruntime-openvino==1.21.0"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:55:54.752654"}
{"repo_name": "browser-use/browser-use", "stars": 71871, "language": "Python", "tasks": [{"task_title": "åˆå§‹åŒ–é¡¹ç›®", "task_description": "ä½¿ç”¨CLIå‘½ä»¤åˆå§‹åŒ–é¡¹ç›®ï¼Œè®¾ç½®é»˜è®¤æ¨¡æ¿ã€‚", "example_code": null, "running_command": "uvx browser-use init --template default", "expected_input": null, "expected_output": null}, {"task_title": "åˆå§‹åŒ–é¡¹ç›®å¹¶æŒ‡å®šè¾“å‡ºæ–‡ä»¶", "task_description": "ä½¿ç”¨CLIå‘½ä»¤åˆå§‹åŒ–é¡¹ç›®ï¼Œè®¾ç½®é»˜è®¤æ¨¡æ¿å¹¶æŒ‡å®šè¾“å‡ºæ–‡ä»¶åã€‚", "example_code": null, "running_command": "uvx browser-use init --template default --output my_agent.py", "expected_input": null, "expected_output": null}, {"task_title": "å®‰è£…æµè§ˆå™¨ä½¿ç”¨åº“", "task_description": "ä½¿ç”¨CLIå‘½ä»¤æ·»åŠ æµè§ˆå™¨ä½¿ç”¨åº“åˆ°é¡¹ç›®ä¸­å¹¶åŒæ­¥ã€‚", "example_code": null, "running_command": "uv add browser-use\nuv sync", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨AgentæŸ¥æ‰¾GitHubä»“åº“æ˜Ÿæ ‡æ•°", "task_description": "åˆ›å»ºä¸€ä¸ªAgentæ¥æŸ¥æ‰¾æŒ‡å®šGitHubä»“åº“çš„æ˜Ÿæ ‡æ•°é‡ï¼Œä½¿ç”¨ChatBrowserUseå’ŒBrowserã€‚", "example_code": "from browser_use import Agent, Browser, ChatBrowserUse\nimport asyncio\n\nasync def example():\n    browser = Browser()\n    llm = ChatBrowserUse()\n    agent = Agent(\n        task=\"Find the number of stars of the browser-use repo\",\n        llm=llm,\n        browser=browser,\n    )\n    history = await agent.run()\n    return history\n\nif __name__ == \"__main__\":\n    history = asyncio.run(example())", "running_command": null, "expected_input": null, "expected_output": "å†å²è®°å½•åŒ…å«æ˜Ÿæ ‡æ•°é‡"}, {"task_title": "è‡ªå®šä¹‰å·¥å…·", "task_description": "å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰å·¥å…·ï¼Œå¹¶åœ¨Agentä¸­ä½¿ç”¨è¯¥å·¥å…·æ‰§è¡Œä»»åŠ¡ã€‚", "example_code": "from browser_use.tools import Tool\n\n@Tool()\ndef custom_tool(param: str) -> str:\n    \"\"\"Description of what this tool does.\"\"\"\n    return f\"Result: {param}\"\n\nagent = Agent(\n    task=\"Your task\",\n    llm=llm,\n    browser=browser,\n    use_custom_tools=[custom_tool],\n)", "running_command": null, "expected_input": "è‡ªå®šä¹‰å·¥å…·çš„å‚æ•°", "expected_output": "Result: è‡ªå®šä¹‰å·¥å…·çš„å‚æ•°"}, {"task_title": "å®‰è£…æµè§ˆå™¨ä½¿ç”¨åº“ï¼ˆç®€åŒ–å‘½ä»¤ï¼‰", "task_description": "ä½¿ç”¨CLIå‘½ä»¤å¿«é€Ÿå®‰è£…æµè§ˆå™¨ä½¿ç”¨åº“ã€‚", "example_code": null, "running_command": "uvx browser-use install", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T22:56:14.307299"}
{"repo_name": "pallets/flask", "stars": 70671, "language": "Python", "tasks": [{"task_title": "åˆ›å»ºåŸºæœ¬çš„Flaskåº”ç”¨", "task_description": "åˆ›å»ºä¸€ä¸ªç®€å•çš„Flaskåº”ç”¨ï¼Œå¹¶å®šä¹‰ä¸€ä¸ªè·¯ç”±ä»¥è¿”å›'Hello, World!'", "example_code": "from flask import Flask\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return \"Hello, World!\"", "running_command": null, "expected_input": null, "expected_output": "Hello, World!"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:56:30.239018"}
{"repo_name": "sherlock-project/sherlock", "stars": 69905, "language": "Python", "tasks": [{"task_title": "æ£€æŸ¥å•ä¸ªç”¨æˆ·å", "task_description": "ä½¿ç”¨Sherlockæ£€æŸ¥ä¸€ä¸ªç¤¾äº¤ç½‘ç»œä¸Šçš„ç”¨æˆ·åæ˜¯å¦å­˜åœ¨ã€‚", "example_code": null, "running_command": "sherlock user123", "expected_input": "user123", "expected_output": "[{ \"username\": \"user123\", \"links\": [\"https://www.example.com/user/user123/\"] }] "}, {"task_title": "æ£€æŸ¥å¤šä¸ªç”¨æˆ·å", "task_description": "ä½¿ç”¨Sherlockæ£€æŸ¥å¤šä¸ªç¤¾äº¤ç½‘ç»œä¸Šçš„ç”¨æˆ·åæ˜¯å¦å­˜åœ¨ã€‚", "example_code": null, "running_command": "sherlock user1 user2 user3", "expected_input": "user1 user2 user3", "expected_output": "[{ \"username\": \"user1\", \"links\": [...] }, { \"username\": \"user2\", \"links\": [...] }, { \"username\": \"user3\", \"links\": [...] }] "}, {"task_title": "æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯", "task_description": "æ˜¾ç¤ºSherlockçš„å¸®åŠ©ä¿¡æ¯å’Œå¯ç”¨å‘½ä»¤é€‰é¡¹ã€‚", "example_code": null, "running_command": "sherlock --help", "expected_input": null, "expected_output": "usage: sherlock [-h] [--version] [--verbose] ..."}, {"task_title": "ä½¿ç”¨JSONè¾“å…¥", "task_description": "é€šè¿‡Apifyè°ƒç”¨Sherlockï¼Œä½¿ç”¨JSONæ ¼å¼çš„è¾“å…¥æ•°æ®æ¥æ£€æŸ¥ç”¨æˆ·åã€‚", "example_code": null, "running_command": "echo '{\"usernames\":[\"user123\"]}' | apify call -so netmilk/sherlock", "expected_input": "{\"usernames\":[\"user123\"]}", "expected_output": "[{ \"username\": \"user123\", \"links\": [\"https://www.1337x.to/user/user123/\"] }] "}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T22:56:44.953550"}
{"repo_name": "xtekky/gpt4free", "stars": 65454, "language": "Python", "tasks": [{"task_title": "Run GUI", "task_description": "å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ˆGUIï¼‰ä»¥ä¾¿ä¸æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚", "example_code": "from g4f.gui import run_gui\nrun_gui()", "running_command": null, "expected_input": null, "expected_output": "å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢"}, {"task_title": "Run CLI GUI", "task_description": "é€šè¿‡å‘½ä»¤è¡Œæ¥å£å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ŒæŒ‡å®šç«¯å£å’Œè°ƒè¯•æ¨¡å¼ã€‚", "example_code": null, "running_command": "python -m g4f.cli gui --port 8080 --debug", "expected_input": null, "expected_output": "å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢"}, {"task_title": "Run CLI", "task_description": "é€šè¿‡å‘½ä»¤è¡Œæ¥å£å¯åŠ¨æœåŠ¡ï¼ŒæŒ‡å®šç«¯å£å’Œè°ƒè¯•æ¨¡å¼ã€‚", "example_code": null, "running_command": "python -m g4f --port 8080 --debug", "expected_input": null, "expected_output": "å¯åŠ¨æœåŠ¡"}, {"task_title": "Chat Completion", "task_description": "ä½¿ç”¨å®¢æˆ·ç«¯ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œç”Ÿæˆå›å¤ã€‚", "example_code": "from g4f.client import Client\n\nclient = Client()\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n    web_search=False\n)\nprint(response.choices[0].message.content)", "running_command": null, "expected_input": "Hello, how are you?", "expected_output": "æ¨¡å‹çš„å›å¤å†…å®¹"}, {"task_title": "Image Generation", "task_description": "ä½¿ç”¨å®¢æˆ·ç«¯ç”Ÿæˆå›¾åƒï¼Œè¿”å›ç”Ÿæˆçš„å›¾åƒURLã€‚", "example_code": "from g4f.client import Client\n\nclient = Client()\nresponse = client.images.generate(\n    model=\"flux\",\n    prompt=\"a white siamese cat\",\n    response_format=\"url\"\n)\nprint(f\"Generated image URL: {response.data[0].url}\")", "running_command": null, "expected_input": "a white siamese cat", "expected_output": "ç”Ÿæˆçš„å›¾åƒURL"}, {"task_title": "Async Chat Completion", "task_description": "ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œç”Ÿæˆå›å¤ã€‚", "example_code": "from g4f.client import AsyncClient\nimport asyncio\n\nasync def main():\n    client = AsyncClient()\n    response = await client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": \"Explain quantum computing briefly\"}],\n    )\n    print(response.choices[0].message.content)\n\nasyncio.run(main())", "running_command": null, "expected_input": "Explain quantum computing briefly", "expected_output": "æ¨¡å‹çš„å›å¤å†…å®¹"}], "setup": {"setup_commands": ["pip install -U g4f[all]", "git clone https://github.com/xtekky/gpt4free.git\ncd gpt4free\npip install -r requirements.txt\npip install -e .", "pip install -U g4f[all]"], "docker_commands": ["   docker pull hlohaus789/g4f", "   docker run -p 8080:8080 -p 7900:7900 \\\n     --shm-size=\"2g\" \\\n     -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n     -v ${PWD}/generated_media:/app/generated_media \\\n     hlohaus789/g4f:latest", "mkdir -p ${PWD}/har_and_cookies ${PWD}/generated_media\nchown -R 1000:1000 ${PWD}/har_and_cookies ${PWD}/generated_media\n\ndocker run \\\n  -p 1337:8080 -p 8080:8080 \\\n  -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n  -v ${PWD}/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest-slim"], "has_docker_files": true}, "timestamp": "2025-10-28T22:57:07.290044"}
{"repo_name": "OpenHands/OpenHands", "stars": 64533, "language": "Python", "tasks": [{"task_title": "Launch the GUI server", "task_description": "ä½¿ç”¨OpenHandsåº“å¯åŠ¨GUIæœåŠ¡å™¨ã€‚", "example_code": null, "running_command": "uvx --python 3.12 --from openhands-ai openhands serve", "expected_input": null, "expected_output": "GUI server is running"}, {"task_title": "Launch the CLI", "task_description": "ä½¿ç”¨OpenHandsåº“å¯åŠ¨å‘½ä»¤è¡Œç•Œé¢ã€‚", "example_code": null, "running_command": "uvx --python 3.12 --from openhands-ai openhands", "expected_input": null, "expected_output": "CLI is running"}], "setup": {"setup_commands": [], "docker_commands": ["docker pull docker.all-hands.dev/all-hands-ai/runtime:0.59-nikolaik\n\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.59-nikolaik \\\n    -e LOG_ALL_EVENTS=true \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands:/.openhands \\\n    -p 3000:3000 \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.59"], "has_docker_files": true}, "timestamp": "2025-10-28T22:57:14.035480"}
{"repo_name": "PaddlePaddle/PaddleOCR", "stars": 61777, "language": "Python", "tasks": [{"task_title": "Run PP-OCRv5 inference", "task_description": "ä½¿ç”¨PP-OCRv5æ¨¡å‹è¿›è¡ŒOCRæ¨ç†ï¼Œå¤„ç†ç»™å®šçš„å›¾åƒURLï¼Œå¹¶ç¦ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»å’Œæ–‡æ¡£å»ç•¸å˜åŠŸèƒ½ã€‚", "example_code": null, "running_command": "paddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png", "expected_output": "OCRç»“æœ"}, {"task_title": "Run PP-StructureV3 inference", "task_description": "ä½¿ç”¨PP-StructureV3æ¨¡å‹è¿›è¡Œç»“æ„åŒ–æ–‡æ¡£æ¨ç†ï¼Œå¤„ç†ç»™å®šçš„å›¾åƒURLï¼Œå¹¶ç¦ç”¨æ–‡æ¡£æ–¹å‘åˆ†ç±»å’Œæ–‡æ¡£å»ç•¸å˜åŠŸèƒ½ã€‚", "example_code": null, "running_command": "paddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png", "expected_output": "ç»“æ„åŒ–æ–‡æ¡£ç»“æœ"}, {"task_title": "Run PP-ChatOCRv4 inference", "task_description": "ä½¿ç”¨PP-ChatOCRv4æ¨¡å‹è¿›è¡ŒOCRæ¨ç†ï¼Œå¤„ç†ç»™å®šçš„å›¾åƒURLï¼Œæå–ç‰¹å®šä¿¡æ¯ï¼Œå¹¶ä½¿ç”¨Qianfan API Keyè¿›è¡Œè¯·æ±‚ã€‚", "example_code": null, "running_command": "paddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k é©¾é©¶å®¤å‡†ä¹˜äººæ•° --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png", "expected_output": "æå–çš„é©¾é©¶å®¤å‡†ä¹˜äººæ•°"}, {"task_title": "Run PaddleOCR-VL inference", "task_description": "ä½¿ç”¨PaddleOCR-VLæ¨¡å‹è¿›è¡Œæ–‡æ¡£è§£æï¼Œå¤„ç†ç»™å®šçš„å›¾åƒURLã€‚", "example_code": null, "running_command": "paddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png", "expected_output": "æ–‡æ¡£è§£æç»“æœ"}, {"task_title": "Initialize PaddleOCR instance and run inference", "task_description": "åˆå§‹åŒ–PaddleOCRå®ä¾‹ï¼Œä½¿ç”¨ç»™å®šçš„å›¾åƒURLè¿›è¡ŒOCRæ¨ç†ï¼Œå¹¶å°†ç»“æœå¯è§†åŒ–å’Œä¿å­˜ã€‚", "example_code": "from paddleocr import PaddleOCR\nocr = PaddleOCR(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False,\n    use_textline_orientation=False)\nresult = ocr.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png\")\nfor res in result:\n    res.print()\n    res.save_to_img(\"output\")\n    res.save_to_json(\"output\")", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png", "expected_output": "OCRç»“æœå¯è§†åŒ–å’ŒJSONè¾“å‡º"}, {"task_title": "Run PPStructureV3 and save results", "task_description": "åˆå§‹åŒ–PPStructureV3å®ä¾‹ï¼Œä½¿ç”¨ç»™å®šçš„å›¾åƒURLè¿›è¡Œæ¨ç†ï¼Œå¹¶å°†ç»“æœå¯è§†åŒ–å’Œä¿å­˜ä¸ºJSONå’ŒMarkdownæ ¼å¼ã€‚", "example_code": "from paddleocr import PPStructureV3\npipeline = PPStructureV3(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\noutput = pipeline.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png\",\n)\nfor res in output:\n    res.print() \n    res.save_to_json(save_path=\"output\") \n    res.save_to_markdown(save_path=\"output\")", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png", "expected_output": "ç»“æ„åŒ–ç»“æœå¯è§†åŒ–å’Œä¿å­˜"}, {"task_title": "Run PPChatOCRv4Doc with multimodal support", "task_description": "åˆå§‹åŒ–PPChatOCRv4Docå®ä¾‹ï¼Œä½¿ç”¨ç»™å®šçš„å›¾åƒURLè¿›è¡Œæ¨ç†ï¼Œæ”¯æŒå¤šæ¨¡æ€å¤§æ¨¡å‹å¹¶è¿›è¡ŒèŠå¤©åŠŸèƒ½ã€‚", "example_code": "from paddleocr import PPChatOCRv4Doc\npipeline = PPChatOCRv4Doc(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\nvisual_predict_res = pipeline.visual_predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n    use_common_ocr=True,\n    use_seal_recognition=True,\n    use_table_recognition=True,\n)\nchat_result = pipeline.chat(\n    key_list=[\"é©¾é©¶å®¤å‡†ä¹˜äººæ•°\"],\n    visual_info=visual_info_list,\n    vector_info=vector_info,\n    mllm_predict_info=mllm_predict_info,\n    chat_bot_config=chat_bot_config,\n    retriever_config=retriever_config,\n)\nprint(chat_result)", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png", "expected_output": "èŠå¤©ç»“æœ"}, {"task_title": "Run PaddleOCRVL inference", "task_description": "ä½¿ç”¨PaddleOCR-VLæ¨¡å‹è¿›è¡Œè§†è§‰æ¨ç†ï¼Œå¤„ç†ç»™å®šçš„å›¾åƒURLï¼Œå¹¶å°†ç»“æœå¯è§†åŒ–å’Œä¿å­˜ã€‚", "example_code": "from paddleocr import PaddleOCRVL\npipeline = PaddleOCRVL()\noutput = pipeline.predict(\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\")\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"output\")\n    res.save_to_markdown(save_path=\"output\")", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png", "expected_output": "è§†è§‰æ¨ç†ç»“æœå¯è§†åŒ–å’Œä¿å­˜"}], "setup": {"setup_commands": ["# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series\npython -m pip install paddleocr\n# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.\n# python -m pip install \"paddleocr[all]\""], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:57:50.907852"}
{"repo_name": "Significant-Gravitas/AutoGPT", "stars": 179345, "language": "Python", "tasks": [{"task_title": "åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†", "task_description": "ä½¿ç”¨agentå‘½ä»¤æ¥åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†ã€‚", "example_code": null, "running_command": "cli.py agent", "expected_input": null, "expected_output": null}, {"task_title": "åŸºå‡†æµ‹è¯•", "task_description": "ä½¿ç”¨benchmarkå‘½ä»¤æ¥å¯åŠ¨åŸºå‡†æµ‹è¯•å¹¶åˆ—å‡ºæµ‹è¯•å’Œç±»åˆ«ã€‚", "example_code": null, "running_command": "cli.py benchmark", "expected_input": null, "expected_output": null}, {"task_title": "å®‰è£…ä¾èµ–", "task_description": "ä½¿ç”¨setupå‘½ä»¤æ¥å®‰è£…ç³»ç»Ÿæ‰€éœ€çš„ä¾èµ–ã€‚", "example_code": null, "running_command": "cli.py setup", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T22:58:29.185006"}
{"repo_name": "Significant-Gravitas/AutoGPT", "stars": 179345, "language": "Python", "tasks": [{"task_title": "åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†", "task_description": "ä½¿ç”¨agentå‘½ä»¤æ¥åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†ã€‚", "example_code": null, "running_command": "cli.py agent", "expected_input": null, "expected_output": "ä»£ç†å·²åˆ›å»º/å¯åŠ¨/åœæ­¢"}, {"task_title": "åŸºå‡†æµ‹è¯•", "task_description": "ä½¿ç”¨benchmarkå‘½ä»¤æ¥å¯åŠ¨åŸºå‡†æµ‹è¯•ï¼Œå¹¶åˆ—å‡ºæµ‹è¯•å’Œç±»åˆ«ã€‚", "example_code": null, "running_command": "cli.py benchmark", "expected_input": null, "expected_output": "åŸºå‡†æµ‹è¯•å·²å¯åŠ¨ï¼Œæµ‹è¯•å’Œç±»åˆ«åˆ—è¡¨"}, {"task_title": "å®‰è£…ä¾èµ–", "task_description": "ä½¿ç”¨setupå‘½ä»¤æ¥å®‰è£…ç³»ç»Ÿæ‰€éœ€çš„ä¾èµ–ã€‚", "example_code": null, "running_command": "cli.py setup", "expected_input": null, "expected_output": "ä¾èµ–å·²å®‰è£…"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T22:59:21.212536"}
{"repo_name": "ytdl-org/youtube-dl", "stars": 138581, "language": "Python", "tasks": [{"task_title": "è·å–è§†é¢‘æ–‡ä»¶å", "task_description": "ä½¿ç”¨youtube-dlè·å–è§†é¢‘çš„æ–‡ä»¶åï¼Œæ”¯æŒç‰¹æ®Šå­—ç¬¦", "example_code": null, "running_command": "youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl test video ''_Ã¤â†­ğ•.mp4"}, {"task_title": "è·å–ç®€åŒ–æ–‡ä»¶å", "task_description": "ä½¿ç”¨youtube-dlè·å–è§†é¢‘çš„æ–‡ä»¶åï¼Œé™åˆ¶æ–‡ä»¶åä¸­çš„ç‰¹æ®Šå­—ç¬¦", "example_code": null, "running_command": "youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc --restrict-filenames", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl_test_video_.mp4"}, {"task_title": "ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨", "task_description": "ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨ä¸­çš„æ¯ä¸ªè§†é¢‘ï¼Œå¹¶æŒ‰æ’­æ”¾é¡ºåºä¿å­˜åˆ°å•ç‹¬çš„ç›®å½•", "example_code": null, "running_command": "youtube-dl -o '%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_input": "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_output": "ä¸‹è½½çš„æ¯ä¸ªè§†é¢‘æ–‡ä»¶æŒ‰é¡ºåºä¿å­˜"}, {"task_title": "ä¸‹è½½YouTubeé¢‘é“çš„æ‰€æœ‰æ’­æ”¾åˆ—è¡¨", "task_description": "ä¸‹è½½YouTubeé¢‘é“ä¸­æ‰€æœ‰æ’­æ”¾åˆ—è¡¨çš„è§†é¢‘ï¼Œå¹¶å°†æ¯ä¸ªæ’­æ”¾åˆ—è¡¨ä¿å­˜åˆ°å•ç‹¬çš„ç›®å½•", "example_code": null, "running_command": "youtube-dl -o '%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' https://www.youtube.com/user/TheLinuxFoundation/playlists", "expected_input": "https://www.youtube.com/user/TheLinuxFoundation/playlists", "expected_output": "ä¸‹è½½çš„æ¯ä¸ªè§†é¢‘æ–‡ä»¶æŒ‰æ’­æ”¾åˆ—è¡¨å’Œç´¢å¼•ä¿å­˜"}, {"task_title": "ä¸‹è½½Udemyè¯¾ç¨‹", "task_description": "ä¸‹è½½Udemyè¯¾ç¨‹ï¼Œå°†æ¯ä¸ªç« èŠ‚ä¿å­˜åˆ°æŒ‡å®šç›®å½•ä¸­", "example_code": null, "running_command": "youtube-dl -u user -p password -o '~/MyVideos/%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s' https://www.udemy.com/java-tutorial/", "expected_input": "https://www.udemy.com/java-tutorial/", "expected_output": "ä¸‹è½½çš„æ¯ä¸ªè§†é¢‘æ–‡ä»¶æŒ‰ç« èŠ‚ä¿å­˜"}, {"task_title": "ä¸‹è½½æ•´ä¸ªç³»åˆ—å­£", "task_description": "ä¸‹è½½è§†é¢‘ç³»åˆ—çš„æ¯ä¸€å­£ï¼Œå°†æ¯ä¸ªç³»åˆ—å’Œå­£èŠ‚ä¿å­˜åˆ°æŒ‡å®šç›®å½•ä¸­", "example_code": null, "running_command": "youtube-dl -o 'C:/MyVideos/%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s' https://videomore.ru/kino_v_detalayah/5_sezon/367617", "expected_input": "https://videomore.ru/kino_v_detalayah/5_sezon/367617", "expected_output": "ä¸‹è½½çš„æ¯ä¸ªè§†é¢‘æ–‡ä»¶æŒ‰ç³»åˆ—å’Œå­£èŠ‚ä¿å­˜"}, {"task_title": "å®æ—¶æµå¼ä¸‹è½½è§†é¢‘", "task_description": "å°†ä¸‹è½½çš„è§†é¢‘ç›´æ¥æµå¼è¾“å‡ºåˆ°æ ‡å‡†è¾“å‡º", "example_code": null, "running_command": "youtube-dl -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "è§†é¢‘æµæ•°æ®"}, {"task_title": "ä¸‹è½½æœ€ä½³mp4æ ¼å¼", "task_description": "ä¸‹è½½å¯ç”¨çš„æœ€ä½³mp4æ ¼å¼è§†é¢‘ï¼Œè‹¥æ²¡æœ‰mp4åˆ™ä¸‹è½½å…¶ä»–æœ€ä½³æ ¼å¼", "example_code": null, "running_command": "youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³mp4æ ¼å¼è§†é¢‘"}, {"task_title": "ä¸‹è½½480pä»¥ä¸‹çš„æœ€ä½³æ ¼å¼", "task_description": "ä¸‹è½½æœ€ä½³æ ¼å¼çš„è§†é¢‘ï¼Œä½†ä¸è¶…è¿‡480p", "example_code": null, "running_command": "youtube-dl -f 'bestvideo[height<=480]+bestaudio/best[height<=480]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³æ ¼å¼è§†é¢‘ï¼Œåˆ†è¾¨ç‡ä¸è¶…è¿‡480p"}, {"task_title": "ä¸‹è½½ä¸è¶…è¿‡50MBçš„æœ€ä½³è§†é¢‘æ ¼å¼", "task_description": "ä¸‹è½½æœ€ä½³è§†é¢‘æ ¼å¼ï¼Œä½†æ–‡ä»¶å¤§å°ä¸è¶…è¿‡50MB", "example_code": null, "running_command": "youtube-dl -f 'best[filesize<50M]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³è§†é¢‘æ ¼å¼ï¼Œå¤§å°ä¸è¶…è¿‡50MB"}, {"task_title": "é€šè¿‡HTTP/HTTPSåè®®ä¸‹è½½æœ€ä½³æ ¼å¼", "task_description": "ä¸‹è½½æœ€ä½³æ ¼å¼çš„è§†é¢‘ï¼Œé€šè¿‡HTTP/HTTPSåè®®", "example_code": null, "running_command": "youtube-dl -f '(bestvideo+bestaudio/best)[protocol^=http]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³æ ¼å¼è§†é¢‘ï¼Œä½¿ç”¨HTTP/HTTPSåè®®"}, {"task_title": "ä¸‹è½½æœ€ä½³è§†é¢‘å’ŒéŸ³é¢‘æ ¼å¼", "task_description": "ä¸‹è½½æœ€ä½³è§†é¢‘æ ¼å¼å’Œæœ€ä½³éŸ³é¢‘æ ¼å¼ï¼Œä½†ä¸åˆå¹¶å®ƒä»¬", "example_code": null, "running_command": "youtube-dl -f 'bestvideo,bestaudio' -o '%(title)s.f%(format_id)s.%(ext)s'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³è§†é¢‘å’ŒéŸ³é¢‘æ ¼å¼"}, {"task_title": "ä¸‹è½½æœ€è¿‘6ä¸ªæœˆä¸Šä¼ çš„è§†é¢‘", "task_description": "ä¸‹è½½æœ€è¿‘6ä¸ªæœˆå†…ä¸Šä¼ çš„è§†é¢‘", "example_code": null, "running_command": "youtube-dl --dateafter now-6months", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€è¿‘6ä¸ªæœˆå†…çš„è§†é¢‘"}, {"task_title": "ä¸‹è½½ç‰¹å®šæ—¥æœŸä¸Šä¼ çš„è§†é¢‘", "task_description": "ä¸‹è½½åœ¨ç‰¹å®šæ—¥æœŸä¸Šä¼ çš„è§†é¢‘", "example_code": null, "running_command": "youtube-dl --date 19700101", "expected_input": null, "expected_output": "ä¸‹è½½çš„åœ¨1970å¹´1æœˆ1æ—¥ä¸Šä¼ çš„è§†é¢‘"}, {"task_title": "ä¸‹è½½2000å¹´ä»£ä¸Šä¼ çš„è§†é¢‘", "task_description": "ä¸‹è½½åœ¨2000å¹´ä»£ä¸Šä¼ çš„è§†é¢‘", "example_code": null, "running_command": "youtube-dl --dateafter 20000101 --datebefore 20091231", "expected_input": null, "expected_output": "ä¸‹è½½çš„åœ¨2000å¹´ä»£ä¸Šä¼ çš„è§†é¢‘"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T22:59:54.808444"}
{"repo_name": "langflow-ai/langflow", "stars": 136412, "language": "Python", "tasks": [{"task_title": "è¿è¡ŒLangFlow", "task_description": "é€šè¿‡å‘½ä»¤è¡Œå·¥å…·å¯åŠ¨LangFlowåº”ç”¨ï¼Œè¿›è¡Œæµçš„ç®¡ç†å’Œè¿è¡Œã€‚", "example_code": null, "running_command": "uv run langflow run", "expected_input": null, "expected_output": "åº”ç”¨å¯åŠ¨å¹¶è¿è¡Œ"}], "setup": {"setup_commands": ["uv pip install langflow -U"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:00:02.217004"}
{"repo_name": "yt-dlp/yt-dlp", "stars": 133008, "language": "Python", "tasks": [{"task_title": "Download video with custom filename", "task_description": "This task demonstrates downloading a video while specifying the output filename format using placeholders.", "example_code": null, "running_command": "yt-dlp --print filename -o \"test video.%(ext)s\" BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "test video.webm"}, {"task_title": "Download video with title as filename", "task_description": "This task showcases how to use the video title for the output filename, handling special characters.", "example_code": null, "running_command": "yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl test video ''_Ã¤â†­ğ•.webm"}, {"task_title": "Restrict filenames", "task_description": "This task shows how to restrict filenames to avoid special characters.", "example_code": null, "running_command": "yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc --restrict-filenames", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl_test_video_.webm"}, {"task_title": "Download YouTube playlist videos in separate directory by index", "task_description": "This task demonstrates downloading all videos from a YouTube playlist, organizing them into directories based on their order in the playlist.", "example_code": null, "running_command": "yt-dlp -o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\"", "expected_input": "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_output": "Videos downloaded in specified directory structure."}, {"task_title": "Download Udemy course with chapter organization", "task_description": "This task shows how to download a Udemy course while organizing each chapter into separate directories.", "example_code": null, "running_command": "yt-dlp -u user -p password -P \"~/MyVideos\" -o \"%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s\" \"https://www.udemy.com/java-tutorial\"", "expected_input": "user, password, https://www.udemy.com/java-tutorial", "expected_output": "Course chapters downloaded in specified directory structure."}, {"task_title": "Download video and subtitles to separate locations", "task_description": "This task demonstrates downloading a video and its subtitles to specified directories.", "example_code": null, "running_command": "yt-dlp -P \"C:/MyVideos\" -P \"temp:tmp\" -P \"subtitle:subs\" -o \"%(uploader)s/%(title)s.%(ext)s\" BaW_jenozKc --write-subs", "expected_input": "BaW_jenozKc", "expected_output": "Video and subtitles downloaded to specified directories."}, {"task_title": "Stream video to stdout", "task_description": "This task demonstrates how to stream the video being downloaded directly to standard output.", "example_code": null, "running_command": "yt-dlp -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "Streaming video data to stdout."}, {"task_title": "Download best video and audio formats", "task_description": "This task shows how to download the best available video-only and audio-only formats, merging them if necessary.", "example_code": null, "running_command": "yt-dlp -f \"bv+ba/b\"", "expected_input": null, "expected_output": "Best video and audio formats downloaded and merged."}, {"task_title": "Download video with specific codec", "task_description": "This task demonstrates downloading the best video available with a specific codec (h264 or h265).", "example_code": null, "running_command": "yt-dlp -f \"(bv*[vcodec~='^((he|a)vc|h26[45])']+ba) / (bv*+ba/b)\"", "expected_input": null, "expected_output": "Best video with specified codec downloaded."}, {"task_title": "Parse metadata for custom title format", "task_description": "This task shows how to parse metadata to set a custom title format for the downloaded video.", "example_code": null, "running_command": "yt-dlp --parse-metadata \"title:%(artist)s - %(title)s\"", "expected_input": null, "expected_output": "Metadata parsed and title formatted accordingly."}, {"task_title": "Download video using Python code", "task_description": "This task demonstrates how to download a video using the yt_dlp library in Python.", "example_code": "from yt_dlp import YoutubeDL\n\nURLS = ['https://www.youtube.com/watch?v=BaW_jenozKc']\nwith YoutubeDL() as ydl:\n    ydl.download(URLS)", "running_command": null, "expected_input": "https://www.youtube.com/watch?v=BaW_jenozKc", "expected_output": "Video downloaded successfully."}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:00:26.575480"}
{"repo_name": "Significant-Gravitas/AutoGPT", "stars": 179345, "language": "Python", "tasks": [{"task_title": "åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†", "task_description": "ä½¿ç”¨agentå‘½ä»¤æ¥åˆ›å»ºã€å¯åŠ¨å’Œåœæ­¢ä»£ç†ã€‚", "example_code": null, "running_command": "cli.py agent", "expected_input": null, "expected_output": null}, {"task_title": "å¯åŠ¨åŸºå‡†æµ‹è¯•", "task_description": "ä½¿ç”¨benchmarkå‘½ä»¤æ¥å¯åŠ¨åŸºå‡†æµ‹è¯•å¹¶åˆ—å‡ºæµ‹è¯•å’Œç±»åˆ«ã€‚", "example_code": null, "running_command": "cli.py benchmark", "expected_input": null, "expected_output": null}, {"task_title": "å®‰è£…ç³»ç»Ÿæ‰€éœ€ä¾èµ–", "task_description": "ä½¿ç”¨setupå‘½ä»¤æ¥å®‰è£…ç³»ç»Ÿæ‰€éœ€çš„ä¾èµ–ã€‚", "example_code": null, "running_command": "cli.py setup", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:00:54.077097"}
{"repo_name": "ytdl-org/youtube-dl", "stars": 138581, "language": "Python", "tasks": [{"task_title": "è·å–è§†é¢‘æ–‡ä»¶å", "task_description": "ä½¿ç”¨youtube-dlè·å–è§†é¢‘çš„æ–‡ä»¶åï¼Œæ”¯æŒç‰¹æ®Šå­—ç¬¦ã€‚", "example_code": null, "running_command": "youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl test video ''_Ã¤â†­ğ•.mp4"}, {"task_title": "è·å–ç®€åŒ–æ–‡ä»¶å", "task_description": "ä½¿ç”¨youtube-dlè·å–è§†é¢‘çš„æ–‡ä»¶åï¼Œé™åˆ¶æ–‡ä»¶åä¸­çš„å­—ç¬¦ã€‚", "example_code": null, "running_command": "youtube-dl --get-filename -o '%(title)s.%(ext)s' BaW_jenozKc --restrict-filenames", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl_test_video_.mp4"}, {"task_title": "ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨", "task_description": "ä¸‹è½½YouTubeæ’­æ”¾åˆ—è¡¨ä¸­çš„è§†é¢‘ï¼Œå¹¶æŒ‰è§†é¢‘é¡ºåºä¿å­˜åœ¨ä¸åŒç›®å½•ä¸­ã€‚", "example_code": null, "running_command": "youtube-dl -o '%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_input": "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_output": "ä¸‹è½½çš„æ’­æ”¾åˆ—è¡¨è§†é¢‘"}, {"task_title": "ä¸‹è½½YouTubeé¢‘é“çš„æ‰€æœ‰æ’­æ”¾åˆ—è¡¨", "task_description": "ä¸‹è½½YouTubeé¢‘é“/ç”¨æˆ·çš„æ‰€æœ‰æ’­æ”¾åˆ—è¡¨ï¼Œå¹¶å°†æ¯ä¸ªæ’­æ”¾åˆ—è¡¨ä¿å­˜åœ¨ä¸åŒç›®å½•ä¸­ã€‚", "example_code": null, "running_command": "youtube-dl -o '%(uploader)s/%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' https://www.youtube.com/user/TheLinuxFoundation/playlists", "expected_input": "https://www.youtube.com/user/TheLinuxFoundation/playlists", "expected_output": "ä¸‹è½½çš„é¢‘é“æ’­æ”¾åˆ—è¡¨è§†é¢‘"}, {"task_title": "ä¸‹è½½Udemyè¯¾ç¨‹", "task_description": "ä¸‹è½½Udemyè¯¾ç¨‹ï¼ŒæŒ‰ç« èŠ‚ä¿å­˜åœ¨æŒ‡å®šç›®å½•ä¸­ã€‚", "example_code": null, "running_command": "youtube-dl -u user -p password -o '~/MyVideos/%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s' https://www.udemy.com/java-tutorial/", "expected_input": "https://www.udemy.com/java-tutorial/", "expected_output": "ä¸‹è½½çš„Udemyè¯¾ç¨‹è§†é¢‘"}, {"task_title": "ä¸‹è½½æ•´éƒ¨å‰§é›†", "task_description": "ä¸‹è½½æ•´éƒ¨å‰§é›†ï¼ŒæŒ‰ç³»åˆ—å’Œå­£èŠ‚ä¿å­˜åœ¨æŒ‡å®šç›®å½•ä¸­ã€‚", "example_code": null, "running_command": "youtube-dl -o 'C:/MyVideos/%(series)s/%(season_number)s - %(season)s/%(episode_number)s - %(episode)s.%(ext)s' https://videomore.ru/kino_v_detalayah/5_sezon/367617", "expected_input": "https://videomore.ru/kino_v_detalayah/5_sezon/367617", "expected_output": "ä¸‹è½½çš„å‰§é›†è§†é¢‘"}, {"task_title": "æµå¼ä¸‹è½½è§†é¢‘", "task_description": "å°†æ­£åœ¨ä¸‹è½½çš„è§†é¢‘æµå¼ä¼ è¾“åˆ°æ ‡å‡†è¾“å‡ºã€‚", "example_code": null, "running_command": "youtube-dl -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "è§†é¢‘æµæ•°æ®"}, {"task_title": "ä¸‹è½½æœ€ä½³mp4æ ¼å¼", "task_description": "ä¸‹è½½å¯ç”¨çš„æœ€ä½³mp4æ ¼å¼ï¼Œæˆ–å¦‚æœæ²¡æœ‰mp4å¯ç”¨åˆ™ä¸‹è½½å…¶ä»–æœ€ä½³æ ¼å¼ã€‚", "example_code": null, "running_command": "youtube-dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/best[ext=mp4]/best'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³mp4æ ¼å¼è§†é¢‘"}, {"task_title": "ä¸‹è½½ä¸è¶…è¿‡480pçš„æœ€ä½³æ ¼å¼", "task_description": "ä¸‹è½½æœ€ä½³æ ¼å¼ï¼Œä½†ä¸è¶…è¿‡480pã€‚", "example_code": null, "running_command": "youtube-dl -f 'bestvideo[height<=480]+bestaudio/best[height<=480]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„ä¸è¶…è¿‡480pçš„è§†é¢‘"}, {"task_title": "ä¸‹è½½æœ€å¤§50MBçš„è§†é¢‘", "task_description": "ä¸‹è½½æœ€ä½³è§†é¢‘æ ¼å¼ï¼Œä½†ä¸å¤§äº50 MBã€‚", "example_code": null, "running_command": "youtube-dl -f 'best[filesize<50M]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€å¤§50MBçš„è§†é¢‘"}, {"task_title": "é€šè¿‡HTTP/HTTPSåè®®ä¸‹è½½æœ€ä½³æ ¼å¼", "task_description": "é€šè¿‡HTTP/HTTPSåè®®ä¸‹è½½æœ€ä½³æ ¼å¼ã€‚", "example_code": null, "running_command": "youtube-dl -f '(bestvideo+bestaudio/best)[protocol^=http]'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³æ ¼å¼è§†é¢‘"}, {"task_title": "ä¸‹è½½æœ€ä½³è§†é¢‘å’ŒéŸ³é¢‘æ ¼å¼", "task_description": "ä¸‹è½½æœ€ä½³è§†é¢‘æ ¼å¼å’Œæœ€ä½³éŸ³é¢‘æ ¼å¼ï¼Œä½†ä¸åˆå¹¶ã€‚", "example_code": null, "running_command": "youtube-dl -f 'bestvideo,bestaudio' -o '%(title)s.f%(format_id)s.%(ext)s'", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€ä½³è§†é¢‘å’ŒéŸ³é¢‘æ ¼å¼"}, {"task_title": "ä¸‹è½½æœ€è¿‘6ä¸ªæœˆä¸Šä¼ çš„è§†é¢‘", "task_description": "ä»…ä¸‹è½½æœ€è¿‘6ä¸ªæœˆå†…ä¸Šä¼ çš„è§†é¢‘ã€‚", "example_code": null, "running_command": "youtube-dl --dateafter now-6months", "expected_input": null, "expected_output": "ä¸‹è½½çš„æœ€è¿‘6ä¸ªæœˆä¸Šä¼ çš„è§†é¢‘"}, {"task_title": "ä¸‹è½½ç‰¹å®šæ—¥æœŸä¸Šä¼ çš„è§†é¢‘", "task_description": "ä»…ä¸‹è½½åœ¨1970å¹´1æœˆ1æ—¥ä¸Šä¼ çš„è§†é¢‘ã€‚", "example_code": null, "running_command": "youtube-dl --date 19700101", "expected_input": null, "expected_output": "ä¸‹è½½çš„åœ¨ç‰¹å®šæ—¥æœŸä¸Šä¼ çš„è§†é¢‘"}, {"task_title": "ä¸‹è½½ç‰¹å®šåå¹´ä¸Šä¼ çš„è§†é¢‘", "task_description": "ä»…ä¸‹è½½åœ¨2000å¹´ä»£ä¸Šä¼ çš„è§†é¢‘ã€‚", "example_code": null, "running_command": "youtube-dl --dateafter 20000101 --datebefore 20091231", "expected_input": null, "expected_output": "ä¸‹è½½çš„åœ¨ç‰¹å®šåå¹´ä¸Šä¼ çš„è§†é¢‘"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:01:27.625138"}
{"repo_name": "langflow-ai/langflow", "stars": 136412, "language": "Python", "tasks": [{"task_title": "è¿è¡ŒLangflow", "task_description": "ä½¿ç”¨Langflowåº“è¿è¡Œä¸€ä¸ªæµä»»åŠ¡ã€‚", "example_code": null, "running_command": "uv run langflow run", "expected_input": null, "expected_output": "å¯åŠ¨LangflowæœåŠ¡å¹¶è¿è¡ŒæŒ‡å®šä»»åŠ¡"}], "setup": {"setup_commands": ["uv pip install langflow -U"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:01:34.427824"}
{"repo_name": "yt-dlp/yt-dlp", "stars": 133008, "language": "Python", "tasks": [{"task_title": "Download video with custom filename", "task_description": "ä½¿ç”¨æŒ‡å®šçš„è¾“å‡ºæ¨¡æ¿ä¸‹è½½è§†é¢‘ï¼Œå¹¶æ‰“å°æ–‡ä»¶åã€‚", "example_code": null, "running_command": "yt-dlp --print filename -o \"test video.%(ext)s\" BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "test video.webm"}, {"task_title": "Download video with title as filename", "task_description": "ä½¿ç”¨è§†é¢‘æ ‡é¢˜ä½œä¸ºæ–‡ä»¶åä¸‹è½½è§†é¢‘ï¼Œå¹¶æ‰“å°æ–‡ä»¶åï¼Œå¤„ç†ç‰¹æ®Šå­—ç¬¦ã€‚", "example_code": null, "running_command": "yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl test video ''_Ã¤â†­ğ•.webm"}, {"task_title": "Download video with restricted filenames", "task_description": "ä¸‹è½½è§†é¢‘å¹¶é™åˆ¶æ–‡ä»¶åä¸­çš„å­—ç¬¦ã€‚", "example_code": null, "running_command": "yt-dlp --print filename -o \"%(title)s.%(ext)s\" BaW_jenozKc --restrict-filenames", "expected_input": "BaW_jenozKc", "expected_output": "youtube-dl_test_video_.webm"}, {"task_title": "Download videos from YouTube playlist", "task_description": "ä»YouTubeæ’­æ”¾åˆ—è¡¨ä¸­ä¸‹è½½è§†é¢‘ï¼Œå¹¶æŒ‰ç…§è§†é¢‘åœ¨æ’­æ”¾åˆ—è¡¨ä¸­çš„é¡ºåºå­˜å‚¨ã€‚", "example_code": null, "running_command": "yt-dlp -o \"%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s\" \"https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re\"", "expected_input": "https://www.youtube.com/playlist?list=PLwiyx1dc3P2JR9N8gQaQN_BCvlSlap7re", "expected_output": "ä¸‹è½½å¯¹åº”çš„æ’­æ”¾åˆ—è¡¨è§†é¢‘"}, {"task_title": "Download Udemy course videos", "task_description": "ä»Udemyè¯¾ç¨‹ä¸‹è½½è§†é¢‘ï¼Œå¹¶æŒ‰ç…§ç« èŠ‚å­˜å‚¨ã€‚", "example_code": null, "running_command": "yt-dlp -u user -p password -P \"~/MyVideos\" -o \"%(playlist)s/%(chapter_number)s - %(chapter)s/%(title)s.%(ext)s\" \"https://www.udemy.com/java-tutorial\"", "expected_input": "https://www.udemy.com/java-tutorial", "expected_output": "ä¸‹è½½å¯¹åº”çš„Udemyè¯¾ç¨‹è§†é¢‘"}, {"task_title": "Download video and subtitles", "task_description": "ä¸‹è½½è§†é¢‘å’Œå­—å¹•ï¼Œå¹¶åˆ†åˆ«å­˜å‚¨ã€‚", "example_code": null, "running_command": "yt-dlp -P \"C:/MyVideos\" -P \"subtitle:subs\" -o \"%(uploader)s/%(title)s.%(ext)s\" BaW_jenozKc --write-subs", "expected_input": "BaW_jenozKc", "expected_output": "ä¸‹è½½è§†é¢‘å’Œå¯¹åº”çš„å­—å¹•"}, {"task_title": "Stream video to stdout", "task_description": "å°†ä¸‹è½½çš„è§†é¢‘æµè¾“å‡ºåˆ°æ ‡å‡†è¾“å‡ºã€‚", "example_code": null, "running_command": "yt-dlp -o - BaW_jenozKc", "expected_input": "BaW_jenozKc", "expected_output": "è§†é¢‘æµæ•°æ®"}, {"task_title": "Download best video and audio formats", "task_description": "ä¸‹è½½æœ€ä½³è§†é¢‘å’ŒéŸ³é¢‘æ ¼å¼ï¼Œå¹¶åˆå¹¶å®ƒä»¬ã€‚", "example_code": null, "running_command": "yt-dlp -f \"bv+ba/b\"", "expected_input": null, "expected_output": "ä¸‹è½½æœ€ä½³è§†é¢‘å’ŒéŸ³é¢‘æ ¼å¼"}, {"task_title": "Download video with specific duration filter", "task_description": "åªä¸‹è½½æ—¶é•¿è¶…è¿‡ä¸€åˆ†é’Ÿçš„è§†é¢‘ã€‚", "example_code": "def longer_than_a_minute(info, *, incomplete):\n    duration = info.get('duration')\n    if duration and duration < 60:\n        return 'The video is too short'\n\nydl_opts = {\n    'match_filter': longer_than_a_minute,\n}", "running_command": null, "expected_input": "https://www.youtube.com/watch?v=BaW_jenozKc", "expected_output": "ä¸‹è½½ç¬¦åˆæ—¶é•¿æ¡ä»¶çš„è§†é¢‘"}, {"task_title": "Custom post-processor example", "task_description": "åˆ›å»ºè‡ªå®šä¹‰åå¤„ç†å™¨å¹¶åœ¨ä¸‹è½½è¿‡ç¨‹ä¸­æ‰§è¡Œã€‚", "example_code": "class MyCustomPP(yt_dlp.postprocessor.PostProcessor):\n    def run(self, info):\n        self.to_screen('Doing stuff')\n        return [], info\n\nydl_opts = {\n    'postprocessors': [MyCustomPP()],\n}", "running_command": null, "expected_input": "https://www.youtube.com/watch?v=BaW_jenozKc", "expected_output": "Doing stuff"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:01:55.995396"}
{"repo_name": "deepseek-ai/DeepSeek-V3", "stars": 100031, "language": "Python", "tasks": [{"task_title": "FP8æƒé‡è½¬æ¢ä¸ºBF16æ ¼å¼", "task_description": "è¯¥ä»»åŠ¡ç”¨äºå°†FP8æ ¼å¼çš„æƒé‡æ–‡ä»¶è½¬æ¢ä¸ºBF16æ ¼å¼ï¼Œä½¿ç”¨äº†Pythonè„šæœ¬è¿›è¡Œå¤„ç†ã€‚", "example_code": null, "running_command": "python fp8_cast_bf16.py --input-fp8-hf-path /path/to/fp8_weights --output-bf16-hf-path /path/to/bf16_weights", "expected_input": "/path/to/fp8_weights, /path/to/bf16_weights", "expected_output": "è½¬æ¢å®Œæˆï¼ŒBF16æƒé‡æ–‡ä»¶å·²ç”Ÿæˆ"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:02:08.080068"}
{"repo_name": "nvbn/thefuck", "stars": 94501, "language": "Python", "tasks": [{"task_title": "Fix git push without upstream branch", "task_description": "Automatically fix the issue of pushing to a git branch that has no upstream branch set.", "example_code": null, "running_command": "fuck", "expected_input": null, "expected_output": "git push --set-upstream origin master"}, {"task_title": "Correct misspelled command", "task_description": "Suggest the correct command when a misspelled command is entered.", "example_code": null, "running_command": "fuck", "expected_input": "puthon", "expected_output": "python"}, {"task_title": "Fix unrecognized git command", "task_description": "Automatically correct an unrecognized git command to its intended form.", "example_code": null, "running_command": "fuck", "expected_input": "git brnch", "expected_output": "git branch"}, {"task_title": "Fix unrecognized lein task", "task_description": "Automatically correct an unrecognized lein task to its intended form.", "example_code": null, "running_command": "fuck", "expected_input": "lein rpl", "expected_output": "lein repl"}, {"task_title": "Enable The Fuck with custom alias", "task_description": "Set up a custom alias for The Fuck to use in the terminal.", "example_code": null, "running_command": "eval $(thefuck --alias)", "expected_input": null, "expected_output": null}, {"task_title": "Run The Fuck with confirmation", "task_description": "Run The Fuck with a confirmation prompt before executing the suggested command.", "example_code": null, "running_command": "fuck --yeah", "expected_input": null, "expected_output": null}, {"task_title": "Run The Fuck with a reverse option", "task_description": "Run The Fuck with the reverse option to undo the last command.", "example_code": null, "running_command": "fuck -r", "expected_input": null, "expected_output": null}, {"task_title": "Upgrade The Fuck", "task_description": "Upgrade The Fuck package to the latest version.", "example_code": null, "running_command": "pip3 install thefuck --upgrade", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["âœ apt-get install vim\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\nâœ fuck\nsudo apt-get install vim [enter/â†‘/â†“/ctrl+c]\n[sudo] password for nvbn:\nReading package lists... Done\n...", "âœ apt-get install vim\nE: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)\nE: Unable to lock the administration directory (/var/lib/dpkg/), are you root?\n\nâœ fuck\nsudo apt-get install vim\n[sudo] password for nvbn:\nReading package lists... Done\n...", "brew install thefuck", "pip install thefuck"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:02:22.866384"}
{"repo_name": "comfyanonymous/ComfyUI", "stars": 92192, "language": "Python", "tasks": [{"task_title": "Run ComfyUI with AMD GPU support", "task_description": "This task involves running the ComfyUI application on AMD GPUs that are not officially supported by ROCm, using specific environment variables to set the graphics version.", "example_code": null, "running_command": "HSA_OVERRIDE_GFX_VERSION=10.3.0 python main.py", "expected_input": null, "expected_output": "ComfyUI application running with AMD GPU support"}, {"task_title": "Run ComfyUI for RDNA3 AMD GPUs", "task_description": "This task involves running the ComfyUI application specifically for AMD RDNA3 GPUs by setting the appropriate graphics version.", "example_code": null, "running_command": "HSA_OVERRIDE_GFX_VERSION=11.0.0 python main.py", "expected_input": null, "expected_output": "ComfyUI application running with RDNA3 AMD GPU support"}, {"task_title": "Enable experimental memory efficient attention", "task_description": "This task involves enabling experimental memory efficient attention in ComfyUI on certain AMD GPUs using a specific command, which may improve performance.", "example_code": null, "running_command": "Enable memory efficient attention on recent PyTorch", "expected_input": null, "expected_output": "Memory efficient attention enabled"}], "setup": {"setup_commands": ["pip install comfy-cli\ncomfy install"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:02:36.899771"}
{"repo_name": "fastapi/fastapi", "stars": 91264, "language": "Python", "tasks": [{"task_title": "è¯»å–æ ¹è·¯å¾„", "task_description": "å®šä¹‰ä¸€ä¸ªGETè¯·æ±‚çš„æ ¹è·¯å¾„å¤„ç†å‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«é—®å€™ä¿¡æ¯çš„JSONå¯¹è±¡ã€‚", "example_code": "from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef read_root():\n    return {\"Hello\": \"World\"}", "running_command": null, "expected_input": null, "expected_output": "{\"Hello\": \"World\"}"}, {"task_title": "è¯»å–ç‰¹å®šé¡¹", "task_description": "å®šä¹‰ä¸€ä¸ªGETè¯·æ±‚çš„è·¯å¾„å¤„ç†å‡½æ•°ï¼Œæ¥å—ä¸€ä¸ªè·¯å¾„å‚æ•°å’Œä¸€ä¸ªå¯é€‰æŸ¥è¯¢å‚æ•°ï¼Œè¿”å›åŒ…å«é¡¹IDå’ŒæŸ¥è¯¢å‚æ•°çš„JSONå¯¹è±¡ã€‚", "example_code": "from typing import Union\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\ndef read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q}", "running_command": null, "expected_input": "item_id=1&q=test", "expected_output": "{\"item_id\": 1, \"q\": \"test\"}"}, {"task_title": "å¼‚æ­¥è¯»å–æ ¹è·¯å¾„", "task_description": "ä½¿ç”¨å¼‚æ­¥å®šä¹‰ä¸€ä¸ªGETè¯·æ±‚çš„æ ¹è·¯å¾„å¤„ç†å‡½æ•°ï¼Œè¿”å›ä¸€ä¸ªåŒ…å«é—®å€™ä¿¡æ¯çš„JSONå¯¹è±¡ã€‚", "example_code": "from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\nasync def read_root():\n    return {\"Hello\": \"World\"}", "running_command": null, "expected_input": null, "expected_output": "{\"Hello\": \"World\"}"}, {"task_title": "å¼‚æ­¥è¯»å–ç‰¹å®šé¡¹", "task_description": "ä½¿ç”¨å¼‚æ­¥å®šä¹‰ä¸€ä¸ªGETè¯·æ±‚çš„è·¯å¾„å¤„ç†å‡½æ•°ï¼Œæ¥å—ä¸€ä¸ªè·¯å¾„å‚æ•°å’Œä¸€ä¸ªå¯é€‰æŸ¥è¯¢å‚æ•°ï¼Œè¿”å›åŒ…å«é¡¹IDå’ŒæŸ¥è¯¢å‚æ•°çš„JSONå¯¹è±¡ã€‚", "example_code": "from typing import Union\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/items/{item_id}\")\nasync def read_item(item_id: int, q: Union[str, None] = None):\n    return {\"item_id\": item_id, \"q\": q}", "running_command": null, "expected_input": "item_id=1&q=test", "expected_output": "{\"item_id\": 1, \"q\": \"test\"}"}], "setup": {"setup_commands": ["$ pip install \"fastapi[standard]\"\n\n---> 100%"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:03:20.554994"}
{"repo_name": "openai/whisper", "stars": 90053, "language": "Python", "tasks": [{"task_title": "Transcribe audio file", "task_description": "ä½¿ç”¨æ¨¡å‹'turbo'å°†éŸ³é¢‘æ–‡ä»¶è½¬æ¢ä¸ºæ–‡æœ¬ã€‚", "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\nresult = model.transcribe(\"audio.mp3\")\nprint(result[\"text\"])", "running_command": null, "expected_input": "audio.mp3", "expected_output": "Transcribed text from audio"}, {"task_title": "Detect language from audio", "task_description": "åŠ è½½éŸ³é¢‘æ–‡ä»¶å¹¶æ£€æµ‹å…¶ä¸­çš„è¯­è¨€ã€‚", "example_code": "import whisper\n\nmodel = whisper.load_model(\"turbo\")\naudio = whisper.load_audio(\"audio.mp3\")\naudio = whisper.pad_or_trim(audio)\nmel = whisper.log_mel_spectrogram(audio, n_mels=model.dims.n_mels).to(model.device)\n_, probs = model.detect_language(mel)\nprint(f\"Detected language: {max(probs, key=probs.get)}\")", "running_command": null, "expected_input": "audio.mp3", "expected_output": "Detected language: <language>"}, {"task_title": "Translate audio to text", "task_description": "ä½¿ç”¨æ¨¡å‹'medium'å°†éŸ³é¢‘æ–‡ä»¶ç¿»è¯‘ä¸ºæ–‡æœ¬ï¼ŒæŒ‡å®šè¯­è¨€ä¸ºJapaneseã€‚", "example_code": null, "running_command": "whisper japanese.wav --model medium --language Japanese --task translate", "expected_input": "japanese.wav", "expected_output": "Translated text from audio"}, {"task_title": "Convert audio formats", "task_description": "å°†éŸ³é¢‘æ–‡ä»¶ä»ä¸€ç§æ ¼å¼è½¬æ¢ä¸ºå¦ä¸€ç§æ ¼å¼ï¼Œä½¿ç”¨æ¨¡å‹'turbo'ã€‚", "example_code": null, "running_command": "whisper audio.flac audio.mp3 audio.wav --model turbo", "expected_input": "audio.flac, audio.mp3, audio.wav", "expected_output": "Converted audio formats"}, {"task_title": "Display help information", "task_description": "æ˜¾ç¤ºwhisperå‘½ä»¤è¡Œå·¥å…·çš„å¸®åŠ©ä¿¡æ¯ã€‚", "example_code": null, "running_command": "whisper --help", "expected_input": null, "expected_output": "Help information for whisper command"}], "setup": {"setup_commands": ["# on Ubuntu or Debian\nsudo apt update && sudo apt install ffmpeg\n\n# on Arch Linux\nsudo pacman -S ffmpeg\n\n# on MacOS using Homebrew (https://brew.sh/)\nbrew install ffmpeg\n\n# on Windows using Chocolatey (https://chocolatey.org/)\nchoco install ffmpeg\n\n# on Windows using Scoop (https://scoop.sh/)\nscoop install ffmpeg", "pip install setuptools-rust"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:03:35.549348"}
{"repo_name": "microsoft/markitdown", "stars": 82211, "language": "Python", "tasks": [{"task_title": "Convert PDF to Markdown", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼çš„æ–‡æ¡£ã€‚", "example_code": null, "running_command": "markitdown path-to-file.pdf > document.md", "expected_input": "path-to-file.pdf", "expected_output": "document.mdå†…å®¹"}, {"task_title": "Convert PDF to Markdown with Output File", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼å¹¶æŒ‡å®šè¾“å‡ºæ–‡ä»¶ã€‚", "example_code": null, "running_command": "markitdown path-to-file.pdf -o document.md", "expected_input": "path-to-file.pdf", "expected_output": "document.mdå†…å®¹"}, {"task_title": "Convert PDF from Standard Input", "task_description": "ä»æ ‡å‡†è¾“å…¥ä¸­è¯»å–PDFæ–‡ä»¶å¹¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ã€‚", "example_code": null, "running_command": "cat path-to-file.pdf | markitdown", "expected_input": "path-to-file.pdf", "expected_output": "Markdownå†…å®¹"}, {"task_title": "List Available Plugins", "task_description": "åˆ—å‡ºå¯ç”¨çš„æ’ä»¶ã€‚", "example_code": null, "running_command": "markitdown --list-plugins", "expected_input": null, "expected_output": "å¯ç”¨æ’ä»¶åˆ—è¡¨"}, {"task_title": "Use Plugins for Conversion", "task_description": "ä½¿ç”¨æ’ä»¶å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ã€‚", "example_code": null, "running_command": "markitdown --use-plugins path-to-file.pdf", "expected_input": "path-to-file.pdf", "expected_output": "Markdownå†…å®¹"}, {"task_title": "Convert PDF with Document Intelligence Endpoint", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œå¹¶ä½¿ç”¨æŒ‡å®šçš„æ–‡æ¡£æ™ºèƒ½ç«¯ç‚¹ã€‚", "example_code": null, "running_command": "markitdown path-to-file.pdf -o document.md -d -e \"<document_intelligence_endpoint>\"", "expected_input": "path-to-file.pdf, <document_intelligence_endpoint>", "expected_output": "document.mdå†…å®¹"}, {"task_title": "Convert Excel File to Markdown", "task_description": "å°†Excelæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œä¸å¯ç”¨æ’ä»¶ã€‚", "example_code": "from markitdown import MarkItDown\n\nmd = MarkItDown(enable_plugins=False)\nresult = md.convert(\"test.xlsx\")\nprint(result.text_content)", "running_command": null, "expected_input": "test.xlsx", "expected_output": "Markdownå†…å®¹"}, {"task_title": "Convert PDF with Document Intelligence", "task_description": "å°†PDFæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œå¹¶ä½¿ç”¨æ–‡æ¡£æ™ºèƒ½ç«¯ç‚¹ã€‚", "example_code": "from markitdown import MarkItDown\n\nmd = MarkItDown(docintel_endpoint=\"<document_intelligence_endpoint>\")\nresult = md.convert(\"test.pdf\")\nprint(result.text_content)", "running_command": null, "expected_input": "test.pdf, <document_intelligence_endpoint>", "expected_output": "Markdownå†…å®¹"}, {"task_title": "Convert Image to Markdown using OpenAI", "task_description": "å°†å›¾åƒæ–‡ä»¶è½¬æ¢ä¸ºMarkdownæ ¼å¼ï¼Œä½¿ç”¨OpenAIçš„å®¢æˆ·ç«¯å’Œæ¨¡å‹ã€‚", "example_code": "from markitdown import MarkItDown\nfrom openai import OpenAI\n\nclient = OpenAI()\nmd = MarkItDown(llm_client=client, llm_model=\"gpt-4o\", llm_prompt=\"optional custom prompt\")\nresult = md.convert(\"example.jpg\")\nprint(result.text_content)", "running_command": null, "expected_input": "example.jpg", "expected_output": "Markdownå†…å®¹"}], "setup": {"setup_commands": ["python -m venv .venv\nsource .venv/bin/activate", "uv venv --python=3.12 .venv\nsource .venv/bin/activate\n# NOTE: Be sure to use 'uv pip install' rather than just 'pip install' to install packages in this virtual environment", "conda create -n markitdown python=3.12\nconda activate markitdown", "git clone git@github.com:microsoft/markitdown.git\ncd markitdown\npip install -e 'packages/markitdown[all]'", "pip install 'markitdown[pdf, docx, pptx]'", "  pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/\n  hatch shell\n  hatch test"], "docker_commands": ["docker build -t markitdown:latest .\ndocker run --rm -i markitdown:latest < ~/your-file.pdf > output.md"], "has_docker_files": true}, "timestamp": "2025-10-28T23:03:54.996605"}
{"repo_name": "3b1b/manim", "stars": 81503, "language": "Python", "tasks": [{"task_title": "Opening Manim Example", "task_description": "å±•ç¤ºå¦‚ä½•ä½¿ç”¨Manimåº“åˆ›å»ºä¸€ä¸ªç®€å•çš„åŠ¨ç”»ç¤ºä¾‹ï¼Œæ¼”ç¤ºäº†åŸºæœ¬çš„åŠ¨ç”»åŠŸèƒ½ã€‚", "example_code": "from manim import *\n\nclass OpeningManimExample(Scene):\n    def construct(self):\n        square = Square()\n        self.play(Create(square))\n        self.wait(1)", "running_command": null, "expected_input": null, "expected_output": "ä¸€ä¸ªåŒ…å«æ–¹å½¢åŠ¨ç”»çš„åœºæ™¯"}], "setup": {"setup_commands": ["# Install manimgl\npip install manimgl\n\n# Try it out\nmanimgl", "# Install manimgl\npip install -e .\n\n# Try it out\nmanimgl example_scenes.py OpeningManimExample\n# or\nmanim-render example_scenes.py OpeningManimExample", "    git clone https://github.com/3b1b/manim.git\n    cd manim\n    pip install -e .\n    manimgl example_scenes.py OpeningManimExample", "    brew install ffmpeg mactex", "    arch -arm64 brew install pkg-config cairo", "    git clone https://github.com/3b1b/manim.git\n    cd manim\n    pip install -e .\n    manimgl example_scenes.py OpeningManimExample (make sure to add manimgl to path first.)"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:04:01.261750"}
{"repo_name": "hacksider/Deep-Live-Cam", "stars": 74220, "language": "Python", "tasks": [{"task_title": "ä½¿ç”¨CUDAæ‰§è¡Œ", "task_description": "é€šè¿‡CUDAæ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚", "example_code": null, "running_command": "python run.py --execution-provider cuda", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨CoreMLæ‰§è¡Œ", "task_description": "é€šè¿‡CoreMLæ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚", "example_code": null, "running_command": "python3.10 run.py --execution-provider coreml", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨DirectMLæ‰§è¡Œ", "task_description": "é€šè¿‡DirectMLæ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚", "example_code": null, "running_command": "python run.py --execution-provider directml", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨OpenVINOæ‰§è¡Œ", "task_description": "é€šè¿‡OpenVINOæ‰§è¡Œæ¨¡å‹æ¨ç†ã€‚", "example_code": null, "running_command": "python run.py --execution-provider openvino", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["git clone https://github.com/hacksider/Deep-Live-Cam.git\ncd Deep-Live-Cam", "python -m venv venv\nvenv\\Scripts\\activate\npip install -r requirements.txt", "# Ensure you use the installed Python 3.10\npython3 -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt", "# Install Python 3.11 (specific version is important)\nbrew install python@3.11\n\n# Install tkinter package (required for the GUI)\nbrew install python-tk@3.10\n\n# Create and activate virtual environment with Python 3.11\npython3.11 -m venv venv\nsource venv/bin/activate\n\n# Install dependencies\npip install -r requirements.txt", "# Deactivate the virtual environment\nrm -rf venv\n\n# Reinstall the virtual environment\npython -m venv venv\nsource venv/bin/activate\n\n# install the dependencies again\npip install -r requirements.txt\n\n# gfpgan and basicsrs issue fix\npip install git+https://github.com/xinntao/BasicSR.git@master\npip uninstall gfpgan -y\npip install git+https://github.com/TencentARC/GFPGAN.git@master", "pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\npip uninstall onnxruntime onnxruntime-gpu\npip install onnxruntime-gpu==1.21.0", "pip uninstall onnxruntime onnxruntime-silicon\npip install onnxruntime-silicon==1.13.1", "pip uninstall onnxruntime onnxruntime-coreml\npip install onnxruntime-coreml==1.21.0", "pip uninstall onnxruntime onnxruntime-directml\npip install onnxruntime-directml==1.21.0", "pip uninstall onnxruntime onnxruntime-openvino\npip install onnxruntime-openvino==1.21.0"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:04:21.972907"}
{"repo_name": "Shubhamsaboo/awesome-llm-apps", "stars": 73948, "language": "Python", "tasks": [{"task_title": "ç”Ÿæˆæ—…è¡Œè®¡åˆ’", "task_description": "ä½¿ç”¨AIç”Ÿæˆä¸€ä¸ªæ—…è¡Œè®¡åˆ’ï¼ŒåŸºäºç”¨æˆ·è¾“å…¥çš„ç›®çš„åœ°å’Œåå¥½ã€‚", "example_code": "from ai_travel_agent import TravelAgent\n\nagent = TravelAgent()\nplan = agent.generate_plan(destination=\"Paris\", preferences=\"art, history\")\nprint(plan)", "running_command": null, "expected_input": {"destination": "Paris", "preferences": "art, history"}, "expected_output": "Your travel plan to Paris includes visits to the Louvre, MusÃ©e d'Orsay, and historical tours."}, {"task_title": "è·å–æ—…è¡Œå»ºè®®", "task_description": "è·å–åŸºäºç”¨æˆ·éœ€æ±‚çš„æ—…è¡Œå»ºè®®ã€‚", "example_code": "advice = agent.get_travel_advice(budget=1000, duration=7)\nprint(advice)", "running_command": null, "expected_input": {"budget": 1000, "duration": 7}, "expected_output": "Based on your budget and duration, consider visiting Spain or Portugal."}, {"task_title": "æŸ¥è¯¢ç›®çš„åœ°ä¿¡æ¯", "task_description": "æŸ¥è¯¢ç‰¹å®šç›®çš„åœ°çš„åŸºæœ¬ä¿¡æ¯ï¼Œä¾‹å¦‚å¤©æ°”å’Œå½“åœ°æ´»åŠ¨ã€‚", "example_code": "info = agent.get_destination_info(destination=\"Tokyo\")\nprint(info)", "running_command": null, "expected_input": "Tokyo", "expected_output": "Tokyo is currently 20Â°C with a chance of rain. Recommended activities include visiting Shibuya and the Tokyo Tower."}], "setup": {"setup_commands": ["    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git ", "    pip install -r requirements.txt"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:04:31.559355"}
{"repo_name": "browser-use/browser-use", "stars": 71871, "language": "Python", "tasks": [{"task_title": "Initialize a new project", "task_description": "ä½¿ç”¨CLIå‘½ä»¤åˆå§‹åŒ–ä¸€ä¸ªæ–°çš„é¡¹ç›®ã€‚", "example_code": null, "running_command": "uv init", "expected_input": null, "expected_output": null}, {"task_title": "Add browser-use library", "task_description": "ä½¿ç”¨CLIå‘½ä»¤å°†browser-useåº“æ·»åŠ åˆ°é¡¹ç›®ä¸­ã€‚", "example_code": null, "running_command": "uv add browser-use", "expected_input": null, "expected_output": null}, {"task_title": "Sync project dependencies", "task_description": "ä½¿ç”¨CLIå‘½ä»¤åŒæ­¥é¡¹ç›®çš„ä¾èµ–é¡¹ã€‚", "example_code": null, "running_command": "uv sync", "expected_input": null, "expected_output": null}, {"task_title": "Install browser-use library", "task_description": "ä½¿ç”¨CLIå‘½ä»¤å®‰è£…browser-useåº“ã€‚", "example_code": null, "running_command": "uvx browser-use install", "expected_input": null, "expected_output": null}, {"task_title": "Execute a task with Agent", "task_description": "ä½¿ç”¨Agentæ‰§è¡Œä»»åŠ¡ï¼ŒæŸ¥æ‰¾browser-useåº“çš„æ˜Ÿæ ‡æ•°é‡ã€‚", "example_code": "from browser_use import Agent, Browser, ChatBrowserUse\nimport asyncio\n\nasync def example():\n    browser = Browser()\n    llm = ChatBrowserUse()\n    agent = Agent(\n        task=\"Find the number of stars of the browser-use repo\",\n        llm=llm,\n        browser=browser,\n    )\n    history = await agent.run()\n    return history\n\nif __name__ == \"__main__\":\n    history = asyncio.run(example())", "running_command": null, "expected_input": null, "expected_output": "å†å²è®°å½•æ•°æ®"}, {"task_title": "Initialize with a specific template", "task_description": "ä½¿ç”¨CLIå‘½ä»¤åˆå§‹åŒ–ä¸€ä¸ªå¸¦æœ‰é»˜è®¤æ¨¡æ¿çš„é¡¹ç›®ã€‚", "example_code": null, "running_command": "uvx browser-use init --template default", "expected_input": null, "expected_output": null}, {"task_title": "Initialize with a specific template and output file", "task_description": "ä½¿ç”¨CLIå‘½ä»¤åˆå§‹åŒ–ä¸€ä¸ªå¸¦æœ‰é»˜è®¤æ¨¡æ¿çš„é¡¹ç›®ï¼Œå¹¶æŒ‡å®šè¾“å‡ºæ–‡ä»¶ã€‚", "example_code": null, "running_command": "uvx browser-use init --template default --output my_agent.py", "expected_input": null, "expected_output": null}, {"task_title": "Create a custom tool", "task_description": "å®šä¹‰ä¸€ä¸ªè‡ªå®šä¹‰å·¥å…·å¹¶åœ¨Agentä¸­ä½¿ç”¨ã€‚", "example_code": "@Tool()\ndef custom_tool(param: str) -> str:\n    \"\"\"Description of what this tool does.\"\"\"\n    return f\"Result: {param}\"\n\nagent = Agent(\n    task=\"Your task\",\n    llm=llm,\n    browser=browser,\n    use_custom_tools=[custom_tool],\n)", "running_command": null, "expected_input": "è‡ªå®šä¹‰å·¥å…·å‚æ•°", "expected_output": "Result: è‡ªå®šä¹‰å·¥å…·å‚æ•°"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:04:47.164855"}
{"repo_name": "pallets/flask", "stars": 70671, "language": "Python", "tasks": [{"task_title": "åˆ›å»ºç®€å•çš„Flaskåº”ç”¨", "task_description": "è¯¥ä»»åŠ¡å±•ç¤ºå¦‚ä½•åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„Flaskåº”ç”¨ï¼Œå¹¶å®šä¹‰ä¸€ä¸ªè·¯ç”±ï¼Œè¿”å›'Hello, World!'ã€‚", "example_code": "from flask import Flask\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef hello():\n    return \"Hello, World!\"", "running_command": null, "expected_input": null, "expected_output": "Hello, World!"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:05:03.023821"}
{"repo_name": "sherlock-project/sherlock", "stars": 69906, "language": "Python", "tasks": [{"task_title": "Check a single username", "task_description": "This task checks the availability of a single username across various social networks.", "example_code": null, "running_command": "sherlock user123", "expected_input": "user123", "expected_output": "[{\"username\": \"user123\", \"links\": [\"https://www.1337x.to/user/user123/\", ...]}]"}, {"task_title": "Check multiple usernames", "task_description": "This task checks the availability of multiple usernames across various social networks.", "example_code": null, "running_command": "sherlock user1 user2 user3", "expected_input": "user1 user2 user3", "expected_output": "[{\"username\": \"user1\", \"links\": [...]}, {\"username\": \"user2\", \"links\": [...]}, {\"username\": \"user3\", \"links\": [...]}]"}, {"task_title": "Display help information", "task_description": "This task displays the help information and usage instructions for the Sherlock tool.", "example_code": null, "running_command": "sherlock --help", "expected_input": null, "expected_output": "usage: sherlock [-h] [--version] [--verbose] ..."}, {"task_title": "Call Sherlock via API", "task_description": "This task demonstrates how to call the Sherlock service using an API with a JSON input.", "example_code": null, "running_command": "echo '{\"usernames\":[\"user123\"]}' | apify call -so netmilk/sherlock", "expected_input": "{\"usernames\":[\"user123\"]}", "expected_output": "[{\"username\": \"user123\", \"links\": [\"https://www.1337x.to/user/user123/\", ...]}]"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:05:18.947983"}
{"repo_name": "xtekky/gpt4free", "stars": 65454, "language": "Python", "tasks": [{"task_title": "è¿è¡Œå›¾å½¢ç”¨æˆ·ç•Œé¢", "task_description": "å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ä»¥ä¸æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚", "example_code": "from g4f.gui import run_gui\nrun_gui()", "running_command": null, "expected_input": null, "expected_output": "å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢"}, {"task_title": "é€šè¿‡CLIå¯åŠ¨GUI", "task_description": "é€šè¿‡å‘½ä»¤è¡Œæ¥å£å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢ï¼ŒæŒ‡å®šç«¯å£å’Œè°ƒè¯•æ¨¡å¼ã€‚", "example_code": null, "running_command": "python -m g4f.cli gui --port 8080 --debug", "expected_input": null, "expected_output": "å¯åŠ¨å›¾å½¢ç”¨æˆ·ç•Œé¢"}, {"task_title": "é€šè¿‡CLIå¯åŠ¨æœåŠ¡", "task_description": "é€šè¿‡å‘½ä»¤è¡Œæ¥å£å¯åŠ¨æœåŠ¡ï¼ŒæŒ‡å®šç«¯å£å’Œè°ƒè¯•æ¨¡å¼ã€‚", "example_code": null, "running_command": "python -m g4f --port 8080 --debug", "expected_input": null, "expected_output": "æœåŠ¡å·²å¯åŠ¨"}, {"task_title": "ç”ŸæˆèŠå¤©å›å¤", "task_description": "ä½¿ç”¨å®¢æˆ·ç«¯ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œè·å–å›å¤ã€‚", "example_code": "from g4f.client import Client\n\nclient = Client()\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"user\", \"content\": \"Hello, how are you?\"}],\n    web_search=False\n)\nprint(response.choices[0].message.content)", "running_command": null, "expected_input": "Hello, how are you?", "expected_output": "æ¨¡å‹çš„å›å¤å†…å®¹"}, {"task_title": "ç”Ÿæˆå›¾åƒ", "task_description": "ä½¿ç”¨å®¢æˆ·ç«¯ç”Ÿæˆå›¾åƒå¹¶è¿”å›å›¾åƒçš„URLã€‚", "example_code": "from g4f.client import Client\n\nclient = Client()\nresponse = client.images.generate(\n    model=\"flux\",\n    prompt=\"a white siamese cat\",\n    response_format=\"url\"\n)\nprint(f\"Generated image URL: {response.data[0].url}\")", "running_command": null, "expected_input": "a white siamese cat", "expected_output": "Generated image URL: <image_url>"}, {"task_title": "å¼‚æ­¥ç”ŸæˆèŠå¤©å›å¤", "task_description": "ä½¿ç”¨å¼‚æ­¥å®¢æˆ·ç«¯ä¸æ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œè·å–å›å¤ã€‚", "example_code": "from g4f.client import AsyncClient\nimport asyncio\n\nasync def main():\n    client = AsyncClient()\n    response = await client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[{\"role\": \"user\", \"content\": \"Explain quantum computing briefly\"}],\n    )\n    print(response.choices[0].message.content)\n\nasyncio.run(main())", "running_command": null, "expected_input": "Explain quantum computing briefly", "expected_output": "æ¨¡å‹çš„å›å¤å†…å®¹"}], "setup": {"setup_commands": ["pip install -U g4f[all]", "git clone https://github.com/xtekky/gpt4free.git\ncd gpt4free\npip install -r requirements.txt\npip install -e .", "pip install -U g4f[all]"], "docker_commands": ["   docker pull hlohaus789/g4f", "   docker run -p 8080:8080 -p 7900:7900 \\\n     --shm-size=\"2g\" \\\n     -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n     -v ${PWD}/generated_media:/app/generated_media \\\n     hlohaus789/g4f:latest", "mkdir -p ${PWD}/har_and_cookies ${PWD}/generated_media\nchown -R 1000:1000 ${PWD}/har_and_cookies ${PWD}/generated_media\n\ndocker run \\\n  -p 1337:8080 -p 8080:8080 \\\n  -v ${PWD}/har_and_cookies:/app/har_and_cookies \\\n  -v ${PWD}/generated_media:/app/generated_media \\\n  hlohaus789/g4f:latest-slim"], "has_docker_files": true}, "timestamp": "2025-10-28T23:05:40.499421"}
{"repo_name": "OpenHands/OpenHands", "stars": 64533, "language": "Python", "tasks": [{"task_title": "Launch the GUI server", "task_description": "å¯åŠ¨OpenHandsçš„GUIæœåŠ¡å™¨ï¼Œæä¾›å›¾å½¢ç”¨æˆ·ç•Œé¢ä¾›ç”¨æˆ·æ“ä½œã€‚", "example_code": null, "running_command": "uvx --python 3.12 --from openhands-ai openhands serve", "expected_input": null, "expected_output": "GUI server is running"}, {"task_title": "Launch the CLI", "task_description": "å¯åŠ¨OpenHandsçš„å‘½ä»¤è¡Œæ¥å£ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡å‘½ä»¤è¡Œè¿›è¡Œæ“ä½œã€‚", "example_code": null, "running_command": "uvx --python 3.12 --from openhands-ai openhands", "expected_input": null, "expected_output": "CLI is ready for commands"}], "setup": {"setup_commands": [], "docker_commands": ["docker pull docker.all-hands.dev/all-hands-ai/runtime:0.59-nikolaik\n\ndocker run -it --rm --pull=always \\\n    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.59-nikolaik \\\n    -e LOG_ALL_EVENTS=true \\\n    -v /var/run/docker.sock:/var/run/docker.sock \\\n    -v ~/.openhands:/.openhands \\\n    -p 3000:3000 \\\n    --add-host host.docker.internal:host-gateway \\\n    --name openhands-app \\\n    docker.all-hands.dev/all-hands-ai/openhands:0.59"], "has_docker_files": true}, "timestamp": "2025-10-28T23:05:48.351145"}
{"repo_name": "PaddlePaddle/PaddleOCR", "stars": 61778, "language": "Python", "tasks": [{"task_title": "Run PP-OCRv5 inference", "task_description": "ä½¿ç”¨PP-OCRv5è¿›è¡ŒOCRæ¨æ–­ï¼Œå¤„ç†å›¾åƒå¹¶æå–æ–‡æœ¬ä¿¡æ¯ã€‚", "example_code": null, "running_command": "paddleocr ocr -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png --use_doc_orientation_classify False --use_doc_unwarping False --use_textline_orientation False", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png", "expected_output": "æå–çš„æ–‡æœ¬ä¿¡æ¯"}, {"task_title": "Run PP-StructureV3 inference", "task_description": "ä½¿ç”¨PP-StructureV3è¿›è¡Œç»“æ„åŒ–æ–‡æ¡£æ¨æ–­ï¼Œå¤„ç†å›¾åƒå¹¶æå–ç»“æ„åŒ–ä¿¡æ¯ã€‚", "example_code": null, "running_command": "paddleocr pp_structurev3 -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png --use_doc_orientation_classify False --use_doc_unwarping False", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png", "expected_output": "æå–çš„ç»“æ„åŒ–ä¿¡æ¯"}, {"task_title": "Run PP-ChatOCRv4 inference", "task_description": "ä½¿ç”¨PP-ChatOCRv4è¿›è¡Œæ–‡æ¡£OCRæ¨æ–­ï¼Œéœ€è¦æä¾›APIå¯†é’¥ä»¥è·å–ç‰¹å®šä¿¡æ¯ã€‚", "example_code": null, "running_command": "paddleocr pp_chatocrv4_doc -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png -k é©¾é©¶å®¤å‡†ä¹˜äººæ•° --qianfan_api_key your_api_key --use_doc_orientation_classify False --use_doc_unwarping False", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png, é©¾é©¶å®¤å‡†ä¹˜äººæ•°, your_api_key", "expected_output": "æŒ‡å®šä¿¡æ¯çš„æå–ç»“æœ"}, {"task_title": "Run PaddleOCR-VL inference", "task_description": "ä½¿ç”¨PaddleOCR-VLè¿›è¡Œæ–‡æ¡£è§£æï¼Œå¤„ç†å›¾åƒå¹¶æå–ä¿¡æ¯ã€‚", "example_code": null, "running_command": "paddleocr doc_parser -i https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png", "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png", "expected_output": "æå–çš„æ–‡æ¡£è§£æç»“æœ"}, {"task_title": "Initialize PaddleOCR instance", "task_description": "åˆå§‹åŒ–PaddleOCRå®ä¾‹ä»¥è¿›è¡ŒOCRæ¨æ–­ã€‚", "example_code": "from paddleocr import PaddleOCR\nocr = PaddleOCR(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False,\n    use_textline_orientation=False)\nresult = ocr.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png\")", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/general_ocr_002.png", "expected_output": "æå–çš„æ–‡æœ¬ä¿¡æ¯"}, {"task_title": "Visualize and save results", "task_description": "å¯è§†åŒ–OCRç»“æœå¹¶å°†å…¶ä¿å­˜ä¸ºå›¾åƒå’ŒJSONæ ¼å¼ã€‚", "example_code": "for res in result:\n    res.print()\n    res.save_to_img(\"output\")\n    res.save_to_json(\"output\")", "running_command": null, "expected_input": "OCRç»“æœ", "expected_output": "å¯è§†åŒ–çš„è¾“å‡ºå›¾åƒå’ŒJSONæ–‡ä»¶"}, {"task_title": "Run PPStructureV3 and save results", "task_description": "ä½¿ç”¨PPStructureV3è¿›è¡Œæ–‡æ¡£ç»“æ„åŒ–æ¨æ–­å¹¶ä¿å­˜ç»“æœã€‚", "example_code": "from paddleocr import PPStructureV3\npipeline = PPStructureV3(\n    use_doc_orientation_classify=False,\n    use_doc_unwarping=False\n)\noutput = pipeline.predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png\",\n)\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"output\")\n    res.save_to_markdown(save_path=\"output\")", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/pp_structure_v3_demo.png", "expected_output": "æå–çš„ç»“æ„åŒ–ä¿¡æ¯å’Œä¿å­˜çš„JSON/Markdownæ–‡ä»¶"}, {"task_title": "Run PPChatOCRv4 with multimodal support", "task_description": "ä½¿ç”¨PPChatOCRv4è¿›è¡Œå¤šæ¨¡æ€æ¨æ–­ï¼Œæ”¯æŒè¡¨æ ¼å’Œå°ç« è¯†åˆ«ã€‚", "example_code": "visual_predict_res = pipeline.visual_predict(\n    input=\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png\",\n    use_common_ocr=True,\n    use_seal_recognition=True,\n    use_table_recognition=True,\n)", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/vehicle_certificate-1.png", "expected_output": "æå–çš„è§†è§‰ä¿¡æ¯"}, {"task_title": "Run PaddleOCRVL inference", "task_description": "ä½¿ç”¨PaddleOCR-VLè¿›è¡Œè§†è§‰è¯­è¨€æ¨æ–­ï¼Œå¤„ç†å›¾åƒå¹¶æå–ä¿¡æ¯ã€‚", "example_code": "from paddleocr import PaddleOCRVL\npipeline = PaddleOCRVL()\noutput = pipeline.predict(\"https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png\")\nfor res in output:\n    res.print()\n    res.save_to_json(save_path=\"output\")\n    res.save_to_markdown(save_path=\"output\")", "running_command": null, "expected_input": "https://paddle-model-ecology.bj.bcebos.com/paddlex/imgs/demo_image/paddleocr_vl_demo.png", "expected_output": "æå–çš„è§†è§‰è¯­è¨€ä¿¡æ¯å’Œä¿å­˜çš„JSON/Markdownæ–‡ä»¶"}], "setup": {"setup_commands": ["# If you only want to use the basic text recognition feature (returns text position coordinates and content), including the PP-OCR series\npython -m pip install paddleocr\n# If you want to use all features such as document parsing, document understanding, document translation, key information extraction, etc.\n# python -m pip install \"paddleocr[all]\""], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:06:27.454972"}
{"repo_name": "hiyouga/LLaMA-Factory", "stars": 61011, "language": "Python", "tasks": [{"task_title": "åŒæ­¥é¢å¤–ä¾èµ–", "task_description": "ä½¿ç”¨uvå·¥å…·åŒæ­¥é¢å¤–çš„torchå’Œmetricsä¾èµ–ï¼Œå…è®¸é¢„å‘å¸ƒç‰ˆæœ¬ã€‚", "example_code": null, "running_command": "uv sync --extra torch --extra metrics --prerelease=allow", "expected_input": null, "expected_output": null}, {"task_title": "è®­ç»ƒLLaMAæ¨¡å‹ï¼ˆé¢„è®­ç»ƒï¼‰", "task_description": "ä½¿ç”¨llamafactory-cliå‘½ä»¤è¡Œå·¥å…·è®­ç»ƒLLaMAæ¨¡å‹ï¼Œé…ç½®æ–‡ä»¶ä¸ºllama3_lora_pretrain.yamlï¼Œå…è®¸é¢„å‘å¸ƒç‰ˆæœ¬ã€‚", "example_code": null, "running_command": "uv run --prerelease=allow llamafactory-cli train examples/train_lora/llama3_lora_pretrain.yaml", "expected_input": null, "expected_output": null}, {"task_title": "è®­ç»ƒLLaMAæ¨¡å‹ï¼ˆå¾®è°ƒï¼‰", "task_description": "ä½¿ç”¨llamafactory-cliå‘½ä»¤è¡Œå·¥å…·è®­ç»ƒLLaMAæ¨¡å‹ï¼Œé…ç½®æ–‡ä»¶ä¸ºllama3_lora_sft.yamlã€‚", "example_code": null, "running_command": "llamafactory-cli train examples/train_lora/llama3_lora_sft.yaml", "expected_input": null, "expected_output": null}, {"task_title": "ä¸LLaMAæ¨¡å‹å¯¹è¯", "task_description": "ä½¿ç”¨llamafactory-cliå‘½ä»¤è¡Œå·¥å…·ä¸LLaMAæ¨¡å‹è¿›è¡Œå¯¹è¯ï¼Œé…ç½®æ–‡ä»¶ä¸ºllama3_lora_sft.yamlã€‚", "example_code": null, "running_command": "llamafactory-cli chat examples/inference/llama3_lora_sft.yaml", "expected_input": null, "expected_output": null}, {"task_title": "å¯¼å‡ºLLaMAæ¨¡å‹", "task_description": "ä½¿ç”¨llamafactory-cliå‘½ä»¤è¡Œå·¥å…·å¯¼å‡ºLLaMAæ¨¡å‹ï¼Œé…ç½®æ–‡ä»¶ä¸ºllama3_lora_sft.yamlã€‚", "example_code": null, "running_command": "llamafactory-cli export examples/merge_lora/llama3_lora_sft.yaml", "expected_input": null, "expected_output": null}, {"task_title": "å¯åŠ¨Webç•Œé¢", "task_description": "ä½¿ç”¨llamafactory-cliå‘½ä»¤è¡Œå·¥å…·å¯åŠ¨LLaMAæ¨¡å‹çš„Webç•Œé¢ã€‚", "example_code": null, "running_command": "llamafactory-cli webui", "expected_input": null, "expected_output": null}, {"task_title": "å¯åŠ¨Dockerå®¹å™¨ï¼ˆCUDAï¼‰", "task_description": "è¿›å…¥docker/docker-cudaç›®å½•ï¼Œå¯åŠ¨Dockerå®¹å™¨ã€‚", "example_code": null, "running_command": "cd docker/docker-cuda/ && docker compose up -d && docker compose exec llamafactory bash", "expected_input": null, "expected_output": null}, {"task_title": "å¯åŠ¨Dockerå®¹å™¨ï¼ˆNPUï¼‰", "task_description": "è¿›å…¥docker/docker-npuç›®å½•ï¼Œå¯åŠ¨Dockerå®¹å™¨ã€‚", "example_code": null, "running_command": "cd docker/docker-npu/ && docker compose up -d && docker compose exec llamafactory bash", "expected_input": null, "expected_output": null}, {"task_title": "å¯åŠ¨Dockerå®¹å™¨ï¼ˆROCMï¼‰", "task_description": "è¿›å…¥docker/docker-rocmç›®å½•ï¼Œå¯åŠ¨Dockerå®¹å™¨ã€‚", "example_code": null, "running_command": "cd docker/docker-rocm/ && docker compose up -d && docker compose exec llamafactory bash", "expected_input": null, "expected_output": null}, {"task_title": "å¯åŠ¨APIæœåŠ¡", "task_description": "ä½¿ç”¨llamafactory-cliå‘½ä»¤è¡Œå·¥å…·å¯åŠ¨APIæœåŠ¡ï¼Œé…ç½®æ–‡ä»¶ä¸ºllama3.yamlï¼Œè®¾ç½®æ¨ç†åç«¯ä¸ºvllmã€‚", "example_code": null, "running_command": "API_PORT=8000 llamafactory-cli api examples/inference/llama3.yaml infer_backend=vllm vllm_enforce_eager=true", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨ModelScope Hub", "task_description": "è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨ModelScope Hubã€‚", "example_code": null, "running_command": "export USE_MODELSCOPE_HUB=1", "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨OpenMind Hub", "task_description": "è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨OpenMind Hubã€‚", "example_code": null, "running_command": "export USE_OPENMIND_HUB=1", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["pip install --upgrade huggingface_hub\nhuggingface-cli login", "git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\ncd LLaMA-Factory\npip install -e \".[torch,metrics]\" --no-build-isolation", "pip uninstall torch torchvision torchaudio\npip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126\npython -c \"import torch; print(torch.cuda.is_available())\"", "pip install https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.41.2.post2-py3-none-win_amd64.whl", "# replace the url according to your CANN version and devices\n# install CANN Toolkit\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-toolkit_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# install CANN Kernels\nwget https://ascend-repo.obs.cn-east-2.myhuaweicloud.com/Milan-ASL/Milan-ASL%20V100R001C20SPC702/Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run\nbash Ascend-cann-kernels-910b_8.0.0.alpha002_linux-\"$(uname -i)\".run --install\n\n# set env variables\nsource /usr/local/Ascend/ascend-toolkit/set_env.sh", "# Install bitsandbytes from source\n# Clone bitsandbytes repo, Ascend NPU backend is currently enabled on multi-backend-refactor branch\ngit clone -b multi-backend-refactor https://github.com/bitsandbytes-foundation/bitsandbytes.git\ncd bitsandbytes/\n\n# Install dependencies\npip install -r requirements-dev.txt\n\n# Install the dependencies for the compilation tools. Note that the commands for this step may vary depending on the operating system. The following are provided for reference\napt-get install -y build-essential cmake\n\n# Compile & install  \ncmake -DCOMPUTE_BACKEND=npu -S .\nmake\npip install .", "git clone -b main https://github.com/huggingface/transformers.git\ncd transformers\npip install ."], "docker_commands": ["docker run -it --rm --gpus=all --ipc=host hiyouga/llamafactory:latest", "docker build -f ./docker/docker-cuda/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host --gpus=all \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash", "docker build -f ./docker/docker-npu/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=torch-npu,metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -v /usr/local/dcmi:/usr/local/dcmi \\\n    -v /usr/local/bin/npu-smi:/usr/local/bin/npu-smi \\\n    -v /usr/local/Ascend/driver:/usr/local/Ascend/driver \\\n    -v /etc/ascend_install.info:/etc/ascend_install.info \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/davinci0 \\\n    --device /dev/davinci_manager \\\n    --device /dev/devmm_svm \\\n    --device /dev/hisi_hdc \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash", "docker build -f ./docker/docker-rocm/Dockerfile \\\n    --build-arg PIP_INDEX=https://pypi.org/simple \\\n    --build-arg EXTRAS=metrics \\\n    -t llamafactory:latest .\n\ndocker run -dit --ipc=host \\\n    -p 7860:7860 \\\n    -p 8000:8000 \\\n    --device /dev/kfd \\\n    --device /dev/dri \\\n    --name llamafactory \\\n    llamafactory:latest\n\ndocker exec -it llamafactory bash"], "has_docker_files": true}, "timestamp": "2025-10-28T23:06:49.636201"}
{"repo_name": "localstack/localstack", "stars": 60991, "language": "Python", "tasks": [{"task_title": "å¯åŠ¨LocalStack", "task_description": "ä½¿ç”¨LocalStack CLIå¯åŠ¨LocalStackæœåŠ¡ï¼Œè¿è¡Œåœ¨Dockeræ¨¡å¼ä¸‹ã€‚", "example_code": null, "running_command": "localstack start -d", "expected_input": null, "expected_output": "starting LocalStack in Docker mode ğŸ³"}, {"task_title": "æŸ¥çœ‹æœåŠ¡çŠ¶æ€", "task_description": "ä½¿ç”¨LocalStack CLIæ£€æŸ¥å½“å‰å¯ç”¨çš„æœåŠ¡åŠå…¶çŠ¶æ€ã€‚", "example_code": null, "running_command": "localstack status services", "expected_input": null, "expected_output": "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\nâ”ƒ Service                  â”ƒ Status      â”ƒ\nâ”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\nâ”‚ acm                      â”‚ âœ” available â”‚\nâ”‚ apigateway               â”‚ âœ” available â”‚\nâ”‚ cloudformation           â”‚ âœ” available â”‚\nâ”‚ cloudwatch               â”‚ âœ” available â”‚\nâ”‚ config                   â”‚ âœ” available â”‚\nâ”‚ dynamodb                 â”‚ âœ” available â”‚\n..."}, {"task_title": "åˆ›å»ºSQSé˜Ÿåˆ—", "task_description": "ä½¿ç”¨awslocalå‘½ä»¤åˆ›å»ºä¸€ä¸ªæ–°çš„SQSé˜Ÿåˆ—ï¼ŒæŒ‡å®šé˜Ÿåˆ—åç§°ã€‚", "example_code": null, "running_command": "awslocal sqs create-queue --queue-name sample-queue", "expected_input": "sample-queue", "expected_output": "{\n    \"QueueUrl\": \"http://sqs.us-east-1.localhost.localstack.cloud:4566/000000000000/sample-queue\"\n}"}], "setup": {"setup_commands": ["brew install localstack/tap/localstack-cli", "python3 -m pip install localstack"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:06:59.608366"}
{"repo_name": "openinterpreter/open-interpreter", "stars": 60723, "language": "Python", "tasks": [{"task_title": "Chat with Interpreter", "task_description": "ä¸è§£é‡Šå™¨è¿›è¡Œå¯¹è¯ï¼Œæ‰§è¡Œå•ä¸ªå‘½ä»¤æˆ–å¼€å§‹äº¤äº’å¼èŠå¤©ã€‚", "example_code": "interpreter.chat(\"Plot AAPL and META's normalized stock prices\")", "running_command": null, "expected_input": "Plot AAPL and META's normalized stock prices", "expected_output": "æ‰§è¡Œç»˜åˆ¶AAPLå’ŒMETAçš„æ ‡å‡†åŒ–è‚¡ä»·çš„å‘½ä»¤"}, {"task_title": "Stream Chat Response", "task_description": "é€šè¿‡æµå¼å“åº”ä»è§£é‡Šå™¨è·å–æ¶ˆæ¯ã€‚", "example_code": "for chunk in interpreter.chat(message, display=False, stream=True):\n  print(chunk)", "running_command": null, "expected_input": "What operating system are we on?", "expected_output": "æ“ä½œç³»ç»Ÿçš„ç›¸å…³ä¿¡æ¯"}, {"task_title": "Add Subtitles to Videos", "task_description": "ä¸ºæŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰è§†é¢‘æ·»åŠ å­—å¹•ã€‚", "example_code": "interpreter.chat(\"Add subtitles to all videos in /videos.\")", "running_command": null, "expected_input": "Add subtitles to all videos in /videos.", "expected_output": "ä¸º/videosä¸­çš„æ‰€æœ‰è§†é¢‘æ·»åŠ å­—å¹•"}, {"task_title": "Reset and Resume Chat", "task_description": "é‡ç½®è§£é‡Šå™¨çš„æ¶ˆæ¯å¹¶æ¢å¤å…ˆå‰çš„èŠå¤©è®°å½•ã€‚", "example_code": "messages = interpreter.chat(\"My name is Killian.\")\ninterpreter.messages = []\ninterpreter.messages = messages", "running_command": null, "expected_input": "My name is Killian.", "expected_output": "å°†'Killian'çš„æ¶ˆæ¯æ¢å¤åˆ°èŠå¤©è®°å½•ä¸­"}, {"task_title": "Modify System Message", "task_description": "ä¿®æ”¹ç³»ç»Ÿæ¶ˆæ¯ä»¥è¿è¡Œä¸éœ€è¦ç”¨æˆ·ç¡®è®¤çš„shellå‘½ä»¤ã€‚", "example_code": "interpreter.system_message += \"\"\nRun shell commands with -y so the user doesn't have to confirm them.\n\"\"", "running_command": null, "expected_input": null, "expected_output": "ç³»ç»Ÿæ¶ˆæ¯å·²æ›´æ–°"}, {"task_title": "Set LLM Model", "task_description": "è®¾ç½®ä½¿ç”¨çš„è¯­è¨€æ¨¡å‹ã€‚", "example_code": "interpreter.llm.model = \"gpt-3.5-turbo\"", "running_command": null, "expected_input": null, "expected_output": "LLMæ¨¡å‹è®¾ç½®ä¸ºgpt-3.5-turbo"}, {"task_title": "Chat API Endpoint", "task_description": "é€šè¿‡FastAPIåˆ›å»ºä¸€ä¸ªèŠå¤©APIç«¯ç‚¹ï¼Œå¤„ç†æ¶ˆæ¯å¹¶æµå¼è¿”å›ç»“æœã€‚", "example_code": "app = FastAPI()\n@app.get(\"/chat\")\ndef chat_endpoint(message: str):\n    ...", "running_command": null, "expected_input": "message", "expected_output": "æµå¼è¿”å›èŠå¤©ç»“æœ"}, {"task_title": "Enable Verbose Mode", "task_description": "åœ¨å‘½ä»¤è¡Œä¸­å¯ç”¨æˆ–ç¦ç”¨è¯¦ç»†æ¨¡å¼ã€‚", "example_code": null, "running_command": "> %verbose true", "expected_input": null, "expected_output": "è¯¦ç»†æ¨¡å¼å·²å¯ç”¨"}], "setup": {"setup_commands": ["pip install git+https://github.com/OpenInterpreter/open-interpreter.git", "pip install open-interpreter", "pip install fastapi uvicorn\nuvicorn server:app --reload"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:07:12.133094"}
{"repo_name": "FoundationAgents/MetaGPT", "stars": 59129, "language": "Python", "tasks": [{"task_title": "åˆå§‹åŒ–é…ç½®", "task_description": "è¯¥ä»»åŠ¡ç”¨äºåˆå§‹åŒ–MetaGPTçš„é…ç½®æ–‡ä»¶ï¼Œç”Ÿæˆé»˜è®¤é…ç½®æ–‡ä»¶ä»¥ä¾›ç”¨æˆ·ä¿®æ”¹ã€‚", "example_code": null, "running_command": "metagpt --init-config", "expected_input": null, "expected_output": "åˆ›å»º ~/.metagpt/config2.yaml æ–‡ä»¶"}], "setup": {"setup_commands": ["pip install --upgrade metagpt\n# or `pip install --upgrade git+https://github.com/geekan/MetaGPT.git`\n# or `git clone https://github.com/geekan/MetaGPT && cd MetaGPT && pip install --upgrade -e .`"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:07:18.976568"}
{"repo_name": "meta-llama/llama", "stars": 58883, "language": "Python", "tasks": [{"task_title": "Chat Completion", "task_description": "è¯¥ä»»åŠ¡ç”¨äºç”ŸæˆèŠå¤©å›å¤ï¼Œä½¿ç”¨äº†æŒ‡å®šçš„æ¨¡å‹å’Œåˆ†è¯å™¨ï¼Œæ”¯æŒè®¾ç½®æœ€å¤§åºåˆ—é•¿åº¦å’Œæ‰¹å¤„ç†å¤§å°ã€‚", "example_code": null, "running_command": "torchrun --nproc_per_node 1 example_chat_completion.py --ckpt_dir llama-2-7b-chat/ --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 6", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["    pip install -e ."], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:07:25.912682"}
{"repo_name": "soimort/you-get", "stars": 56519, "language": "Python", "tasks": [{"task_title": "ä¸‹è½½YouTubeè§†é¢‘", "task_description": "ä½¿ç”¨you-getåº“ä»YouTubeä¸‹è½½è§†é¢‘ï¼ŒæŒ‡å®šè§†é¢‘çš„URLã€‚", "example_code": null, "running_command": "you-get 'https://www.youtube.com/watch?v=jNQXAC9IVRw'", "expected_input": "https://www.youtube.com/watch?v=jNQXAC9IVRw", "expected_output": "site:                YouTube\ntitle:               Me at the zoo\nstream:\n    - itag:          43\n      container:     webm\n      quality:       medium\n      size:          0.5 MiB (564215 bytes)\nDownloading Me at the zoo.webm ...\n 100% (  0.5/  0.5MB) â”œâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ”¤[1/1]    6 MB/s\nSaving Me at the zoo.en.srt ... Done."}], "setup": {"setup_commands": ["pip install you-get", "[sudo] python -m pip install .", "python -m pip install . --user", "git clone git://github.com/soimort/you-get.git", "brew install you-get", "pip install --upgrade you-get", "pip install --upgrade --force-reinstall git+https://github.com/soimort/you-get@develop"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:07:43.901560"}
{"repo_name": "ultralytics/yolov5", "stars": 55837, "language": "Python", "tasks": [{"task_title": "Load a YOLOv5 model", "task_description": "åŠ è½½YOLOv5æ¨¡å‹ä»¥è¿›è¡Œæ¨ç†ï¼Œæ”¯æŒä¸åŒçš„æ¨¡å‹é€‰é¡¹ã€‚", "example_code": "import torch\n\nmodel = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")", "running_command": null, "expected_input": null, "expected_output": "æ¨¡å‹å¯¹è±¡"}, {"task_title": "Perform inference", "task_description": "å¯¹è¾“å…¥å›¾åƒè¿›è¡Œæ¨ç†ï¼Œè‡ªåŠ¨å¤„ç†æ‰¹é‡ã€è°ƒæ•´å¤§å°å’Œå½’ä¸€åŒ–ã€‚", "example_code": "results = model(img)", "running_command": null, "expected_input": "https://ultralytics.com/images/zidane.jpg", "expected_output": "æ¨ç†ç»“æœå¯¹è±¡"}, {"task_title": "Process inference results", "task_description": "å¤„ç†æ¨ç†ç»“æœï¼Œæ”¯æŒæ‰“å°ã€æ˜¾ç¤ºã€ä¿å­˜ç­‰åŠŸèƒ½ã€‚", "example_code": "results.print()\nresults.show()\nresults.save()", "running_command": null, "expected_input": null, "expected_output": "ç»“æœæ‰“å°åˆ°æ§åˆ¶å°ã€æ˜¾ç¤ºåœ¨çª—å£æˆ–ä¿å­˜åˆ°æ–‡ä»¶"}, {"task_title": "Run inference using a webcam", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ä»æ‘„åƒå¤´è¿›è¡Œæ¨ç†ã€‚", "example_code": null, "running_command": "python detect.py --weights yolov5s.pt --source 0", "expected_input": null, "expected_output": "å®æ—¶æ¨ç†ç»“æœ"}, {"task_title": "Run inference on a local image file", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·å¯¹æœ¬åœ°å›¾åƒæ–‡ä»¶è¿›è¡Œæ¨ç†ã€‚", "example_code": null, "running_command": "python detect.py --weights yolov5s.pt --source img.jpg", "expected_input": "img.jpg", "expected_output": "æ¨ç†ç»“æœ"}, {"task_title": "Train YOLOv5 model", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·è®­ç»ƒYOLOv5æ¨¡å‹ï¼ŒæŒ‡å®šæ•°æ®é›†å’Œè®­ç»ƒå‚æ•°ã€‚", "example_code": null, "running_command": "python train.py --data coco.yaml --epochs 300 --weights '' --cfg yolov5s.yaml --batch-size 64", "expected_input": null, "expected_output": "è®­ç»ƒè¿‡ç¨‹æ—¥å¿—å’Œæœ€ç»ˆæ¨¡å‹"}, {"task_title": "Validate the model", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·éªŒè¯è®­ç»ƒåçš„æ¨¡å‹ã€‚", "example_code": null, "running_command": "python segment/val.py --weights yolov5s-seg.pt --data coco.yaml --img 640", "expected_input": null, "expected_output": "éªŒè¯ç»“æœå’Œæ€§èƒ½æŒ‡æ ‡"}, {"task_title": "Run prediction", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·å¯¹æŒ‡å®šå›¾åƒè¿›è¡Œé¢„æµ‹ã€‚", "example_code": null, "running_command": "python segment/predict.py --weights yolov5m-seg.pt --source data/images/bus.jpg", "expected_input": "data/images/bus.jpg", "expected_output": "é¢„æµ‹ç»“æœ"}, {"task_title": "Export model", "task_description": "å°†è®­ç»ƒå¥½çš„æ¨¡å‹å¯¼å‡ºä¸ºå…¶ä»–æ ¼å¼ã€‚", "example_code": null, "running_command": "python export.py --weights yolov5s-seg.pt --include onnx engine --img 640 --device 0", "expected_input": null, "expected_output": "å¯¼å‡ºçš„æ¨¡å‹æ–‡ä»¶"}], "setup": {"setup_commands": ["# Install the ultralytics package\npip install ultralytics", "# Clone the YOLOv5 repository\ngit clone https://github.com/ultralytics/yolov5\n\n# Navigate to the cloned directory\ncd yolov5\n\n# Install required packages\npip install -r requirements.txt"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:07:58.353861"}
{"repo_name": "ageitgey/face_recognition", "stars": 55644, "language": "Python", "tasks": [{"task_title": "è·å–äººè„¸ä½ç½®", "task_description": "åŠ è½½å›¾åƒå¹¶è·å–å›¾åƒä¸­æ‰€æœ‰äººè„¸çš„ä½ç½®åæ ‡ã€‚", "example_code": "import face_recognition\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_locations = face_recognition.face_locations(image)", "running_command": null, "expected_input": "my_picture.jpg", "expected_output": "[[top, right, bottom, left], ...]"}, {"task_title": "è·å–äººè„¸ç‰¹å¾ç‚¹", "task_description": "åŠ è½½å›¾åƒå¹¶è·å–å›¾åƒä¸­æ‰€æœ‰äººè„¸çš„ç‰¹å¾ç‚¹ä½ç½®ã€‚", "example_code": "import face_recognition\nimage = face_recognition.load_image_file(\"my_picture.jpg\")\nface_landmarks_list = face_recognition.face_landmarks(image)", "running_command": null, "expected_input": "my_picture.jpg", "expected_output": "[{'left_eye': [(x, y), ...], ...}, ...]"}, {"task_title": "äººè„¸ç¼–ç ", "task_description": "åŠ è½½å·²çŸ¥å’ŒæœªçŸ¥å›¾åƒï¼Œç”Ÿæˆå…¶äººè„¸ç¼–ç ä»¥è¿›è¡Œæ¯”è¾ƒã€‚", "example_code": "import face_recognition\nknown_image = face_recognition.load_image_file(\"biden.jpg\")\nunknown_image = face_recognition.load_image_file(\"unknown.jpg\")\nbiden_encoding = face_recognition.face_encodings(known_image)[0]\nunknown_encoding = face_recognition.face_encodings(unknown_image)[0]\nresults = face_recognition.compare_faces([biden_encoding], unknown_encoding)", "running_command": null, "expected_input": "biden.jpg, unknown.jpg", "expected_output": "[True/False]"}, {"task_title": "æ‰¹é‡äººè„¸è¯†åˆ«", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·è¿›è¡Œæ‰¹é‡äººè„¸è¯†åˆ«ï¼Œè¯†åˆ«å·²çŸ¥å’ŒæœªçŸ¥å›¾åƒä¸­çš„äººè„¸ã€‚", "example_code": null, "running_command": "face_recognition ./pictures_of_people_i_know/ ./unknown_pictures/", "expected_input": "./pictures_of_people_i_know/, ./unknown_pictures/", "expected_output": "/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person"}, {"task_title": "äººè„¸è¯†åˆ«ä¸è·ç¦»", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·è¿›è¡Œäººè„¸è¯†åˆ«å¹¶æ˜¾ç¤ºç›¸ä¼¼åº¦è·ç¦»ã€‚", "example_code": null, "running_command": "face_recognition --show-distance true ./pictures_of_people_i_know/ ./unknown_pictures/", "expected_input": "./pictures_of_people_i_know/, ./unknown_pictures/", "expected_output": "/unknown_pictures/unknown.jpg,Barack Obama,0.378542298956785\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person,None"}, {"task_title": "ä½¿ç”¨å¤šæ ¸å¤„ç†è¿›è¡Œäººè„¸è¯†åˆ«", "task_description": "ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·å¹¶æŒ‡å®šä½¿ç”¨å¤šä¸ªCPUè¿›è¡Œäººè„¸è¯†åˆ«ã€‚", "example_code": null, "running_command": "face_recognition --cpus 4 ./pictures_of_people_i_know/ ./unknown_pictures/", "expected_input": "./pictures_of_people_i_know/, ./unknown_pictures/", "expected_output": "/unknown_pictures/unknown.jpg,Barack Obama\n/face_recognition_test/unknown_pictures/unknown.jpg,unknown_person"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:08:14.977209"}
{"repo_name": "Textualize/rich", "stars": 54204, "language": "Python", "tasks": [{"task_title": "æ‰“å°å¸¦æ ·å¼çš„æ–‡æœ¬", "task_description": "ä½¿ç”¨Richåº“çš„printåŠŸèƒ½æ‰“å°å¸¦æœ‰æ ·å¼çš„æ–‡æœ¬ã€‚", "example_code": "from rich import print\n\nprint(\"Hello, [bold magenta]World[/bold magenta]!\")", "running_command": null, "expected_input": null, "expected_output": "Hello, World! (with 'World' in bold magenta)"}, {"task_title": "å®‰è£…Prettyæ‰“å°", "task_description": "ä½¿ç”¨Prettyæ¨¡å—å®‰è£…Richçš„Prettyæ‰“å°åŠŸèƒ½ã€‚", "example_code": "from rich import pretty\npretty.install()", "running_command": null, "expected_input": null, "expected_output": null}, {"task_title": "åˆ›å»ºæ§åˆ¶å°å¯¹è±¡", "task_description": "åˆ›å»ºä¸€ä¸ªRichæ§åˆ¶å°å¯¹è±¡ä»¥ç”¨äºæ‰“å°ã€‚", "example_code": "from rich.console import Console\n\nconsole = Console()", "running_command": null, "expected_input": null, "expected_output": null}, {"task_title": "æ‰“å°å¤šä¸ªæ–‡æœ¬", "task_description": "ä½¿ç”¨æ§åˆ¶å°å¯¹è±¡æ‰“å°å¤šä¸ªæ–‡æœ¬ã€‚", "example_code": "console.print(\"Hello\", \"World!\")", "running_command": null, "expected_input": null, "expected_output": "Hello World!"}, {"task_title": "æ‰“å°å¸¦æ ·å¼çš„æ–‡æœ¬", "task_description": "ä½¿ç”¨æ§åˆ¶å°å¯¹è±¡æ‰“å°å¸¦æ ·å¼çš„æ–‡æœ¬ã€‚", "example_code": "console.print(\"Hello\", \"World!\", style=\"bold red\")", "running_command": null, "expected_input": null, "expected_output": "Hello World! (with 'Hello' in bold red)"}, {"task_title": "æ‰“å°å¸¦æ ¼å¼çš„æ–‡æœ¬", "task_description": "ä½¿ç”¨æ§åˆ¶å°å¯¹è±¡æ‰“å°å¸¦æœ‰å¤šç§æ ·å¼çš„æ–‡æœ¬ã€‚", "example_code": "console.print(\"Where there is a [bold cyan]Will[/bold cyan] there [u]is[/u] a [i]way[/i].\")", "running_command": null, "expected_input": null, "expected_output": "Where there is a Will there is a way. (with styles applied)"}, {"task_title": "æ£€æŸ¥å¯¹è±¡çš„å±æ€§å’Œæ–¹æ³•", "task_description": "ä½¿ç”¨inspectåŠŸèƒ½æ£€æŸ¥åˆ—è¡¨å¯¹è±¡çš„å±æ€§å’Œæ–¹æ³•ã€‚", "example_code": "my_list = [\"foo\", \"bar\"]\nfrom rich import inspect\ninspect(my_list, methods=True)", "running_command": null, "expected_input": null, "expected_output": "Display of the 'my_list' object's attributes and methods."}, {"task_title": "è®°å½•ä¿¡æ¯", "task_description": "ä½¿ç”¨æ§åˆ¶å°å¯¹è±¡è®°å½•ä¿¡æ¯å’Œæœ¬åœ°å˜é‡ã€‚", "example_code": "console.log(test_data, log_locals=True)", "running_command": null, "expected_input": null, "expected_output": "Log output of test_data with local variables."}, {"task_title": "æ‰“å°è¡¨æ ¼", "task_description": "ä½¿ç”¨Richåº“æ‰“å°æ ¼å¼åŒ–çš„è¡¨æ ¼ã€‚", "example_code": "from rich.table import Table\n\n...\ntable.add_row(...)\nconsole.print(table)", "running_command": null, "expected_input": null, "expected_output": "Formatted table displaying movie data."}, {"task_title": "è·Ÿè¸ªè¿›åº¦", "task_description": "ä½¿ç”¨trackåŠŸèƒ½æ˜¾ç¤ºè¿›åº¦æ¡ã€‚", "example_code": "from rich.progress import track\n\nfor step in track(range(100)):\n    do_step(step)", "running_command": null, "expected_input": null, "expected_output": "Progress bar indicating completion of steps."}, {"task_title": "æ˜¾ç¤ºä»»åŠ¡çŠ¶æ€", "task_description": "ä½¿ç”¨çŠ¶æ€ä¸Šä¸‹æ–‡æ˜¾ç¤ºä»»åŠ¡è¿›å±•ã€‚", "example_code": "with console.status(\"[bold green]Working on tasks...\") as status:\n    ...\n    console.log(f\"{task} complete\")", "running_command": null, "expected_input": null, "expected_output": "Log messages indicating task completion."}, {"task_title": "æ‰“å°ç›®å½•å†…å®¹", "task_description": "æ‰“å°æŒ‡å®šç›®å½•çš„æ–‡ä»¶åˆ—è¡¨ã€‚", "example_code": "directory = os.listdir(sys.argv[1])\nprint(Columns(directory))", "running_command": null, "expected_input": "Directory path", "expected_output": "Formatted list of files in the specified directory."}, {"task_title": "æ‰“å°Markdownå†…å®¹", "task_description": "è¯»å–å¹¶æ‰“å°Markdownæ–‡ä»¶å†…å®¹ã€‚", "example_code": "with open(\"README.md\") as readme:\n    markdown = Markdown(readme.read())\nconsole.print(markdown)", "running_command": null, "expected_input": "README.md file", "expected_output": "Formatted Markdown content from the README file."}, {"task_title": "æ‰“å°ä»£ç è¯­æ³•é«˜äº®", "task_description": "ä½¿ç”¨SyntaxåŠŸèƒ½æ‰“å°å¸¦è¯­æ³•é«˜äº®çš„ä»£ç ç‰‡æ®µã€‚", "example_code": "syntax = Syntax(my_code, \"python\", theme=\"monokai\", line_numbers=True)\nconsole.print(syntax)", "running_command": null, "expected_input": "Python code string", "expected_output": "Formatted code with syntax highlighting."}], "setup": {"setup_commands": ["python -m pip install rich"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:09:19.598059"}
{"repo_name": "OpenBB-finance/OpenBB", "stars": 53955, "language": "Python", "tasks": [{"task_title": "è·å–å†å²è‚¡ç¥¨ä»·æ ¼", "task_description": "æ­¤ä»»åŠ¡ç”¨äºè·å–æŒ‡å®šè‚¡ç¥¨ï¼ˆå¦‚AAPLï¼‰çš„å†å²ä»·æ ¼æ•°æ®ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºDataFrameæ ¼å¼ã€‚", "example_code": "from openbb import obb\noutput = obb.equity.price.historical(\"AAPL\")\ndf = output.to_dataframe()", "running_command": null, "expected_input": "AAPL", "expected_output": "DataFrameåŒ…å«AAPLçš„å†å²ä»·æ ¼æ•°æ®"}], "setup": {"setup_commands": ["pip install \"openbb[all]\""], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:09:26.018304"}
{"repo_name": "psf/requests", "stars": 53420, "language": "Python", "tasks": [{"task_title": "åŸºæœ¬è®¤è¯è¯·æ±‚", "task_description": "ä½¿ç”¨åŸºæœ¬è®¤è¯å‘é€GETè¯·æ±‚ï¼Œå¹¶è·å–å“åº”çš„çŠ¶æ€ç ã€å¤´éƒ¨ã€ç¼–ç ã€æ–‡æœ¬å’ŒJSONæ•°æ®ã€‚", "example_code": "import requests\n\nr = requests.get('https://httpbin.org/basic-auth/user/pass', auth=('user', 'pass'))\n\nr.status_code\nr.headers['content-type']\nr.encoding\nr.text\nr.json()", "running_command": null, "expected_input": "https://httpbin.org/basic-auth/user/pass, ('user', 'pass')", "expected_output": "200, 'application/json; charset=utf8', 'utf-8', '{\"authenticated\": true, ...}', {'authenticated': True, ...}"}], "setup": {"setup_commands": ["$ python -m pip install requests", "git clone -c fetch.fsck.badTimezone=ignore https://github.com/psf/requests.git"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:09:38.501439"}
{"repo_name": "RVC-Boss/GPT-SoVITS", "stars": 51888, "language": "Python", "tasks": [{"task_title": "éŸ³é¢‘åˆ‡ç‰‡", "task_description": "è¯¥ä»»åŠ¡ç”¨äºå°†åŸå§‹éŸ³é¢‘æ–‡ä»¶æˆ–ç›®å½•ä¸­çš„éŸ³é¢‘åˆ†å‰²æˆå¤šä¸ªå­ç‰‡æ®µï¼ŒåŸºäºéŸ³é‡é˜ˆå€¼ã€æœ€å°é•¿åº¦å’Œæœ€å°é—´éš”ç­‰å‚æ•°ã€‚", "example_code": null, "running_command": "python audio_slicer.py", "expected_input": "<path_to_original_audio_file_or_directory>, <directory_where_subdivided_audio_clips_will_be_saved>, <volume_threshold>, <minimum_duration_of_each_subclip>, <shortest_time_gap_between_adjacent_subclips>, <step_size_for_computing_volume_curve>", "expected_output": "åˆ†å‰²åçš„éŸ³é¢‘ç‰‡æ®µä¿å­˜åœ¨æŒ‡å®šç›®å½•ä¸­"}, {"task_title": "è¯­éŸ³è¯†åˆ«", "task_description": "è¯¥ä»»åŠ¡ç”¨äºå¯¹è¾“å…¥éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œå¹¶å°†è¯†åˆ«ç»“æœè¾“å‡ºåˆ°æŒ‡å®šæ–‡ä»¶ã€‚", "example_code": null, "running_command": "python tools/asr/funasr_asr.py", "expected_input": "<input>, <output>", "expected_output": "è¯†åˆ«çš„æ–‡æœ¬ç»“æœä¿å­˜åœ¨è¾“å‡ºæ–‡ä»¶ä¸­"}, {"task_title": "å¿«é€Ÿè¯­éŸ³è¯†åˆ«", "task_description": "è¯¥ä»»åŠ¡ç”¨äºå¿«é€Ÿè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œæ”¯æŒæŒ‡å®šè¯­è¨€å’Œç²¾åº¦é€‰é¡¹ã€‚", "example_code": null, "running_command": "python ./tools/asr/fasterwhisper_asr.py", "expected_input": "<input>, <output>, <language>, <precision>", "expected_output": "è¯†åˆ«çš„æ–‡æœ¬ç»“æœä¿å­˜åœ¨è¾“å‡ºæ–‡ä»¶ä¸­"}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:09:48.281137"}
{"repo_name": "microsoft/autogen", "stars": 51187, "language": "Python", "tasks": [{"task_title": "ç®€å•çš„åŠ©æ‰‹ä»»åŠ¡", "task_description": "ä½¿ç”¨OpenAIæ¨¡å‹åˆ›å»ºä¸€ä¸ªåŠ©æ‰‹ä»£ç†å¹¶æ‰§è¡Œç®€å•çš„ä»»åŠ¡ï¼Œè¾“å‡º'Hello World!'", "example_code": "import asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n    agent = AssistantAgent(\"assistant\", model_client=model_client)\n    print(await agent.run(task=\"Say 'Hello World!'\"))\n    await model_client.close()\n\nasyncio.run(main())", "running_command": null, "expected_input": "Say 'Hello World!'", "expected_output": "'Hello World!'"}, {"task_title": "æ•°å­¦ä¸åŒ–å­¦ä¸“å®¶åŠ©æ‰‹", "task_description": "åˆ›å»ºæ•°å­¦å’ŒåŒ–å­¦ä¸“å®¶åŠ©æ‰‹ï¼Œé€šè¿‡å·¥å…·å¤„ç†å¤æ‚çš„æ•°å­¦å’ŒåŒ–å­¦é—®é¢˜ã€‚", "example_code": "import asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.tools import AgentTool\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n\n    math_agent = AssistantAgent(\n        \"math_expert\",\n        model_client=model_client,\n        system_message=\"You are a math expert.\",\n        description=\"A math expert assistant.\",\n        model_client_stream=True,\n    )\n    math_agent_tool = AgentTool(math_agent, return_value_as_last_message=True)\n\n    chemistry_agent = AssistantAgent(\n        \"chemistry_expert\",\n        model_client=model_client,\n        system_message=\"You are a chemistry expert.\",\n        description=\"A chemistry expert assistant.\",\n        model_client_stream=True,\n    )\n    chemistry_agent_tool = AgentTool(chemistry_agent, return_value_as_last_message=True)\n\n    agent = AssistantAgent(\n        \"assistant\",\n        system_message=\"You are a general assistant. Use expert tools when needed.\",\n        model_client=model_client,\n        model_client_stream=True,\n        tools=[math_agent_tool, chemistry_agent_tool],\n        max_tool_iterations=10,\n    )\n    await Console(agent.run_stream(task=\"What is the integral of x^2?\"))\n    await Console(agent.run_stream(task=\"What is the molecular weight of water?\"))\n\nasyncio.run(main())", "running_command": null, "expected_input": "What is the integral of x^2?\nWhat is the molecular weight of water?", "expected_output": "Integral of x^2 is (1/3)x^3 + C.\nMolecular weight of water is 18.015 g/mol."}, {"task_title": "å¯åŠ¨AutoGen Studio", "task_description": "é€šè¿‡å‘½ä»¤è¡Œå¯åŠ¨AutoGen Studioï¼ŒæŒ‡å®šç«¯å£å’Œåº”ç”¨ç›®å½•ã€‚", "example_code": null, "running_command": "autogenstudio ui --port 8080 --appdir ./my-app", "expected_input": "./my-app", "expected_output": "AutoGen Studio running on http://localhost:8080"}], "setup": {"setup_commands": ["# Install AgentChat and OpenAI client from Extensions\npip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"", "# Install AutoGen Studio for no-code GUI\npip install -U \"autogenstudio\"", "# First run `npm install -g @playwright/mcp@latest` to install the MCP server.\nimport asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_agentchat.ui import Console\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\nfrom autogen_ext.tools.mcp import McpWorkbench, StdioServerParams\n\n\nasync def main() -> None:\n    model_client = OpenAIChatCompletionClient(model=\"gpt-4.1\")\n    server_params = StdioServerParams(\n        command=\"npx\",\n        args=[\n            \"@playwright/mcp@latest\",\n            \"--headless\",\n        ],\n    )\n    async with McpWorkbench(server_params) as mcp:\n        agent = AssistantAgent(\n            \"web_browsing_assistant\",\n            model_client=model_client,\n            workbench=mcp, # For multiple MCP servers, put them in a list.\n            model_client_stream=True,\n            max_tool_iterations=10,\n        )\n        await Console(agent.run_stream(task=\"Find out how many contributors for the microsoft/autogen repository\"))\n\n\nasyncio.run(main())"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:10:12.422269"}
{"repo_name": "pathwaycom/pathway", "stars": 48875, "language": "Python", "tasks": [{"task_title": "è¯»å–CSVæ•°æ®", "task_description": "ä½¿ç”¨Pathwayåº“è¯»å–CSVæ–‡ä»¶ï¼Œå¹¶å®šä¹‰æ•°æ®çš„æ¨¡å¼ã€‚", "example_code": "import pathway as pw\n\nclass InputSchema(pw.Schema):\n  value: int\n\ninput_table = pw.io.csv.read(\n  \"./input/\",\n  schema=InputSchema\n)", "running_command": null, "expected_input": "./input/", "expected_output": "æ•°æ®è¡¨æ ¼å¯¹è±¡ï¼ŒåŒ…å«CSVæ–‡ä»¶ä¸­çš„æ•°æ®"}, {"task_title": "è¿‡æ»¤æ•°æ®", "task_description": "å¯¹è¯»å–çš„æ•°æ®è¿›è¡Œè¿‡æ»¤ï¼Œåªä¿ç•™å€¼å¤§äºæˆ–ç­‰äº0çš„è®°å½•ã€‚", "example_code": "filtered_table = input_table.filter(input_table.value>=0)", "running_command": null, "expected_input": "input_table", "expected_output": "è¿‡æ»¤åçš„æ•°æ®è¡¨æ ¼å¯¹è±¡ï¼ŒåŒ…å«å€¼å¤§äºæˆ–ç­‰äº0çš„è®°å½•"}, {"task_title": "è®¡ç®—æ€»å’Œ", "task_description": "å¯¹è¿‡æ»¤åçš„æ•°æ®è¿›è¡Œèšåˆè®¡ç®—ï¼Œè®¡ç®—'value'åˆ—çš„æ€»å’Œã€‚", "example_code": "result_table = filtered_table.reduce(\n  sum_value = pw.reducers.sum(filtered_table.value)\n)", "running_command": null, "expected_input": "filtered_table", "expected_output": "ç»“æœè¡¨æ ¼å¯¹è±¡ï¼ŒåŒ…å«'value'åˆ—çš„æ€»å’Œ"}, {"task_title": "å†™å…¥JSONLæ–‡ä»¶", "task_description": "å°†è®¡ç®—ç»“æœå†™å…¥åˆ°JSON Linesæ ¼å¼çš„æ–‡ä»¶ä¸­ã€‚", "example_code": "pw.io.jsonlines.write(result_table, \"output.jsonl\")", "running_command": null, "expected_input": "result_table", "expected_output": "output.jsonlæ–‡ä»¶ï¼ŒåŒ…å«èšåˆç»“æœ"}, {"task_title": "è¿è¡Œè®¡ç®—", "task_description": "æ‰§è¡ŒPathwayçš„è®¡ç®—æµç¨‹ã€‚", "example_code": "pw.run()", "running_command": null, "expected_input": null, "expected_output": "æ‰§è¡Œè®¡ç®—æµç¨‹çš„ç»“æœ"}], "setup": {"setup_commands": ["pip install -U pathway"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:10:35.847891"}
{"repo_name": "karpathy/nanoGPT", "stars": 48344, "language": "Python", "tasks": [{"task_title": "Prepare Shakespeare Character Dataset", "task_description": "å‡†å¤‡èå£«æ¯”äºšå­—ç¬¦æ•°æ®é›†ä»¥ä¾›è®­ç»ƒä½¿ç”¨ã€‚", "example_code": null, "running_command": "python data/shakespeare_char/prepare.py", "expected_input": null, "expected_output": "Data preparation complete."}, {"task_title": "Train Shakespeare Character Model", "task_description": "è®­ç»ƒèå£«æ¯”äºšå­—ç¬¦æ¨¡å‹ï¼Œä½¿ç”¨æŒ‡å®šçš„é…ç½®æ–‡ä»¶ã€‚", "example_code": null, "running_command": "python train.py config/train_shakespeare_char.py", "expected_input": null, "expected_output": "Training complete."}, {"task_title": "Sample from Trained Shakespeare Character Model", "task_description": "ä»è®­ç»ƒå¥½çš„èå£«æ¯”äºšå­—ç¬¦æ¨¡å‹ä¸­ç”Ÿæˆæ–‡æœ¬æ ·æœ¬ã€‚", "example_code": null, "running_command": "python sample.py --out_dir=out-shakespeare-char", "expected_input": null, "expected_output": "Generated samples saved in out-shakespeare-char."}, {"task_title": "Train Shakespeare Character Model with Parameters", "task_description": "ä½¿ç”¨æ›´å¤šå‚æ•°è®­ç»ƒèå£«æ¯”äºšå­—ç¬¦æ¨¡å‹ã€‚", "example_code": null, "running_command": "python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0", "expected_input": null, "expected_output": "Training complete."}, {"task_title": "Sample from Trained Shakespeare Character Model on CPU", "task_description": "åœ¨CPUä¸Šä»è®­ç»ƒå¥½çš„èå£«æ¯”äºšå­—ç¬¦æ¨¡å‹ä¸­ç”Ÿæˆæ–‡æœ¬æ ·æœ¬ã€‚", "example_code": null, "running_command": "python sample.py --out_dir=out-shakespeare-char --device=cpu", "expected_input": null, "expected_output": "Generated samples saved in out-shakespeare-char."}, {"task_title": "Prepare OpenWebText Dataset", "task_description": "å‡†å¤‡OpenWebTextæ•°æ®é›†ä»¥ä¾›è®­ç»ƒä½¿ç”¨ã€‚", "example_code": null, "running_command": "python data/openwebtext/prepare.py", "expected_input": null, "expected_output": "Data preparation complete."}, {"task_title": "Train GPT-2 Model with Distributed Training", "task_description": "ä½¿ç”¨åˆ†å¸ƒå¼è®­ç»ƒè®­ç»ƒGPT-2æ¨¡å‹ã€‚", "example_code": null, "running_command": "torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py", "expected_input": null, "expected_output": "Distributed training complete."}, {"task_title": "Distributed Training on Master Node", "task_description": "åœ¨ä¸»èŠ‚ç‚¹ä¸Šè¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚", "example_code": null, "running_command": "torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py", "expected_input": null, "expected_output": "Distributed training complete."}, {"task_title": "Distributed Training on Worker Node", "task_description": "åœ¨å·¥ä½œèŠ‚ç‚¹ä¸Šè¿è¡Œåˆ†å¸ƒå¼è®­ç»ƒã€‚", "example_code": null, "running_command": "torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py", "expected_input": null, "expected_output": "Distributed training complete."}, {"task_title": "Evaluate GPT-2 Model", "task_description": "è¯„ä¼°ä¸åŒé…ç½®çš„GPT-2æ¨¡å‹ã€‚", "example_code": null, "running_command": "$ python train.py config/eval_gpt2.py", "expected_input": null, "expected_output": "Evaluation complete."}, {"task_title": "Fine-tune Shakespeare Model", "task_description": "å¯¹èå£«æ¯”äºšæ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚", "example_code": null, "running_command": "python train.py config/finetune_shakespeare.py", "expected_input": null, "expected_output": "Fine-tuning complete."}, {"task_title": "Sample from Fine-tuned GPT-2 Model", "task_description": "ä»å¾®è°ƒåçš„GPT-2æ¨¡å‹ä¸­ç”Ÿæˆæ–‡æœ¬æ ·æœ¬ï¼Œå¸¦æœ‰åˆå§‹åŒ–æ–‡æœ¬å’Œæ ·æœ¬æ•°é‡çš„å‚æ•°ã€‚", "example_code": null, "running_command": "python sample.py --init_from=gpt2-xl --start=\"What is the answer to life, the universe, and everything?\" --num_samples=5 --max_new_tokens=100", "expected_input": "What is the answer to life, the universe, and everything?", "expected_output": "Generated samples based on the input."}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:10:57.897992"}
{"repo_name": "ultralytics/ultralytics", "stars": 47987, "language": "Python", "tasks": [{"task_title": "ä½¿ç”¨é¢„è®­ç»ƒYOLOæ¨¡å‹è¿›è¡Œé¢„æµ‹", "task_description": "ä½¿ç”¨é¢„è®­ç»ƒçš„YOLOæ¨¡å‹ï¼ˆå¦‚YOLO11nï¼‰å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹ã€‚", "example_code": null, "running_command": "yolo predict model=yolo11n.pt source='https://ultralytics.com/images/bus.jpg'", "expected_input": "https://ultralytics.com/images/bus.jpg", "expected_output": "é¢„æµ‹ç»“æœï¼ŒåŒ…æ‹¬æ£€æµ‹åˆ°çš„å¯¹è±¡åŠå…¶ä½ç½®ä¿¡æ¯"}, {"task_title": "åŠ è½½é¢„è®­ç»ƒYOLOæ¨¡å‹", "task_description": "åŠ è½½ä¸€ä¸ªé¢„è®­ç»ƒçš„YOLO11næ¨¡å‹ä»¥è¿›è¡Œåç»­æ“ä½œã€‚", "example_code": "from ultralytics import YOLO\n\nmodel = YOLO(\"yolo11n.pt\")", "running_command": null, "expected_input": null, "expected_output": "åŠ è½½çš„YOLOæ¨¡å‹å¯¹è±¡"}, {"task_title": "è®­ç»ƒYOLOæ¨¡å‹", "task_description": "åœ¨COCO8æ•°æ®é›†ä¸Šè®­ç»ƒYOLOæ¨¡å‹ï¼ŒæŒ‡å®šè®­ç»ƒçš„è½®æ•°å’Œå›¾åƒå¤§å°ã€‚", "example_code": "train_results = model.train(\n    data=\"coco8.yaml\",\n    epochs=100,\n    imgsz=640,\n    device=\"cpu\",\n)", "running_command": null, "expected_input": "coco8.yaml, 100, 640, cpu", "expected_output": "è®­ç»ƒç»“æœï¼ŒåŒ…æ‹¬æŸå¤±å€¼å’Œæ¨¡å‹æ€§èƒ½æŒ‡æ ‡"}, {"task_title": "è¯„ä¼°æ¨¡å‹æ€§èƒ½", "task_description": "åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½å¹¶è·å–æ€§èƒ½æŒ‡æ ‡ã€‚", "example_code": "metrics = model.val()", "running_command": null, "expected_input": null, "expected_output": "æ¨¡å‹æ€§èƒ½æŒ‡æ ‡"}, {"task_title": "å¯¹å›¾åƒè¿›è¡Œå¯¹è±¡æ£€æµ‹", "task_description": "å¯¹æŒ‡å®šå›¾åƒè¿›è¡Œå¯¹è±¡æ£€æµ‹å¹¶å±•ç¤ºæ£€æµ‹ç»“æœã€‚", "example_code": "results = model(\"path/to/image.jpg\")\nresults[0].show()", "running_command": null, "expected_input": "path/to/image.jpg", "expected_output": "æ£€æµ‹ç»“æœçš„å¯è§†åŒ–å±•ç¤º"}, {"task_title": "å¯¼å‡ºæ¨¡å‹", "task_description": "å°†YOLOæ¨¡å‹å¯¼å‡ºä¸ºONNXæ ¼å¼ï¼Œä»¥ä¾¿äºéƒ¨ç½²ã€‚", "example_code": "path = model.export(format=\"onnx\")", "running_command": null, "expected_input": null, "expected_output": "å¯¼å‡ºæ¨¡å‹çš„è·¯å¾„"}], "setup": {"setup_commands": ["pip install ultralytics"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:11:11.402168"}
{"repo_name": "opendatalab/MinerU", "stars": 47634, "language": "Python", "tasks": [{"task_title": "æ•°æ®å¤„ç†", "task_description": "ä½¿ç”¨MinerUåº“å¤„ç†æŒ‡å®šè·¯å¾„ä¸‹çš„æ•°æ®ï¼Œå¹¶å°†ç»“æœè¾“å‡ºåˆ°å¦ä¸€ä¸ªè·¯å¾„ã€‚", "example_code": null, "running_command": "mineru -p <input_path> -o <output_path>", "expected_input": "<input_path>, <output_path>", "expected_output": "å¤„ç†åçš„æ•°æ®æ–‡ä»¶"}], "setup": {"setup_commands": ["pip install --upgrade pip\npip install uv\nuv pip install -U \"mineru[core]\"", "git clone https://github.com/opendatalab/MinerU.git\ncd MinerU\nuv pip install -e .[core]"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:11:18.694874"}
{"repo_name": "unslothai/unsloth", "stars": 47573, "language": "Python", "tasks": [{"task_title": "åŠ è½½æ•°æ®é›†", "task_description": "ä»æŒ‡å®šçš„URLåŠ è½½LAIONæ•°æ®é›†ï¼Œä½¿ç”¨datasetsåº“çš„load_datasetåŠŸèƒ½ã€‚", "example_code": "url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\ndataset = load_dataset(\"json\", data_files = {\"train\" : url}, split = \"train\")", "running_command": null, "expected_input": "https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl", "expected_output": "åŠ è½½çš„æ•°æ®é›†å¯¹è±¡"}, {"task_title": "åŠ è½½é¢„è®­ç»ƒæ¨¡å‹", "task_description": "ä½¿ç”¨FastModelåŠ è½½é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹ï¼Œæ”¯æŒ4ä½é‡åŒ–ä»¥å‡å°‘å†…å­˜å ç”¨ã€‚", "example_code": "model, tokenizer = FastModel.from_pretrained(\n    model_name = \"unsloth/gpt-oss-20b\",\n    max_seq_length = 2048,\n    load_in_4bit = True,\n    load_in_8bit = False,\n    load_in_16bit = False,\n    full_finetuning = False\n)", "running_command": null, "expected_input": "unsloth/gpt-oss-20b", "expected_output": "åŠ è½½çš„æ¨¡å‹å’Œåˆ†è¯å™¨å¯¹è±¡"}, {"task_title": "æ¨¡å‹å¾®è°ƒ", "task_description": "ä½¿ç”¨SFTTrainerå¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œé…ç½®è®­ç»ƒå‚æ•°å¹¶å¼€å§‹è®­ç»ƒã€‚", "example_code": "trainer = SFTTrainer(\n    model = model,\n    train_dataset = dataset,\n    tokenizer = tokenizer,\n    args = SFTConfig(\n        max_seq_length = max_seq_length,\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 10,\n        max_steps = 60,\n        logging_steps = 1,\n        output_dir = \"outputs\",\n        optim = \"adamw_8bit\",\n        seed = 3407,\n    ),\n)\ntrainer.train()", "running_command": null, "expected_input": "è®­ç»ƒæ•°æ®é›†å’Œé…ç½®å‚æ•°", "expected_output": "è®­ç»ƒè¿‡ç¨‹çš„æ—¥å¿—è¾“å‡ºå’Œæ¨¡å‹ä¿å­˜"}], "setup": {"setup_commands": ["pip install unsloth", "pip install unsloth", "python -m venv unsloth\nsource unsloth/bin/activate\npip install unsloth", "  pip install ninja\n  pip install -v --no-build-isolation -U git+https://github.com/facebookresearch/xformers.git@main#egg=xformers", "conda create --name unsloth_env \\\n    python=3.11 \\\n    pytorch-cuda=12.1 \\\n    pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers \\\n    -y\nconda activate unsloth_env\n\npip install unsloth", "  mkdir -p ~/miniconda3\n  wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n  bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n  rm -rf ~/miniconda3/miniconda.sh\n  ~/miniconda3/bin/conda init bash\n  ~/miniconda3/bin/conda init zsh", "pip install --upgrade pip\npip install \"unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git\"", "pip install --upgrade pip\npip install \"unsloth[cu124-torch250] @ git+https://github.com/unslothai/unsloth.git\"", "pip install \"unsloth[cu121-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git\"\npip install \"unsloth[cu118-ampere-torch240] @ git+https://github.com/unslothai/unsloth.git\"\npip install \"unsloth[cu121-torch240] @ git+https://github.com/unslothai/unsloth.git\"\npip install \"unsloth[cu118-torch240] @ git+https://github.com/unslothai/unsloth.git\"\n\npip install \"unsloth[cu121-torch230] @ git+https://github.com/unslothai/unsloth.git\"\npip install \"unsloth[cu121-ampere-torch230] @ git+https://github.com/unslothai/unsloth.git\"\n\npip install \"unsloth[cu121-torch250] @ git+https://github.com/unslothai/unsloth.git\"\npip install \"unsloth[cu124-ampere-torch250] @ git+https://github.com/unslothai/unsloth.git\"", "wget -qO- https://raw.githubusercontent.com/unslothai/unsloth/main/unsloth/_auto_install.py | python -", "try: import torch\nexcept: raise ImportError('Install torch via `pip install torch`')\nfrom packaging.version import Version as V\nimport re\nv = V(re.match(r\"[0-9\\.]{3,}\", torch.__version__).group(0))\ncuda = str(torch.version.cuda)\nis_ampere = torch.cuda.get_device_capability()[0] >= 8\nUSE_ABI = torch._C._GLIBCXX_USE_CXX11_ABI\nif cuda not in (\"11.8\", \"12.1\", \"12.4\", \"12.6\", \"12.8\"): raise RuntimeError(f\"CUDA = {cuda} not supported!\")\nif   v <= V('2.1.0'): raise RuntimeError(f\"Torch = {v} too old!\")\nelif v <= V('2.1.1'): x = 'cu{}{}-torch211'\nelif v <= V('2.1.2'): x = 'cu{}{}-torch212'\nelif v  < V('2.3.0'): x = 'cu{}{}-torch220'\nelif v  < V('2.4.0'): x = 'cu{}{}-torch230'\nelif v  < V('2.5.0'): x = 'cu{}{}-torch240'\nelif v  < V('2.5.1'): x = 'cu{}{}-torch250'\nelif v <= V('2.5.1'): x = 'cu{}{}-torch251'\nelif v  < V('2.7.0'): x = 'cu{}{}-torch260'\nelif v  < V('2.7.9'): x = 'cu{}{}-torch270'\nelif v  < V('2.8.0'): x = 'cu{}{}-torch271'\nelif v  < V('2.8.9'): x = 'cu{}{}-torch280'\nelse: raise RuntimeError(f\"Torch = {v} too new!\")\nif v > V('2.6.9') and cuda not in (\"11.8\", \"12.6\", \"12.8\"): raise RuntimeError(f\"CUDA = {cuda} not supported!\")\nx = x.format(cuda.replace(\".\", \"\"), \"-ampere\" if is_ampere else \"\")\nprint(f'pip install --upgrade pip && pip install \"unsloth[{x}] @ git+https://github.com/unslothai/unsloth.git\"')"], "docker_commands": ["docker run -d -e JUPYTER_PASSWORD=\"mypassword\" \\\n  -p 8888:8888 -p 2222:22 \\\n  -v $(pwd)/work:/workspace/work \\\n  --gpus all \\\n  unsloth/unsloth"], "has_docker_files": false}, "timestamp": "2025-10-28T23:11:31.110246"}
{"repo_name": "run-llama/llama_index", "stars": 44950, "language": "Python", "tasks": [{"task_title": "åŠ è½½æ–‡æ¡£æ•°æ®", "task_description": "ä½¿ç”¨SimpleDirectoryReaderä»æŒ‡å®šç›®å½•åŠ è½½æ–‡æ¡£æ•°æ®ã€‚", "example_code": "from llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\"YOUR_DATA_DIRECTORY\").load_data()", "running_command": null, "expected_input": "YOUR_DATA_DIRECTORY", "expected_output": "æ–‡æ¡£æ•°æ®åˆ—è¡¨"}, {"task_title": "åˆ›å»ºå‘é‡å­˜å‚¨ç´¢å¼•", "task_description": "ä»åŠ è½½çš„æ–‡æ¡£æ•°æ®åˆ›å»ºä¸€ä¸ªVectorStoreIndexã€‚", "example_code": "from llama_index.core import VectorStoreIndex\n\nindex = VectorStoreIndex.from_documents(documents)", "running_command": null, "expected_input": "documents", "expected_output": "VectorStoreIndexå¯¹è±¡"}, {"task_title": "æŸ¥è¯¢ç´¢å¼•", "task_description": "ä½¿ç”¨åˆ›å»ºçš„ç´¢å¼•ä½œä¸ºæŸ¥è¯¢å¼•æ“æ¥æŸ¥è¯¢é—®é¢˜ã€‚", "example_code": "query_engine = index.as_query_engine()\nquery_engine.query(\"YOUR_QUESTION\")", "running_command": null, "expected_input": "YOUR_QUESTION", "expected_output": "æŸ¥è¯¢ç»“æœ"}, {"task_title": "æŒä¹…åŒ–ç´¢å¼•", "task_description": "å°†å½“å‰ç´¢å¼•çš„å­˜å‚¨ä¸Šä¸‹æ–‡æŒä¹…åŒ–åˆ°ç£ç›˜ã€‚", "example_code": "index.storage_context.persist()", "running_command": null, "expected_input": null, "expected_output": "ç´¢å¼•å·²æŒä¹…åŒ–"}, {"task_title": "ä»å­˜å‚¨åŠ è½½ç´¢å¼•", "task_description": "ä»æŒä¹…åŒ–å­˜å‚¨ä¸­åŠ è½½ç´¢å¼•ã€‚", "example_code": "from llama_index.core import StorageContext, load_index_from_storage\n\nstorage_context = StorageContext.from_defaults(persist_dir=\"./storage\")\nindex = load_index_from_storage(storage_context)", "running_command": null, "expected_input": "./storage", "expected_output": "åŠ è½½çš„VectorStoreIndexå¯¹è±¡"}], "setup": {"setup_commands": ["# custom selection of integrations to work with core\npip install llama-index-core\npip install llama-index-llms-openai\npip install llama-index-llms-replicate\npip install llama-index-embeddings-huggingface", "cd <desired-package-folder>\npip install poetry\npoetry install --with dev"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:11:57.075489"}
{"repo_name": "coqui-ai/TTS", "stars": 43190, "language": "Python", "tasks": [{"task_title": "åˆ—å‡ºå¯ç”¨çš„TTSæ¨¡å‹", "task_description": "ä½¿ç”¨TTS APIåˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ã€‚", "example_code": "print(TTS().list_models())", "running_command": null, "expected_input": null, "expected_output": "å¯ç”¨æ¨¡å‹çš„åˆ—è¡¨"}, {"task_title": "æ–‡æœ¬è½¬è¯­éŸ³", "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶è¾“å‡ºä¸ºéŸ³é¢‘æ•°ç»„ï¼Œä½¿ç”¨æŒ‡å®šçš„è¯´è¯è€…éŸ³é¢‘å’Œè¯­è¨€ã€‚", "example_code": "wav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")", "running_command": null, "expected_input": "Hello world!", "expected_output": "éŸ³é¢‘æ•°ç»„ï¼ˆè¯­éŸ³çš„å¹…åº¦å€¼ï¼‰"}, {"task_title": "æ–‡æœ¬è½¬è¯­éŸ³å¹¶ä¿å­˜åˆ°æ–‡ä»¶", "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜ä¸ºæŒ‡å®šçš„éŸ³é¢‘æ–‡ä»¶ã€‚", "example_code": "tts.tts_to_file(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")", "running_command": null, "expected_input": "Hello world!", "expected_output": "è¾“å‡ºæ–‡ä»¶output.wav"}, {"task_title": "å¤šè¯­è¨€æ–‡æœ¬è½¬è¯­éŸ³", "task_description": "ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜ä¸ºæ–‡ä»¶ï¼Œæ”¯æŒå¤šç§è¯­è¨€ã€‚", "example_code": "tts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")", "running_command": null, "expected_input": "C'est le clonage de la voix.", "expected_output": "è¾“å‡ºæ–‡ä»¶output.wav"}, {"task_title": "è¯­éŸ³è½¬æ¢", "task_description": "ä½¿ç”¨æŒ‡å®šçš„æºå’Œç›®æ ‡éŸ³é¢‘æ–‡ä»¶è¿›è¡Œè¯­éŸ³è½¬æ¢ï¼Œå¹¶å°†ç»“æœä¿å­˜ä¸ºéŸ³é¢‘æ–‡ä»¶ã€‚", "example_code": "tts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")", "running_command": null, "expected_input": null, "expected_output": "è¾“å‡ºæ–‡ä»¶output.wav"}, {"task_title": "å¸¦æœ‰è¯­éŸ³è½¬æ¢çš„æ–‡æœ¬è½¬è¯­éŸ³", "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼ŒåŒæ—¶è¿›è¡Œè¯­éŸ³è½¬æ¢ï¼Œå¹¶ä¿å­˜ä¸ºæ–‡ä»¶ã€‚", "example_code": "tts.tts_with_vc_to_file(\"Wie sage ich auf Italienisch, dass ich dich liebe?\", speaker_wav=\"target/speaker.wav\", file_path=\"output.wav\")", "running_command": null, "expected_input": "Wie sage ich auf Italienisch, dass ich dich liebe?", "expected_output": "è¾“å‡ºæ–‡ä»¶output.wav"}], "setup": {"setup_commands": ["pip install TTS", "git clone https://github.com/coqui-ai/TTS\npip install -e .[all,dev,notebooks]  # Select the relevant extras"], "docker_commands": ["docker run --rm -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu\npython3 TTS/server/server.py --list_models #To get the list of available models\npython3 TTS/server/server.py --model_name tts_models/en/vctk/vits # To start a server"], "has_docker_files": true}, "timestamp": "2025-10-28T23:12:16.332617"}
{"repo_name": "docling-project/docling", "stars": 42497, "language": "Python", "tasks": [{"task_title": "æ–‡æ¡£è½¬æ¢", "task_description": "ä½¿ç”¨DocumentConverterå°†æ–‡æ¡£ä»æŒ‡å®šçš„URLè½¬æ¢ä¸ºMarkdownæ ¼å¼ã€‚", "example_code": "from docling.document_converter import DocumentConverter\n\nsource = \"https://arxiv.org/pdf/2408.09869\"  # document per local path or URL\nconverter = DocumentConverter()\nresult = converter.convert(source)\nprint(result.document.export_to_markdown())  # output: \"## Docling Technical Report[...]\"", "running_command": null, "expected_input": "https://arxiv.org/pdf/2408.09869", "expected_output": "## Docling Technical Report[...]"}, {"task_title": "æ–‡æ¡£è½¬æ¢ï¼ˆCLIï¼‰", "task_description": "é€šè¿‡å‘½ä»¤è¡Œå·¥å…·ç›´æ¥è½¬æ¢æŒ‡å®šURLçš„æ–‡æ¡£ã€‚", "example_code": null, "running_command": "docling https://arxiv.org/pdf/2206.01062", "expected_input": "https://arxiv.org/pdf/2206.01062", "expected_output": "è½¬æ¢ç»“æœ"}, {"task_title": "ä½¿ç”¨ç‰¹å®šç®¡é“å’Œæ¨¡å‹è¿›è¡Œæ–‡æ¡£è½¬æ¢ï¼ˆCLIï¼‰", "task_description": "é€šè¿‡å‘½ä»¤è¡Œå·¥å…·ä½¿ç”¨æŒ‡å®šçš„ç®¡é“å’Œæ¨¡å‹è¿›è¡Œæ–‡æ¡£è½¬æ¢ã€‚", "example_code": null, "running_command": "docling --pipeline vlm --vlm-model granite_docling https://arxiv.org/pdf/2206.01062", "expected_input": "https://arxiv.org/pdf/2206.01062", "expected_output": "è½¬æ¢ç»“æœ"}], "setup": {"setup_commands": ["pip install docling"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:12:28.436399"}
{"repo_name": "virattt/ai-hedge-fund", "stars": 42104, "language": "Python", "tasks": [{"task_title": "Run main script with tickers", "task_description": "è¿è¡Œä¸»è„šæœ¬ä»¥è·å–æŒ‡å®šè‚¡ç¥¨ï¼ˆAAPL, MSFT, NVDAï¼‰çš„æ•°æ®ã€‚", "example_code": null, "running_command": "poetry run python src/main.py --ticker AAPL,MSFT,NVDA", "expected_input": "AAPL, MSFT, NVDA", "expected_output": "Financial data for AAPL, MSFT, NVDA"}, {"task_title": "Run main script with tickers and Ollama", "task_description": "è¿è¡Œä¸»è„šæœ¬ä»¥è·å–æŒ‡å®šè‚¡ç¥¨ï¼ˆAAPL, MSFT, NVDAï¼‰çš„æ•°æ®ï¼Œå¹¶å¯ç”¨OllamaåŠŸèƒ½ã€‚", "example_code": null, "running_command": "poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama", "expected_input": "AAPL, MSFT, NVDA", "expected_output": "Financial data for AAPL, MSFT, NVDA with Ollama"}, {"task_title": "Run main script with date range", "task_description": "è¿è¡Œä¸»è„šæœ¬ä»¥è·å–æŒ‡å®šè‚¡ç¥¨ï¼ˆAAPL, MSFT, NVDAï¼‰åœ¨ç‰¹å®šæ—¥æœŸèŒƒå›´å†…çš„æ•°æ®ã€‚", "example_code": null, "running_command": "poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01", "expected_input": "AAPL, MSFT, NVDA, 2024-01-01, 2024-03-01", "expected_output": "Financial data for AAPL, MSFT, NVDA from 2024-01-01 to 2024-03-01"}, {"task_title": "Run backtester script with tickers", "task_description": "è¿è¡Œå›æµ‹è„šæœ¬ä»¥æµ‹è¯•æŒ‡å®šè‚¡ç¥¨ï¼ˆAAPL, MSFT, NVDAï¼‰çš„æŠ•èµ„ç­–ç•¥ã€‚", "example_code": null, "running_command": "poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA", "expected_input": "AAPL, MSFT, NVDA", "expected_output": "Backtest results for AAPL, MSFT, NVDA"}], "setup": {"setup_commands": ["git clone https://github.com/virattt/ai-hedge-fund.git\ncd ai-hedge-fund", "curl -sSL https://install.python-poetry.org | python3 -", "poetry install"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:12:45.457887"}
{"repo_name": "streamlit/streamlit", "stars": 41977, "language": "Python", "tasks": [{"task_title": "Slider Input and Display Result", "task_description": "è¿™ä¸ªä»»åŠ¡å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨Streamlitåˆ›å»ºä¸€ä¸ªæ»‘å—è¾“å…¥ï¼Œå¹¶è®¡ç®—å’Œæ˜¾ç¤ºè¾“å…¥å€¼çš„å¹³æ–¹ã€‚", "example_code": "import streamlit as st\nx = st.slider(\"Select a value\")\nst.write(x, \"squared is\", x * x)", "running_command": null, "expected_input": "ä»»æ„æ•°å€¼ï¼ˆä¾‹å¦‚ï¼š5ï¼‰", "expected_output": "5 squared is 25"}], "setup": {"setup_commands": ["$ pip install streamlit\n$ streamlit hello"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:12:55.428368"}
{"repo_name": "mem0ai/mem0", "stars": 41956, "language": "Python", "tasks": [{"task_title": "ä¸AIè¿›è¡Œå¯¹è¯å¹¶ä½¿ç”¨è®°å¿†", "task_description": "è¯¥ä»»åŠ¡å±•ç¤ºäº†å¦‚ä½•ä¸AIè¿›è¡Œå¯¹è¯ï¼ŒåŒæ—¶åˆ©ç”¨è®°å¿†åŠŸèƒ½æ¥å¢å¼ºå›ç­”çš„ç›¸å…³æ€§ã€‚é€šè¿‡ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯ï¼Œç³»ç»Ÿæ£€ç´¢ç›¸å…³çš„è®°å¿†ï¼Œå¹¶ç”ŸæˆåŸºäºè¿™äº›è®°å¿†çš„å›ç­”ã€‚", "example_code": "from openai import OpenAI\nfrom mem0 import Memory\n\nopenai_client = OpenAI()\nmemory = Memory()\n\ndef chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n    memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n    system_prompt = f\"You are a helpful AI. Answer the question based on query and memories.\\nUser Memories:\\n{memories_str}\"\n    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n    response = openai_client.chat.completions.create(model=\"gpt-4.1-nano-2025-04-14\", messages=messages)\n    assistant_response = response.choices[0].message.content\n    messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n    memory.add(messages, user_id=user_id)\n    return assistant_response\n\ndef main():\n    print(\"Chat with AI (type 'exit' to quit)\")\n    while True:\n        user_input = input(\"You: \").strip()\n        if user_input.lower() == 'exit':\n            print(\"Goodbye!\")\n            break\n        print(f\"AI: {chat_with_memories(user_input)}\")\n\nif __name__ == \"__main__\":\n    main()", "running_command": null, "expected_input": "Hello, how can you help me today?", "expected_output": "AI: Based on what I remember, I can assist you with various topics. What would you like to know?"}], "setup": {"setup_commands": ["pip install mem0ai", "npm install mem0ai"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:13:06.707429"}
{"repo_name": "zai-org/ChatGLM-6B", "stars": 41152, "language": "Python", "tasks": [{"task_title": "åŠ è½½é¢„è®­ç»ƒæ¨¡å‹å’Œåˆ†è¯å™¨", "task_description": "ä»é¢„è®­ç»ƒæ¨¡å‹åº“åŠ è½½åˆ†è¯å™¨å’Œæ¨¡å‹ï¼Œå¹¶å°†æ¨¡å‹è®¾ç½®ä¸ºåŠç²¾åº¦å’ŒCUDAè®¾å¤‡ã€‚", "example_code": "from transformers import AutoTokenizer, AutoModel\n\ntokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True)\nmodel = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True).half().cuda()", "running_command": null, "expected_input": null, "expected_output": null}, {"task_title": "æ¨¡å‹èŠå¤©åŠŸèƒ½", "task_description": "ä½¿ç”¨åŠ è½½çš„æ¨¡å‹å’Œåˆ†è¯å™¨è¿›è¡Œå¯¹è¯ï¼Œè¿”å›æ¨¡å‹çš„å“åº”å’Œå¯¹è¯å†å²ã€‚", "example_code": "response, history = model.chat(tokenizer, \"ä½ å¥½\", history=[])\nprint(response)", "running_command": null, "expected_input": "ä½ å¥½", "expected_output": "ä½ å¥½ğŸ‘‹!æˆ‘æ˜¯äººå·¥æ™ºèƒ½åŠ©æ‰‹ ChatGLM-6B,å¾ˆé«˜å…´è§åˆ°ä½ ,æ¬¢è¿é—®æˆ‘ä»»ä½•é—®é¢˜ã€‚"}, {"task_title": "ç»§ç»­å¯¹è¯", "task_description": "åœ¨å·²æœ‰å¯¹è¯å†å²çš„åŸºç¡€ä¸Šç»§ç»­ä¸æ¨¡å‹å¯¹è¯ï¼Œè·å–æ–°çš„å“åº”ã€‚", "example_code": "response, history = model.chat(tokenizer, \"æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ\", history=history)\nprint(response)", "running_command": null, "expected_input": "æ™šä¸Šç¡ä¸ç€åº”è¯¥æ€ä¹ˆåŠ", "expected_output": "æ™šä¸Šç¡ä¸ç€å¯èƒ½ä¼šè®©ä½ æ„Ÿåˆ°ç„¦è™‘æˆ–ä¸èˆ’æœ,ä½†ä»¥ä¸‹æ˜¯ä¸€äº›å¯ä»¥å¸®åŠ©ä½ å…¥ç¡çš„æ–¹æ³•:\n\n1. åˆ¶å®šè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨:ä¿æŒè§„å¾‹çš„ç¡çœ æ—¶é—´è¡¨å¯ä»¥å¸®åŠ©ä½ å»ºç«‹å¥åº·çš„ç¡çœ ä¹ æƒ¯,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚å°½é‡åœ¨æ¯å¤©çš„ç›¸åŒæ—¶é—´ä¸ŠåºŠ,å¹¶åœ¨åŒä¸€æ—¶é—´èµ·åºŠã€‚\n2. åˆ›é€ ä¸€ä¸ªèˆ’é€‚çš„ç¡çœ ç¯å¢ƒ:ç¡®ä¿ç¡çœ ç¯å¢ƒèˆ’é€‚,å®‰é™,é»‘æš—ä¸”æ¸©åº¦é€‚å®œã€‚å¯ä»¥ä½¿ç”¨èˆ’é€‚çš„åºŠä¸Šç”¨å“,å¹¶ä¿æŒæˆ¿é—´é€šé£ã€‚\n3. æ”¾æ¾èº«å¿ƒ:åœ¨ç¡å‰åšäº›æ”¾æ¾çš„æ´»åŠ¨,ä¾‹å¦‚æ³¡ä¸ªçƒ­æ°´æ¾¡,å¬äº›è½»æŸ”çš„éŸ³ä¹,é˜…è¯»ä¸€äº›æœ‰è¶£çš„ä¹¦ç±ç­‰,æœ‰åŠ©äºç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚\n4. é¿å…é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™:å’–å•¡å› æ˜¯ä¸€ç§åˆºæ¿€æ€§ç‰©è´¨,ä¼šå½±å“ä½ çš„ç¡çœ è´¨é‡ã€‚å°½é‡é¿å…åœ¨ç¡å‰é¥®ç”¨å«æœ‰å’–å•¡å› çš„é¥®æ–™,ä¾‹å¦‚å’–å•¡,èŒ¶å’Œå¯ä¹ã€‚\n5. é¿å…åœ¨åºŠä¸Šåšä¸ç¡çœ æ— å…³çš„äº‹æƒ…:åœ¨åºŠä¸Šåšäº›ä¸ç¡çœ æ— å…³çš„äº‹æƒ…,ä¾‹å¦‚çœ‹ç”µå½±,ç©æ¸¸æˆæˆ–å·¥ä½œç­‰,å¯èƒ½ä¼šå¹²æ‰°ä½ çš„ç¡çœ ã€‚\n6. å°è¯•å‘¼å¸æŠ€å·§:æ·±å‘¼å¸æ˜¯ä¸€ç§æ”¾æ¾æŠ€å·§,å¯ä»¥å¸®åŠ©ä½ ç¼“è§£ç´§å¼ å’Œç„¦è™‘,ä½¿ä½ æ›´å®¹æ˜“å…¥ç¡ã€‚è¯•ç€æ…¢æ…¢å¸æ°”,ä¿æŒå‡ ç§’é’Ÿ,ç„¶åç¼“æ…¢å‘¼æ°”ã€‚"}, {"task_title": "æ¨¡å‹é‡åŒ–", "task_description": "åŠ è½½æ¨¡å‹æ—¶è¿›è¡Œé‡åŒ–ï¼Œä»¥å‡å°‘å†…å­˜å ç”¨å’Œæé«˜æ•ˆç‡ã€‚", "example_code": "model = AutoModel.from_pretrained(\"THUDM/chatglm-6b\", trust_remote_code=True).quantize(8).half().cuda()", "running_command": null, "expected_input": null, "expected_output": null}, {"task_title": "ä½¿ç”¨æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹", "task_description": "ä»æœ¬åœ°è·¯å¾„åŠ è½½æ¨¡å‹ï¼Œå¹¶è®¾ç½®ä¸ºåŠç²¾åº¦å’Œç‰¹å®šè®¾å¤‡ã€‚", "example_code": "model = AutoModel.from_pretrained(\"your local path\", trust_remote_code=True).half().to('mps')", "running_command": null, "expected_input": null, "expected_output": null}, {"task_title": "åœ¨å¤šä¸ªGPUä¸ŠåŠ è½½æ¨¡å‹", "task_description": "ä½¿ç”¨è‡ªå®šä¹‰å·¥å…·åœ¨å¤šä¸ªGPUä¸ŠåŠ è½½æ¨¡å‹ä»¥è¿›è¡Œå¹¶è¡Œå¤„ç†ã€‚", "example_code": "from utils import load_model_on_gpus\nmodel = load_model_on_gpus(\"THUDM/chatglm-6b\", num_gpus=2)", "running_command": null, "expected_input": null, "expected_output": null}], "setup": {"setup_commands": ["git clone https://huggingface.co/THUDM/chatglm-6b", "GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/THUDM/chatglm-6b", "git clone https://github.com/THUDM/ChatGLM-6B\ncd ChatGLM-6B", "curl -X POST \"http://127.0.0.1:8000\" \\\n     -H 'Content-Type: application/json' \\\n     -d '{\"prompt\": \"ä½ å¥½\", \"history\": []}'"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:13:37.637538"}
{"repo_name": "psf/black", "stars": 41093, "language": "Python", "tasks": [{"task_title": "æ ¼å¼åŒ–Pythonæºæ–‡ä»¶æˆ–ç›®å½•", "task_description": "ä½¿ç”¨Blackå·¥å…·å¯¹æŒ‡å®šçš„Pythonæºæ–‡ä»¶æˆ–ç›®å½•è¿›è¡Œä»£ç æ ¼å¼åŒ–ï¼Œç¡®ä¿ä»£ç ç¬¦åˆPEP 8é£æ ¼æŒ‡å—ã€‚", "example_code": null, "running_command": "black {source_file_or_directory}", "expected_input": "source_file_or_directory", "expected_output": "æ ¼å¼åŒ–åçš„Pythonä»£ç "}, {"task_title": "ä½¿ç”¨Pythonæ¨¡å—æ ¼å¼åŒ–ä»£ç ", "task_description": "é€šè¿‡Pythonæ¨¡å—æ–¹å¼è°ƒç”¨Blackå·¥å…·ï¼Œå¯¹æŒ‡å®šçš„Pythonæºæ–‡ä»¶æˆ–ç›®å½•è¿›è¡Œä»£ç æ ¼å¼åŒ–ã€‚", "example_code": null, "running_command": "python -m black {source_file_or_directory}", "expected_input": "source_file_or_directory", "expected_output": "æ ¼å¼åŒ–åçš„Pythonä»£ç "}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:13:46.895166"}
{"repo_name": "deepspeedai/DeepSpeed", "stars": 40536, "language": "Python", "tasks": [{"task_title": "Generate a DeepSpeed Report", "task_description": "ä½¿ç”¨DeepSpeedç”ŸæˆæŠ¥å‘Šï¼Œä»¥ä¾¿åˆ†æè®­ç»ƒè¿‡ç¨‹ä¸­çš„æ€§èƒ½å’Œæ•ˆç‡ã€‚", "example_code": "from deepspeed import deepspeed\n\ndef main():\n    # Initialize DeepSpeed\n    ds = deepspeed.initialize()\n    # Generate report\n    report = ds.report()\n    print(report)\n\nif __name__ == '__main__':\n    main()", "running_command": null, "expected_input": null, "expected_output": "{'report': {...}}"}], "setup": {"setup_commands": ["pip install deepspeed"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:13:58.273900"}
{"repo_name": "gradio-app/gradio", "stars": 40346, "language": "Python", "tasks": [{"task_title": "é—®å€™ç”¨æˆ·", "task_description": "è¿™ä¸ªä»»åŠ¡é€šè¿‡ç”¨æˆ·è¾“å…¥çš„åå­—å’Œå¼ºåº¦æ¥ç”Ÿæˆé—®å€™è¯­ã€‚ä½¿ç”¨äº†Gradioåº“çš„InterfaceåŠŸèƒ½æ¥åˆ›å»ºä¸€ä¸ªç®€å•çš„Webç•Œé¢ã€‚", "example_code": "import gradio as gr\n\ndef greet(name, intensity):\n    return \"Hello, \" + name + \"!\" * int(intensity)\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=[\"text\", \"slider\"],\n    outputs=[\"text\"],\n)\n\ndemo.launch()", "running_command": null, "expected_input": {"name": "Alice", "intensity": 2}, "expected_output": "Hello, Alice!Hello, Alice!"}, {"task_title": "ç®€å•é—®å€™", "task_description": "è¿™ä¸ªä»»åŠ¡é€šè¿‡ç”¨æˆ·è¾“å…¥çš„åå­—ç”Ÿæˆç®€å•çš„é—®å€™è¯­ã€‚ä½¿ç”¨Gradioåº“çš„InterfaceåŠŸèƒ½ï¼Œå¹¶æ”¯æŒåˆ†äº«åŠŸèƒ½ã€‚", "example_code": "import gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(fn=greet, inputs=\"textbox\", outputs=\"textbox\")\n    \ndemo.launch(share=True)  # Share your demo with just 1 extra parameter ğŸš€", "running_command": null, "expected_input": "Alice", "expected_output": "Hello Alice!"}], "setup": {"setup_commands": ["pip install --upgrade gradio"], "docker_commands": [], "has_docker_files": true}, "timestamp": "2025-10-28T23:14:12.553539"}
{"repo_name": "crewAIInc/crewAI", "stars": 39806, "language": "Python", "tasks": [{"task_title": "åˆ›å»ºå›¢é˜Ÿ", "task_description": "è¯¥ä»»åŠ¡ç”¨äºåˆ›å»ºä¸€ä¸ªæ–°çš„å›¢é˜Ÿï¼ŒæŒ‡å®šé¡¹ç›®åç§°ã€‚ä½¿ç”¨äº†crewAIçš„CLIå‘½ä»¤ã€‚", "example_code": null, "running_command": "crewai create crew", "expected_input": "project_name", "expected_output": "å›¢é˜Ÿå·²åˆ›å»ºï¼Œé¡¹ç›®åç§°ä¸º project_name"}, {"task_title": "åˆ›å»ºæœ€æ–°çš„AIå¼€å‘å›¢é˜Ÿ", "task_description": "è¯¥ä»»åŠ¡ç”¨äºåˆ›å»ºä¸€ä¸ªåä¸ºlatest-ai-developmentçš„å›¢é˜Ÿï¼Œä½¿ç”¨äº†crewAIçš„CLIå‘½ä»¤ã€‚", "example_code": null, "running_command": "crewai create crew latest-ai-development", "expected_input": "latest-ai-development", "expected_output": "å›¢é˜Ÿå·²åˆ›å»ºï¼Œé¡¹ç›®åç§°ä¸º latest-ai-development"}], "setup": {"setup_commands": ["pip install crewai", "pip install 'crewai[tools]'"], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:14:21.805376"}
{"repo_name": "google-research/bert", "stars": 39608, "language": "Python", "tasks": [{"task_title": "æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ - MRPC", "task_description": "è¯¥ä»»åŠ¡ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨MRPCæ•°æ®é›†è¿›è¡Œå¥å­å¯¹çš„åˆ†ç±»ã€‚", "example_code": null, "running_command": "python run_classifier.py --task_name=MRPC --do_train=true --do_eval=true --data_dir=$GLUE_DIR/MRPC --vocab_file=$BERT_BASE_DIR/vocab.txt --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt --max_seq_length=128 --train_batch_size=32 --learning_rate=2e-5 --num_train_epochs=3.0 --output_dir=/tmp/mrpc_output/", "expected_input": null, "expected_output": null}, {"task_title": "æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ - MRPC é¢„æµ‹", "task_description": "è¯¥ä»»åŠ¡ç”¨äºä½¿ç”¨å·²è®­ç»ƒçš„åˆ†ç±»å™¨å¯¹MRPCæ•°æ®é›†è¿›è¡Œé¢„æµ‹ã€‚", "example_code": null, "running_command": "python run_classifier.py --task_name=MRPC --do_predict=true --data_dir=$GLUE_DIR/MRPC --vocab_file=$BERT_BASE_DIR/vocab.txt --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$TRAINED_CLASSIFIER --max_seq_length=128 --output_dir=/tmp/mrpc_output/", "expected_input": null, "expected_output": null}, {"task_title": "é—®ç­”ä»»åŠ¡ - SQuAD", "task_description": "è¯¥ä»»åŠ¡ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ä¸€ä¸ªé—®ç­”æ¨¡å‹ï¼Œä½¿ç”¨SQuADæ•°æ®é›†è¿›è¡Œé—®ç­”ã€‚", "example_code": null, "running_command": "python run_squad.py --vocab_file=$BERT_BASE_DIR/vocab.txt --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt --do_train=True --train_file=$SQUAD_DIR/train-v1.1.json --do_predict=True --predict_file=$SQUAD_DIR/dev-v1.1.json --train_batch_size=12 --learning_rate=3e-5 --num_train_epochs=2.0 --max_seq_length=384 --doc_stride=128 --output_dir=/tmp/squad_base/", "expected_input": null, "expected_output": null}, {"task_title": "é—®ç­”ä»»åŠ¡è¯„ä¼°", "task_description": "è¯¥ä»»åŠ¡ç”¨äºè¯„ä¼°é—®ç­”æ¨¡å‹çš„æ€§èƒ½ï¼Œè¾“å‡ºF1å’Œå‡†ç¡®ç‡ã€‚", "example_code": null, "running_command": "python $SQUAD_DIR/evaluate-v1.1.py $SQUAD_DIR/dev-v1.1.json ./squad/predictions.json", "expected_input": null, "expected_output": "{\"f1\": 88.41249612335034, \"exact_match\": 81.2488174077578}"}, {"task_title": "é—®ç­”ä»»åŠ¡ - SQuAD å¤§æ¨¡å‹è®­ç»ƒ", "task_description": "è¯¥ä»»åŠ¡ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ä¸€ä¸ªå¤§æ¨¡å‹çš„é—®ç­”ä»»åŠ¡ï¼Œä½¿ç”¨SQuADæ•°æ®é›†ã€‚", "example_code": null, "running_command": "python run_squad.py --vocab_file=$BERT_LARGE_DIR/vocab.txt --bert_config_file=$BERT_LARGE_DIR/bert_config.json --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt --do_train=True --train_file=$SQUAD_DIR/train-v1.1.json --do_predict=True --predict_file=$SQUAD_DIR/dev-v1.1.json --train_batch_size=24 --learning_rate=3e-5 --num_train_epochs=2.0 --max_seq_length=384 --doc_stride=128 --output_dir=gs://some_bucket/squad_large/ --use_tpu=True --tpu_name=$TPU_NAME", "expected_input": null, "expected_output": "{\"f1\": 90.87081895814865, \"exact_match\": 84.38978240302744}"}, {"task_title": "é—®ç­”ä»»åŠ¡ - SQuAD v2.0 å¤§æ¨¡å‹è®­ç»ƒ", "task_description": "è¯¥ä»»åŠ¡ç”¨äºè®­ç»ƒå’Œè¯„ä¼°ä¸€ä¸ªå¤§æ¨¡å‹çš„é—®ç­”ä»»åŠ¡ï¼Œä½¿ç”¨SQuAD v2.0æ•°æ®é›†ã€‚", "example_code": null, "running_command": "python run_squad.py --vocab_file=$BERT_LARGE_DIR/vocab.txt --bert_config_file=$BERT_LARGE_DIR/bert_config.json --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt --do_train=True --train_file=$SQUAD_DIR/train-v2.0.json --do_predict=True --predict_file=$SQUAD_DIR/dev-v2.0.json --train_batch_size=24 --learning_rate=3e-5 --num_train_epochs=2.0 --max_seq_length=384 --doc_stride=128 --output_dir=gs://some_bucket/squad_large/ --use_tpu=True --tpu_name=$TPU_NAME --version_2_with_negative=True", "expected_input": null, "expected_output": null}, {"task_title": "é—®ç­”ä»»åŠ¡ - SQuAD v2.0 é¢„æµ‹", "task_description": "è¯¥ä»»åŠ¡ç”¨äºä½¿ç”¨å·²è®­ç»ƒçš„æ¨¡å‹å¯¹SQuAD v2.0æ•°æ®é›†è¿›è¡Œé¢„æµ‹ã€‚", "example_code": null, "running_command": "python run_squad.py --vocab_file=$BERT_LARGE_DIR/vocab.txt --bert_config_file=$BERT_LARGE_DIR/bert_config.json --init_checkpoint=$BERT_LARGE_DIR/bert_model.ckpt --do_train=False --train_file=$SQUAD_DIR/train-v2.0.json --do_predict=True --predict_file=$SQUAD_DIR/dev-v2.0.json --train_batch_size=24 --learning_rate=3e-5 --num_train_epochs=2.0 --max_seq_length=384 --doc_stride=128 --output_dir=gs://some_bucket/squad_large/ --use_tpu=True --tpu_name=$TPU_NAME --version_2_with_negative=True --null_score_diff_threshold=$THRESH", "expected_input": null, "expected_output": null}, {"task_title": "ç‰¹å¾æå–", "task_description": "è¯¥ä»»åŠ¡ç”¨äºä»è¾“å…¥æ–‡æœ¬ä¸­æå–ç‰¹å¾å¹¶ä¿å­˜ä¸ºJSONLæ ¼å¼ã€‚", "example_code": "echo 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > /tmp/input.txt\n\npython extract_features.py --input_file=/tmp/input.txt --output_file=/tmp/output.jsonl --vocab_file=$BERT_BASE_DIR/vocab.txt --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt --layers=-1,-2,-3,-4 --max_seq_length=128 --batch_size=8", "running_command": null, "expected_input": "Who was Jim Henson ? ||| Jim Henson was a puppeteer", "expected_output": null}, {"task_title": "åˆ›å»ºé¢„è®­ç»ƒæ•°æ®", "task_description": "è¯¥ä»»åŠ¡ç”¨äºåˆ›å»ºBERTæ¨¡å‹çš„é¢„è®­ç»ƒæ•°æ®ã€‚", "example_code": null, "running_command": "python create_pretraining_data.py --input_file=./sample_text.txt --output_file=/tmp/tf_examples.tfrecord --vocab_file=$BERT_BASE_DIR/vocab.txt --do_lower_case=True --max_seq_length=128 --max_predictions_per_seq=20 --masked_lm_prob=0.15 --random_seed=12345 --dupe_factor=5", "expected_input": null, "expected_output": null}, {"task_title": "BERTæ¨¡å‹é¢„è®­ç»ƒ", "task_description": "è¯¥ä»»åŠ¡ç”¨äºå¯¹BERTæ¨¡å‹è¿›è¡Œé¢„è®­ç»ƒã€‚", "example_code": null, "running_command": "python run_pretraining.py --input_file=/tmp/tf_examples.tfrecord --output_dir=/tmp/pretraining_output --do_train=True --do_eval=True --bert_config_file=$BERT_BASE_DIR/bert_config.json --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt --train_batch_size=32 --max_seq_length=128 --max_predictions_per_seq=20 --num_train_steps=20 --num_warmup_steps=10 --learning_rate=2e-5", "expected_input": null, "expected_output": null}], "setup": {"setup_commands": [], "docker_commands": [], "has_docker_files": false}, "timestamp": "2025-10-28T23:14:54.234963"}
{"repo_name": "zhayujie/chatgpt-on-wechat", "stars": 39516, "language": "Python", "tasks": [{"task_title": "å¯åŠ¨åº”ç”¨ç¨‹åº", "task_description": "è¿è¡Œä¸»åº”ç”¨ç¨‹åºä»¥å¯åŠ¨èŠå¤©æœºå™¨äººåŠŸèƒ½ã€‚", "example_code": null, "running_command": "python3 app.py", "expected_input": null, "expected_output": "åº”ç”¨ç¨‹åºå¯åŠ¨å¹¶å¼€å§‹ç›‘å¬æ¶ˆæ¯"}, {"task_title": "åå°è¿è¡Œåº”ç”¨ç¨‹åº", "task_description": "åœ¨åå°å¯åŠ¨åº”ç”¨ç¨‹åºå¹¶è·Ÿè¸ªè¾“å‡ºæ—¥å¿—ã€‚", "example_code": null, "running_command": "nohup python3 app.py & tail -f nohup.out", "expected_input": null, "expected_output": "åå°è¿è¡Œï¼Œè¾“å‡ºæ—¥å¿—å®æ—¶æ›´æ–°"}, {"task_title": "æŸ¥çœ‹Dockeræ—¥å¿—", "task_description": "æŸ¥çœ‹chatgpt-on-wechatå®¹å™¨çš„å®æ—¶æ—¥å¿—ã€‚", "example_code": null, "running_command": "sudo docker logs -f chatgpt-on-wechat", "expected_input": null, "expected_output": "å®æ—¶è¾“å‡ºDockerå®¹å™¨çš„æ—¥å¿—"}], "setup": {"setup_commands": ["bash <(curl -sS https://cdn.link-ai.tech/code/cow/install.sh)", "git clone https://github.com/zhayujie/chatgpt-on-wechat\ncd chatgpt-on-wechat/", "pip3 install -r requirements.txt"], "docker_commands": ["wget https://cdn.link-ai.tech/code/cow/docker-compose.yml", "sudo docker compose up -d         # è‹¥docker-composeä¸º 1.X ç‰ˆæœ¬ï¼Œåˆ™æ‰§è¡Œ `sudo  docker-compose up -d`"], "has_docker_files": true}, "timestamp": "2025-10-28T23:15:07.223379"}
