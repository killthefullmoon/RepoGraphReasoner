<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 750px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#269A99", "fixed": true, "id": "v2.generation_functions::Fast_dLLM_QwenForCausalLM", "label": "Fast_dLLM_QwenForCausalLM()", "shape": "dot", "title": "\u003cb\u003ev2.generation_functions::Fast_dLLM_QwenForCausalLM\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Class", "x": 642.8748333130075, "y": 149.37184705550374}, {"color": "#269A99", "fixed": true, "id": "v2.generation_functions::setup_model_with_custom_generation", "label": "setup_model_with_custom_generation()", "shape": "dot", "title": "\u003cb\u003ev2.generation_functions::setup_model_with_custom_generation\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Set up custom generation functions for the model", "x": 638.142467074426, "y": 168.44640606485243}, {"color": "#269A99", "fixed": true, "id": "v2.generation_functions::batch_sample", "label": "batch_sample()", "shape": "dot", "title": "\u003cb\u003ev2.generation_functions::batch_sample\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Function", "x": 641.3605164725128, "y": 155.74558712885437}, {"color": "#269A99", "fixed": true, "id": "v2.generation_functions::mdm_sample_with_visualization", "label": "mdm_sample_with_visualization()", "shape": "dot", "title": "\u003cb\u003ev2.generation_functions::mdm_sample_with_visualization\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: MDM sampling function with visualization\nwith intermediate state output for Gradio visualization", "x": 639.7830092514107, "y": 162.10398228670766}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::fix_seed", "label": "fix_seed()", "shape": "dot", "title": "\u003cb\u003ev2.app::fix_seed\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function", "x": 659.4798493016842, "y": 26.197869474976784}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::format_chat_history", "label": "format_chat_history()", "shape": "dot", "title": "\u003cb\u003ev2.app::format_chat_history\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Format chat history for the LLaDA model\n\nArgs:\n    history: List of [user_message, assistant_message] pairs\n    \nReturns:\n    Formatted conversation for the model", "x": 659.1873245905679, "y": 32.74249683712872}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::generate_response_with_visualization_fast_dllm", "label": "generate_response_with_visualization_fast_dllm()", "shape": "dot", "title": "\u003cb\u003ev2.app::generate_response_with_visualization_fast_dllm\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate text with Fast_dLLM model with visualization using custom generation function\n\nArgs:\n    messages: List of message dictionaries with \u0027role\u0027 and \u0027content\u0027\n    max_new_tokens: Maximum number of tokens to generate\n    temperature: Sampling temperature\n    block_length: Block size for generatio\u2026", "x": 658.8298531032427, "y": 39.28389822764063}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::create_chatbot_demo", "label": "create_chatbot_demo()", "shape": "dot", "title": "\u003cb\u003ev2.app::create_chatbot_demo\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function", "x": 659.7073984154415, "y": 19.650660954021475}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::add_message", "label": "add_message()", "shape": "dot", "title": "\u003cb\u003ev2.app::add_message\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add a message pair to the history and return the updated history", "x": 659.9674865772605, "y": 6.551080895041923}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::user_message_submitted", "label": "user_message_submitted()", "shape": "dot", "title": "\u003cb\u003ev2.app::user_message_submitted\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Process a submitted user message", "x": 658.4074700597743, "y": 45.821429151516384}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::accelerated_response", "label": "accelerated_response()", "shape": "dot", "title": "\u003cb\u003ev2.app::accelerated_response\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate accelerated model response independently", "x": 660.0, "y": 0.0}, {"color": "#5B8FF9", "fixed": true, "id": "v2.app::clear_conversation", "label": "clear_conversation()", "shape": "dot", "title": "\u003cb\u003ev2.app::clear_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Clear the conversation history", "x": 659.8699495124444, "y": 13.10151634140948}, {"color": "#5B8FF9", "fixed": true, "id": "v2.run_chatbot::fix_seed", "label": "fix_seed()", "shape": "dot", "title": "\u003cb\u003ev2.run_chatbot::fix_seed\u003c/b\u003e\u003cbr\u003eModule: v2.run_chatbot\u003cbr\u003eFile: v2/run_chatbot.py\u003cbr\u003eKind: Function", "x": 636.4390515768353, "y": 174.77223357266578}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::set_seed", "label": "set_seed()", "shape": "dot", "title": "\u003cb\u003ev2.eval::set_seed\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 647.0371807791644, "y": 130.1648442911949}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::Fast_dLLM_v2EvalHarness", "label": "Fast_dLLM_v2EvalHarness()", "shape": "dot", "title": "\u003cb\u003ev2.eval::Fast_dLLM_v2EvalHarness\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Class", "x": 657.920217075673, "y": 52.35444549509964}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.eval::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 657.3681421577942, "y": 58.882303589535404}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::rank", "label": "rank()", "shape": "dot", "title": "\u003cb\u003ev2.eval::rank\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 648.2973065840968, "y": 123.73601850635787}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::world_size", "label": "world_size()", "shape": "dot", "title": "\u003cb\u003ev2.eval::world_size\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 644.3258105740354, "y": 142.98339004273285}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::tokenizer_name", "label": "tokenizer_name()", "shape": "dot", "title": "\u003cb\u003ev2.eval::tokenizer_name\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 645.7133052973023, "y": 136.58084551661292}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::apply_chat_template", "label": "apply_chat_template()", "shape": "dot", "title": "\u003cb\u003ev2.eval::apply_chat_template\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 654.5128067001903, "y": 84.92929921669804}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::loglikelihood_rolling", "label": "loglikelihood_rolling()", "shape": "dot", "title": "\u003cb\u003ev2.eval::loglikelihood_rolling\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 649.4935585575448, "y": 117.29500156552757}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::_encode_pair", "label": "_encode_pair()", "shape": "dot", "title": "\u003cb\u003ev2.eval::_encode_pair\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 656.7512996996079, "y": 65.40436027418791}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::_forward_process", "label": "_forward_process()", "shape": "dot", "title": "\u003cb\u003ev2.eval::_forward_process\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 656.0697504758405, "y": 71.9199729600083}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::get_logits", "label": "get_logits()", "shape": "dot", "title": "\u003cb\u003ev2.eval::get_logits\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 652.6979244105314, "y": 97.9051554831729}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::get_loglikelihood", "label": "get_loglikelihood()", "shape": "dot", "title": "\u003cb\u003ev2.eval::get_loglikelihood\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 651.6939758693959, "y": 104.37893377276497}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::loglikelihood", "label": "loglikelihood()", "shape": "dot", "title": "\u003cb\u003ev2.eval::loglikelihood\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 650.6258188381569, "y": 110.84242807326963}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::generate_until", "label": "generate_until()", "shape": "dot", "title": "\u003cb\u003ev2.eval::generate_until\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 653.6375655470079, "y": 91.42173103688815}, {"color": "#9270CA", "fixed": true, "id": "v2.eval::_tokenize", "label": "_tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.eval::_tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 655.3235616364859, "y": 78.42849969284609}, {"color": "#FF9D4D", "fixed": true, "id": "v2.train_scripts.finetune::main", "label": "main()", "shape": "dot", "title": "\u003cb\u003ev2.train_scripts.finetune::main\u003c/b\u003e\u003cbr\u003eModule: v2.train_scripts.finetune\u003cbr\u003eFile: v2/train_scripts/finetune.py\u003cbr\u003eKind: Function", "x": 659.9674865772605, "y": -6.551080895041782}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::OptimizerNames", "label": "OptimizerNames()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::OptimizerNames\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 608.6579191231788, "y": 255.2166481416171}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::ModelArguments", "label": "ModelArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::ModelArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class ModelArguments using the dataclass decorator. \nThe class contains several optional parameters that can be used to configure a model. \n\nmodel_name_or_path : str\n    a string representing the path or name of a pretrained\n    model checkpoint for weights initialization. If None, a model \u2026", "x": 613.6042355278614, "y": 243.08402280336892}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::VisModelArguments", "label": "VisModelArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::VisModelArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 600.7893280715996, "y": 273.2255172477048}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::DatasetArguments", "label": "DatasetArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::DatasetArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class DatasetArguments using the dataclass decorator.\nThe class contains several optional parameters that can be used to configure a dataset for a language model.\n\n\ndataset_path : str\n    a string representing the path of the dataset to use.\n\ndataset_name : str\n    a string representing the\u2026", "x": 626.9849641953356, "y": 206.13067377994415}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::MultiModalDatasetArguments", "label": "MultiModalDatasetArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::MultiModalDatasetArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 611.161184813344, "y": 249.16260991077615}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::FinetunerArguments", "label": "FinetunerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::FinetunerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Adapt transformers.TrainingArguments", "x": 622.7695640570365, "y": 218.5361985672138}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::RewardModelTunerArguments", "label": "RewardModelTunerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::RewardModelTunerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Arguments for reward modeling.", "x": 603.471735266567, "y": 267.2486945419163}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::EvaluatorArguments", "label": "EvaluatorArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::EvaluatorArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class EvaluatorArguments using the dataclass decorator. The class contains several optional\nparameters that can be used to configure a evaluator.\n\nlocal_rank : str\n    For distributed training: local_rank\n\nrandom_shuffle : bool\n\nuse_wandb : bool\n\nrandom_seed : int, default = 1\n\noutput_dir :\u2026", "x": 624.9080488224961, "y": 212.34389682037207}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::InferencerArguments", "label": "InferencerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::InferencerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class InferencerArguments using the dataclass decorator. The class contains several optional\nparameters that can be used to configure a inferencer.\n\nlocal_rank : str\n    For distributed training: local_rank\nrandom_seed : int, default = 1\ninference_batch_size : int, default = 1\ndeepspeed :\n \u2026", "x": 620.5697205942878, "y": 224.70696892069824}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::RaftAlignerArguments", "label": "RaftAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::RaftAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class RaftAlignerArguments to configure raft aligner.", "x": 606.0946850929283, "y": 261.24554101860593}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::BenchmarkingArguments", "label": "BenchmarkingArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::BenchmarkingArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 632.8442781175413, "y": 187.37160845199574}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::DPOAlignerArguments", "label": "DPOAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::DPOAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The arguments for the DPO training script.", "x": 630.953274332775, "y": 193.643914463507}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::DPOv2AlignerArguments", "label": "DPOv2AlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::DPOv2AlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The arguments for the DPOv2 training script.", "x": 629.0001055463807, "y": 199.89714160698233}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::IterativeAlignerArguments", "label": "IterativeAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::IterativeAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Arguments for iterative aligners.", "x": 618.3087351749784, "y": 230.85559990244636}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::IterativeDPOAlignerArguments", "label": "IterativeDPOAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::IterativeDPOAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Arguments for iterative DPO aligners.", "x": 615.9868305638806, "y": 236.981485715372}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::AutoArguments", "label": "AutoArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::AutoArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Automatically choose arguments from FinetunerArguments or EvaluatorArguments.", "x": 634.672930588542, "y": 181.08084155468148}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::split_args", "label": "split_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::split_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Function", "x": 586.494885120874, "y": 302.6941521190206}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::__post_init__", "label": "__post_init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::__post_init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Function", "x": 592.3880342643248, "y": 290.99212508322125}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::get_pipeline_args_class", "label": "get_pipeline_args_class()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::get_pipeline_args_class\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Function", "x": 589.4704986373185, "y": 296.8577626343482}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset", "label": "get_paired_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load dataset and convert it to the necessary format.\n\n    The dataset is converted to a dictionary with the following structure:\n    {\n        \u0027prompt\u0027: List[str],\n        \u0027chosen\u0027: List[str],\n        \u0027rejected\u0027: List[str],\n    }\n\n    Prompts are structured as follows:\n      \"Question: \" + \u003cprompt\u003e \u2026", "x": -621.6772987579693, "y": 221.6243132171977}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "label": "DPOAligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::DPOAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Class", "x": -609.9170635642606, "y": 252.19273497297587}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::return_prompt_and_responses", "label": "return_prompt_and_responses()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::return_prompt_and_responses\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": -623.8464895873209, "y": 215.44270103574354}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": -612.3902522258155, "y": 246.1263475916427}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer", "label": "_initialize_trainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": -614.8031048172123, "y": 240.03571048307757}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset", "label": "_load_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::_load_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": -617.1553836108867, "y": 233.9214237304897}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::align", "label": "align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": -619.4468568473391, "y": 227.78408974718198}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "label": "IterativeDPOAligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Class", "x": -638.9706075755752, "y": -165.27722969151063}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -635.563818538128, "y": -177.92872889231134}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align", "label": "align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -619.4468568473392, "y": -227.78408974718155}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "label": "_align_single_iteration()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -633.7664096720133, "y": -184.2284939184102}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference", "label": "_do_target_model_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -628.0002691753913, "y": -203.01640799609302}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference", "label": "_do_reward_model_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -631.9065586386392, "y": -190.51010773571025}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "label": "_do_single_dpo_align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -629.9844486808018, "y": -196.77295144492317}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args", "label": "_parse_target_model_inference_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -621.6772987579694, "y": -221.6243132171975}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args", "label": "_parse_reward_model_inference_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -623.8464895873209, "y": -215.4427010357434}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args", "label": "_parse_dpo_aligner_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -625.9542156147315, "y": -209.23986224939614}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args", "label": "__filter_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": -637.2986081463332, "y": -171.6114333450617}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::BaseTuner", "label": "BaseTuner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::BaseTuner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A subclass of BasePipeline which is tunable.\n    ", "x": -599.4259103220076, "y": 276.20387041935624}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Function", "x": -602.1379474593069, "y": 270.24043411283407}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::_check_if_tunable", "label": "_check_if_tunable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::_check_if_tunable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Function", "x": -604.790658640142, "y": 264.2503722260825}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::tune", "label": "tune()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::tune\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Function", "x": -607.3837825047553, "y": 258.2342749330848}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::InferencerWithOffloading", "label": "InferencerWithOffloading()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::InferencerWithOffloading\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 73.54779401278955, "y": -655.8892604669269}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "label": "VLLMInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 86.55321664565682, "y": -654.300038734746}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer", "label": "MemorySafeVLLMInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 80.05444903247131, "y": -655.1269229623429}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 118.90636403661227, "y": -649.2004902890883}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 150.96668634248365, "y": -642.5021864669179}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::save_inference_results", "label": "save_inference_results()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::save_inference_results\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 182.655230122192, "y": -634.2216228646017}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::load_inference_results", "label": "load_inference_results()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::load_inference_results\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 163.6911099852475, "y": -639.3787770264178}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params", "label": "parse_to_sampling_params()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 170.02944321648323, "y": -637.7225011237198}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::_inference", "label": "_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 131.7700716150321, "y": -646.7121834530175}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference", "label": "_distributed_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 125.3443926367701, "y": -647.9882585622361}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::scheduling_strategy_fn", "label": "scheduling_strategy_fn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::scheduling_strategy_fn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 188.94143983440173, "y": -632.3773654340446}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::DistributedPredictor", "label": "DistributedPredictor()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::DistributedPredictor\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 67.03389265820448, "y": -656.5869761387963}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::__call__", "label": "__call__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: batch: Dict[str, np.ndarray], {\"item\": array([\u0027...\u0027, \u0027...\u0027, \u0027...\u0027, ...])}\n                ", "x": 93.04345655786581, "y": -653.4086892533375}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::rstrip_partial_utf8", "label": "rstrip_partial_utf8()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::rstrip_partial_utf8\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": -647.6752202982631, "y": -126.95199490987316}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::Inferencer", "label": "Inferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::Inferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Inferencer` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\ninferencer_args : InferencerArg\u2026", "x": -658.6267730749053, "y": -42.5531877646928}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "label": "SpeculativeInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::SpeculativeInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Ref: [arXiv:2211.17192v2](https://arxiv.org/abs/2211.17192)\n\nParameters\n------------\ntarget_model_args : ModelArguments object.\n    Contains the arguments required to load the target model.\n    \ndraft_model_args : ModelArguments object.\n    Contains the arguments required to load the draft model.\n\nd\u2026", "x": -658.1719494596191, "y": -49.08854188631615}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::ToolInferencer", "label": "ToolInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::ToolInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `ToolInferencer` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\ninferencer_args : Inference\u2026", "x": -657.6522791084905, "y": -55.61905953365462}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": -655.7047315623798, "y": -75.17516216615346}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "label": "create_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::create_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Batchlize dataset and format it to dataloader.\n\nArgs:\n    dataset (Dataset): the dataset object\n\nOutput:\n    dataloader (batchlize): the dataloader object\n    dataset_size (int): the length of the dataset", "x": -653.1757893391248, "y": -94.66460912723059}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform inference for a model\n\nParameters\n------------\nmodel : TunableModel object.\n    TunableModel to perform inference\n\ndataset : Dataset object.\n\n\nReturns:\n\noutput_dataset: Dataset object.", "x": -650.0676947796397, "y": -114.07011968033123}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::stream_inference", "label": "stream_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::stream_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": -640.5796520912347, "y": -158.92674201238935}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::score_to_prob", "label": "score_to_prob()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::score_to_prob\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Convert scores (NOT softmaxed tensor) to probabilities with support for temperature, top-p sampling, and argmax.\n\nParameters\n----------\nscores : torch.Tensor\n    Input scores.\ntemperature : float, optional\n    Temperature parameter for controlling randomness. Higher values make the distribution more\u2026", "x": -645.0275019436209, "y": -139.78383932476632}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::sample", "label": "sample()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::sample\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Sample from a tensor of probabilities\n        ", "x": -646.3832037426919, "y": -133.37448751291848}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::predict_next_token", "label": "predict_next_token()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::predict_next_token\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Predict the next token given the input_ids.\n        ", "x": -648.9034243137268, "y": -120.516994295076}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "label": "autoregressive_sampling()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::autoregressive_sampling\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Ref: [arXiv:2211.17192v2](https://arxiv.org/abs/2211.17192) Section 2.2\n        ", "x": -654.9262500869587, "y": -81.679905405396}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::code_exec", "label": "code_exec()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::code_exec\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": -654.0832416599249, "y": -88.1766010892023}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "label": "speculative_sampling()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::speculative_sampling\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Ref: [arXiv:2211.17192v2](https://arxiv.org/abs/2211.17192)\n\nParameters\n----------\ninput_ids : torch.Tensor\ndraft_model : TunableModel object\nmodel_list : List[TunableModel object]\n\nReturns\n-------\ntorch.Tensor", "x": -643.6082484722795, "y": -146.17941886067442}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "label": "RaftAligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::RaftAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `RaftAligner` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nraft_aligner_args : RaftAligne\u2026", "x": -617.1553836108867, "y": -233.92142373048955}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": -614.8031048172124, "y": -240.03571048307742}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "label": "_initialize_trainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_initialize_trainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function takes the model and tokenizer as the input and initialize the trainer.", "x": -602.137947459307, "y": -270.24043411283367}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "label": "_load_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_load_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function prepares the dataset for every iteration.", "x": -599.4259103220074, "y": -276.20387041935635}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset", "label": "_load_input_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_load_input_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load input dataset (i.e. prompt/question dataset) for training.\n\nArgs:\n    dataset: A Dataset object.\n        The dataset to be loaded.\n\nReturns:\n    dataloader (`torch.utils.data.DataLoader`):\n        The dataloader for the dataset.", "x": -596.6548144331225, "y": -282.1400935949658}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_clean_text", "label": "_clean_text()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_clean_text\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": -612.3902522258156, "y": -246.1263475916423}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_discard_sample", "label": "_discard_sample()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_discard_sample\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": -609.9170635642607, "y": -252.19273497297573}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_top", "label": "_get_batch_dataset_top()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_top\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: :param batch_input: input prompts", "x": -604.7906586401422, "y": -264.2503722260824}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_local", "label": "_get_batch_dataset_local()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_local\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: :param batch_input: input prompts", "x": -607.3837825047556, "y": -258.2342749330844}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::align", "label": "align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform alignment for a model\n\nParameters\n------------\nmodel : BaseModel object.\ndataset: Dataset object.\n    Input dataset for model to generate outputs. The input and output\n        will then be feed into reward model to get the reward for\n        alignment.\nreward_model: RegressionModel object.", "x": -593.8249328163247, "y": -288.0485187701673}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::tokenize_function", "label": "tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": -584.985390548214, "y": -305.60119902440437}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::group_texts", "label": "group_texts()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::group_texts\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": -590.9365442871818, "y": -293.92856381427714}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::tokenize", "label": "tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": -587.9899334256859, "y": -299.77964939277894}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.auto_pipeline::AutoPipeline", "label": "AutoPipeline()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.auto_pipeline::AutoPipeline\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.auto_pipeline\u003cbr\u003eFile: v2/src/lmflow/pipeline/auto_pipeline.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The class designed to return a pipeline automatically based on its name.", "x": -578.8036985205983, "y": 317.15339912868075}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.pipeline.auto_pipeline::get_pipeline", "label": "get_pipeline()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.auto_pipeline::get_pipeline\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.auto_pipeline\u003cbr\u003eFile: v2/src/lmflow/pipeline/auto_pipeline.py\u003cbr\u003eKind: Function", "x": -581.9232116789262, "y": 311.3926391379277}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "label": "RewardModelInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Inferencer` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\ninferencer_args : InferencerArg\u2026", "x": -578.8036985205985, "y": -317.1533991286806}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -562.3570717016114, "y": -345.4772407948006}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -540.7968699596867, "y": -378.33681481162495}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "label": "_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -551.8216130706159, "y": -362.06754528422397}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "label": "__inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -569.1042548902522, "y": -334.2459379944817}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "label": "__distributed_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__distributed_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -572.3939043620991, "y": -328.5806114929976}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__vllm_inference", "label": "__vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -555.3882678725, "y": -356.5723936448027}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__post_process_model_output", "label": "__post_process_model_output()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__post_process_model_output\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -558.9002027545729, "y": -351.0421105236483}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::flatten_list", "label": "flatten_list()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::flatten_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -544.5255546902237, "y": -372.9502919817926}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::compress_list", "label": "compress_list()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::compress_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -548.200589755451, "y": -367.52702402922125}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::scheduling_strategy_fn", "label": "scheduling_strategy_fn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::scheduling_strategy_fn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": -537.0149029344556, "y": -383.6860618087361}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "label": "DistributedPredictor()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Class", "x": -581.9232116789262, "y": -311.3926391379276}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__call__", "label": "__call__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: batch: Dict[str, np.ndarray]\nExample (batch size=2):\n{\u0027input\u0027: array([\u0027...\u0027,\u0027...\u0027], dtype=object),\n \u0027output\u0027: array([array([\"...\", \"...\"], dtype=object), array([\u0027...\u0027,\u0027...\u0027], dtype=object)], dtype=object),\n \u0027input_ids\u0027: array([[[128000, 128006,    882, ..., 128256, 128256, 128256],\n         [128000,\u2026", "x": -575.6271584248975, "y": -322.88291141476964}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "label": "RewardModelTuner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::RewardModelTuner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `RewardModelTuner` class.\n\nParameters\n----------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nfinetuner_args : RewardModelTunerArguments objec\u2026", "x": -529.2926176939866, "y": -394.27062387990225}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": -521.3617422626367, "y": -404.69980689996385}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::tune", "label": "tune()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::tune\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": -504.8868037898689, "y": -425.07565839371523}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback", "label": "DynamicLayerActivationCallback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Class", "x": -533.1800262348106, "y": -388.99750593576647}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::freeze_all_layers", "label": "freeze_all_layers()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::freeze_all_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": -517.319056765764, "y": -409.85484443517356}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::on_step_begin", "label": "on_step_begin()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::on_step_begin\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": -513.2254021380315, "y": -414.9695008072953}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers", "label": "switch_active_layers()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::switch_active_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": -509.0811817089043, "y": -420.04327209213284}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::BaseAligner", "label": "BaseAligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::BaseAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A subclass of BasePipeline which is alignable.\n    ", "x": -584.985390548214, "y": 305.60119902440425}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Function", "x": -587.9899334256858, "y": 299.7796493927791}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::_check_if_alignable", "label": "_check_if_alignable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::_check_if_alignable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Function", "x": -590.9365442871818, "y": 293.928563814277}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::align", "label": "align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Function", "x": -593.8249328163247, "y": 288.04851877016745}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.base_pipeline::BasePipeline", "label": "BasePipeline()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_pipeline::BasePipeline\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_pipeline\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_pipeline.py\u003cbr\u003eKind: Class", "x": -596.6548144331225, "y": 282.14009359496595}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "label": "DPOv2Aligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Class", "x": -625.9542156147315, "y": 209.23986224939603}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "label": "MemorySafeDPOv2Aligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Class", "x": -628.0002691753912, "y": 203.0164079960932}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": -631.9065586386392, "y": 190.5101077357104}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::align", "label": "align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": -643.6082484722795, "y": 146.1794188606746}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::__prepare_training_args", "label": "__prepare_training_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::__prepare_training_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": -633.7664096720134, "y": 184.22849391841007}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "label": "convert_to_paired_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Convert a scored one to multiple (text_to_scored_textlist) to a paired dataset by rejection sampling.\n        ", "x": -645.0275019436209, "y": 139.78383932476646}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths", "label": "_calc_response_lengths()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": -635.5638185381279, "y": 177.92872889231154}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty", "label": "_calc_reward_with_length_penalty()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: When length_penalty \u003e 0, penalize the longer sequence by subtracting \nlength_penalty * length from the reward. Vice versa when length_penalty \u003c 0.", "x": -637.2986081463332, "y": 171.61143334506156}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards", "label": "sampling_paired_idx_from_rewards()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare the dataset for DPO training by rejection sampling.\nWe implement different strategies to select pairs, including\nrandom: randomly select two instances\nmax_min: best v.s. worst\nmax_max: best v.s. second best\nmax_random: best v.s. random from the remaining", "x": -646.3832037426919, "y": 133.37448751291862}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards", "label": "_sampling_paired_idx_from_rewards()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": -638.9706075755751, "y": 165.27722969151077}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards_fast", "label": "_sampling_paired_idx_from_rewards_fast()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards_fast\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": -640.5796520912346, "y": 158.9267420123901}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::Finetuner", "label": "Finetuner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::Finetuner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Finetuner` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nfinetuner_args : FinetunerArgume\u2026", "x": -658.1719494596191, "y": 49.088541886316605}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.0167051426142, "y": 36.013641067970795}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::group_text", "label": "group_text()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::group_text\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Groups texts together to form blocks of maximum length `model_max_length` and returns the processed data as\na dictionary.", "x": -659.9918715942613, "y": -3.2755807888084183}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer", "label": "create_customized_optimizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::create_customized_optimizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.601747359515, "y": 22.924547547868784}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::tune", "label": "tune()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::tune\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform tuning for a model\n\nParameters\n------------\nmodel : TunableModel object.\n    TunableModel to perform tuning.\n\ndataset:\n    dataset to train model.", "x": -659.0167051426142, "y": -36.01364106797063}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::group_texts", "label": "group_texts()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::group_texts\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.926845549638, "y": -9.826419638113293}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::CustomizedOptimTrainer", "label": "CustomizedOptimTrainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::CustomizedOptimTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Class", "x": -657.0678132223127, "y": 62.14409728403905}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs", "label": "get_optimizer_cls_and_kwargs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.9918715942613, "y": 3.2755807888082873}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::create_optimizer", "label": "create_optimizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::create_optimizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.7967998671162, "y": 16.37629033427982}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::preprocess_logits_for_metrics", "label": "preprocess_logits_for_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::preprocess_logits_for_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.601747359515, "y": -22.924547547868624}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::compute_metrics", "label": "compute_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::compute_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.341707244485, "y": 29.470546108410677}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback", "label": "DynamicLayerActivationCallback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Class", "x": -657.6522791084905, "y": 55.61905953365508}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::freeze_all_layers", "label": "freeze_all_layers()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::freeze_all_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.926845549638, "y": 9.826419638113162}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::on_step_begin", "label": "on_step_begin()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::on_step_begin\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.7967998671162, "y": -16.37629033427966}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::switch_active_layers", "label": "switch_active_layers()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::switch_active_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": -659.341707244485, "y": -29.470546108410517}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::Evaluator", "label": "Evaluator()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::Evaluator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Evaluator` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nevaluator_args : EvaluatorArgume\u2026", "x": -647.6752202982631, "y": 126.95199490987333}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": -648.9034243137268, "y": 120.51699429507617}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::create_dataloader", "label": "create_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::create_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": -654.9262500869587, "y": 81.67990540539616}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_match", "label": "_match()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_match\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": -654.0832416599249, "y": 88.17660108920276}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::evaluate", "label": "evaluate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::evaluate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform Evaluation for a model\n\nParameters\n------------\nmodel : TunableModel object.\n    TunableModel to perform inference\n\ndataset : Dataset object.\n    ", "x": -655.7047315623797, "y": 75.17516216615391}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator", "label": "_evaluate_acc_with_accelerator()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": -650.0676947796397, "y": 114.0701196803311}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed", "label": "_evaluate_acc_with_deepspeed()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": -651.1679169856449, "y": 107.61200624733424}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_ppl", "label": "_evaluate_ppl()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_ppl\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": -653.1757893391247, "y": 94.66460912723076}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "label": "_evaluate_nll()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_nll\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Evaluates negative log likelihood of the model over a dataset.\n\nNLL = -1/N sum_{i=1}^N sum_{j=1}^|w_i| ln(p(w_{i,j}|context_window)),\n\nwhere N is the number of data samples, w_{i,j} is the j-th token in\ni-th sample. Here \"context_window\" = p(w_{i,start}, w_{i,start+1}, ...,\np_{i,j-1} with start = ma\u2026", "x": -652.2039825317732, "y": 101.14329028509202}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::get_nll", "label": "get_nll()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::get_nll\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": -656.4186093858931, "y": 68.66301225470859}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding", "label": "PreferenceDataCollatorWithPadding()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Class", "x": -500.642681634206, "y": -430.06616389354673}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element", "label": "tokenize_batch_element()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize a single batch element.\n\nAt this stage, we don\u0027t convert to PyTorch tensors yet; we just handle the truncation\n    in case the prompt + chosen or prompt + rejected responses is/are too long. First\n    we truncate the prompt; if we\u0027re still too long, we truncate the chosen/rejected.\n\nWe also\u2026", "x": -487.61605554873233, "y": -444.78149958276765}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate", "label": "collate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Function", "x": -492.00688209030255, "y": -439.919569894065}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__", "label": "__call__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Function", "x": -496.3492333962719, "y": -435.01429689946184}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding", "label": "RewardDataCollatorWithPadding()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_dataprocessor.py\u003cbr\u003eKind: Class", "x": 14.73894871827636, "y": -659.835406287568}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::__call__", "label": "__call__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_dataprocessor::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_dataprocessor.py\u003cbr\u003eKind: Function", "x": 21.28766979453712, "y": -659.6566039347433}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::compute_metrics", "label": "compute_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::compute_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Function", "x": 53.98691873720141, "y": -657.7882733868572}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss", "label": "rm_loss()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::rm_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Function", "x": 60.51338675425617, "y": -657.2200012351494}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::RewardTrainer", "label": "RewardTrainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::RewardTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Class", "x": 34.378174801103796, "y": -659.1040442125543}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::PeftRewardTrainer", "label": "PeftRewardTrainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::PeftRewardTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Class", "x": 27.834293491988866, "y": -659.4128085697166}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::compute_loss", "label": "compute_loss()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::compute_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Function", "x": 47.45513163071905, "y": -658.2917366046083}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "label": "DPOv2Trainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Class", "x": -483.17718638004567, "y": -449.59960694140136}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function", "x": -478.69071192615, "y": -454.3734172634174}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "label": "dpo_loss()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Compute the DPO loss for a batch of policy and reference model log probabilities.\n\nArgs:\n    policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n    policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (\u2026", "x": -474.1570742192903, "y": -459.10246020665414}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_loss_metrics", "label": "get_batch_loss_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_loss_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function", "x": -469.5767199384938, "y": -463.7862698396809}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics", "label": "get_batch_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Compute the DPO loss and other metrics for the given batch of inputs for train or test.", "x": -464.95010036556414, "y": -468.4243846877016}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer", "label": "PeftTrainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Class", "x": -445.9901533832434, "y": -486.5108252497482}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "label": "PeftSavingCallback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Correctly save PEFT model and not full model ", "x": -450.79723081677383, "y": -482.0600135749991}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint", "label": "_save_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Don\u0027t save base model, optimizer etc.\nbut create checkpoint folder (needed for saving adapter) ", "x": -436.2446522254029, "y": -495.26821360222306}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::_save", "label": "_save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::_save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function", "x": -441.13913453639594, "y": -490.9137031907742}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end", "label": "on_train_end()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::on_train_end\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save final best model adapter ", "x": -421.3052679476797, "y": -508.0372734352607}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::on_epoch_end", "label": "on_epoch_end()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::on_epoch_end\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save intermediate model adapters in case of interrupted training ", "x": -431.307188681696, "y": -499.57392745367713}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::on_save", "label": "on_save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::on_save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function", "x": -426.3272303714549, "y": -503.8304205224258}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "label": "RaftTrainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Trainer is a simple but feature-complete training and eval loop for PyTorch, optimized for \ud83e\udd17 Transformers.\nArgs:\n    model ([`PreTrainedModel`] or `torch.nn.Module`, *optional*):\n        The model to train, evaluate or use for predictions. If not provided, a `model_init` must be passed.\n        \u003cTip\u2026", "x": -416.241796201846, "y": -512.1940717097972}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -411.13731401515867, "y": -516.3004057953091}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback", "label": "add_callback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::add_callback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add a callback to the current list of [`~transformer.TrainerCallback`].\nArgs:\n   callback (`type` or [`~transformer.TrainerCallback`]):\n       A [`~transformer.TrainerCallback`] class or an instance of a [`~transformer.TrainerCallback`]. In the\n       first case, will instantiate a member of that cl\u2026", "x": -229.32055089047762, "y": -618.8797015085306}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::pop_callback", "label": "pop_callback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::pop_callback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Remove a callback from the current list of [`~transformer.TrainerCallback`] and returns it.\nIf the callback is not found, returns `None` (and no error is raised).\nArgs:\n   callback (`type` or [`~transformer.TrainerCallback`]):\n       A [`~transformer.TrainerCallback`] class or an instance of a [`~tr\u2026", "x": -57.25085783391262, "y": -657.5122350780107}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::remove_callback", "label": "remove_callback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::remove_callback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Remove a callback from the current list of [`~transformer.TrainerCallback`].\nArgs:\n   callback (`type` or [`~transformer.TrainerCallback`]):\n       A [`~transformer.TrainerCallback`] class or an instance of a [`~transformer.TrainerCallback`]. In the\n       first case, will remove the first member of\u2026", "x": -24.561284134297647, "y": -659.5428290275578}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device", "label": "_move_model_to_device()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -329.9999999999997, "y": -571.5767664977296}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed", "label": "_set_signature_columns_if_needed()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -253.7054727028249, "y": -609.2893673129674}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns", "label": "_remove_unused_columns()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -289.5212133469652, "y": -593.1083096889648}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns", "label": "_get_collator_with_removed_columns()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Wrap the data collator in a callable removing unused columns.", "x": -395.5828539329479, "y": -528.3126022292711}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler", "label": "_get_train_sampler()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -379.6776418207823, "y": -539.8563589524622}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "label": "get_train_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the training [`~torch.utils.data.DataLoader`].\nWill use no sampler if `train_dataset` does not implement `__len__`, a random sampler (adapted to distributed\ntraining if necessary) otherwise.\nSubclass and override this method if you want to inject some custom behavior.", "x": -128.55881542622444, "y": -647.3581937198338}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler", "label": "_get_eval_sampler()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -390.3193988607773, "y": -532.2130840865916}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "label": "get_eval_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the evaluation [`~torch.utils.data.DataLoader`].\nSubclass and override this method if you want to inject some custom behavior.\nArgs:\n    eval_dataset (`torch.utils.data.Dataset`, *optional*):\n        If provided, will override `self.eval_dataset`. If it is a [`~datasets.Dataset`], columns no\u2026", "x": -147.77608795272948, "y": -643.2435214049086}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "label": "get_test_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the test [`~torch.utils.data.DataLoader`].\nSubclass and override this method if you want to inject some custom behavior.\nArgs:\n    test_dataset (`torch.utils.data.Dataset`, *optional*):\n        The test dataset to use. If it is a [`~datasets.Dataset`], columns not accepted by the\n        `mo\u2026", "x": -134.97808210503328, "y": -646.0502436740094}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler", "label": "create_optimizer_and_scheduler()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Setup the optimizer and the learning rate scheduler.\nWe provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\nTrainer\u0027s init through `optimizers`, or subclass and override this method (or `create_optimizer` and/or\n`create_scheduler`) in a subcla\u2026", "x": -179.5053379107941, "y": -635.1203300647301}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer", "label": "create_optimizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Setup the optimizer.\nWe provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\nTrainer\u0027s init through `optimizers`, or subclass and override this method in a subclass.", "x": -185.80062325534578, "y": -633.3072938139312}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_optimizer_cls_and_kwargs", "label": "get_optimizer_cls_and_kwargs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_optimizer_cls_and_kwargs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the optimizer class and optimizer parameters based on the training arguments.\nArgs:\n    args (`transformers.training_args.TrainingArguments`):\n        The training arguments for the training session.", "x": -141.38404999764805, "y": -644.6786411897501}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_scheduler", "label": "create_scheduler()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_scheduler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Setup the scheduler. The optimizer of the trainer must have been set up either before this method is called or\npassed as an argument.\nArgs:\n    num_training_steps (int): The number of training steps to do.", "x": -173.1923667088616, "y": -636.8707907525538}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples", "label": "num_examples()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::num_examples\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Helper to get number of samples in a [`~torch.utils.data.DataLoader`] by accessing its dataset. When\ndataloader.dataset does not exist or has no length, estimates as best it can", "x": -83.30485880223453, "y": -654.7215442460556}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_hp_search_setup", "label": "_hp_search_setup()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_hp_search_setup\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: HP search setup code", "x": -374.3003883376407, "y": -543.5983989033552}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "label": "_report_to_hp_search()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -283.61982873803277, "y": -595.9528443984549}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint", "label": "_tune_save_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -241.56061039537275, "y": -614.2055612784818}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::call_model_init", "label": "call_model_init()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::call_model_init\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -210.79252855376146, "y": -625.4330578934181}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval", "label": "torch_jit_model_eval()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -4.91334596985376, "y": -659.9817111340136}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model", "label": "ipex_optimize_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -109.22755346607495, "y": -650.8988719945793}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model", "label": "_wrap_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -235.45217966754987, "y": -616.5730054825623}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "label": "train()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Main training entry point.\nArgs:\n    resume_from_checkpoint (`str` or `bool`, *optional*):\n        If a `str`, local path to a saved checkpoint as saved by a previous instance of [`Trainer`]. If a\n        `bool` and equals `True`, load the last checkpoint in *args.output_dir* as saved by a previous \u2026", "x": 1.6377954370884886, "y": -659.997967895437}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "label": "_one_train()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_one_train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -318.58872877646485, "y": -578.0148976424364}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "label": "_inner_training_loop()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: 0 This function serves to train one time\n1 Update the self.train_dataset before calling this function", "x": -368.8862567128091, "y": -547.2868805374486}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir", "label": "_get_output_dir()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -385.01748736552065, "y": -536.0611293712138}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint", "label": "_load_from_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -352.4279451412006, "y": -558.0273680417037}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model", "label": "_load_best_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -357.949496339569, "y": -554.501720529566}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load", "label": "_issue_warnings_after_load()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -363.43578037644033, "y": -550.921440445158}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "label": "_maybe_log_save_evaluate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -335.6571457659835, "y": -568.2730686001522}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_rng_state", "label": "_load_rng_state()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_rng_state\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -341.2812207359795, "y": -564.9133813010271}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "label": "_save_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -265.75035161506327, "y": -604.1330570465998}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_optimizer_and_scheduler", "label": "_load_optimizer_and_scheduler()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_optimizer_and_scheduler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: If optimizer and scheduler states exist, load them.", "x": -346.87167079505826, "y": -561.4980356153036}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::hyperparameter_search", "label": "hyperparameter_search()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::hyperparameter_search\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Launch an hyperparameter search using `optuna` or `Ray Tune` or `SigOpt`. The optimized quantity is determined\nby `compute_objective`, which defaults to a function returning the evaluation loss when no metric is provided,\nthe sum of all metrics otherwise.\n\u003cTip warning={true}\u003e\nTo use this method, you\u2026", "x": -122.12688242283072, "y": -648.6023624607607}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::log", "label": "log()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::log\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Log `logs` on the various objects watching training.\nSubclass and override this method to inject custom behavior.\nArgs:\n    logs (`Dict[str, float]`):\n        The values to log.", "x": -89.79944255070784, "y": -653.8624168107402}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input", "label": "_prepare_input()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares one `data` before feeding it to the model, be it a tensor or a nested list/dictionary of tensors.", "x": -307.0519041604836, "y": -584.2252375166801}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs", "label": "_prepare_inputs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare `inputs` before feeding them to the model, converting them to tensors if they are not already and\nhandling potential state.", "x": -301.23782825099886, "y": -587.2442173666947}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager", "label": "compute_loss_context_manager()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: A helper wrapper to group together context managers.", "x": -198.335657190792, "y": -629.4942152924812}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager", "label": "autocast_smart_context_manager()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: A helper wrapper that creates an appropriate context manager for `autocast` while feeding it the desired\narguments, depending on the situation.", "x": -216.99011790240118, "y": -623.3099459600352}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "label": "training_step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::training_step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform a training step on a batch of inputs.\nSubclass and override to inject custom behavior.\nArgs:\n    model (`nn.Module`):\n        The model to train.\n    inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n        The inputs and targets of the model.\n        The dictionary will be unpacked before be\u2026", "x": 8.188775479377403, "y": -659.9491980115956}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss", "label": "compute_loss()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::compute_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: How the loss is computed by Trainer. By default, all models return the loss in the first element.\nSubclass and override for custom behavior.", "x": -204.57417076090658, "y": -627.4945487073871}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::is_local_process_zero", "label": "is_local_process_zero()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::is_local_process_zero\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Whether or not this process is the local (e.g., on one machine if training in a distributed fashion on several\nmachines) main process.", "x": -102.76142842584942, "y": -651.9509865226672}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero", "label": "is_world_process_zero()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Whether or not this process is the global main process (when training in a distributed fashion on several\nmachines, this is only going to be `True` for one process).", "x": -96.28517876209747, "y": -652.9388672385425}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "label": "save_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::save_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Will save the model, so you can reload it using `from_pretrained()`.\nWill only save from the main process.", "x": -18.013531106845804, "y": -659.7541304888229}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_tpu", "label": "_save_tpu()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_save_tpu\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -259.7407077035386, "y": -606.7411019221171}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_save", "label": "_save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -271.7338123340878, "y": -601.4654896454016}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos", "label": "store_flos()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::store_flos\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -11.464003286811838, "y": -659.9004293290313}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints", "label": "_sorted_checkpoints()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -247.64524123761086, "y": -611.7776021499689}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints", "label": "_rotate_checkpoints()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -277.6905003370118, "y": -598.7386625419975}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "label": "evaluate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::evaluate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Run evaluation and returns metrics.\nThe calling script will be responsible for providing a method to compute metrics, as they are task-dependent\n(pass it to the init `compute_metrics` argument).\nYou can also subclass and override this method to inject custom behavior.\nArgs:\n    eval_dataset (`Datase\u2026", "x": -166.86233163834115, "y": -638.5585034123469}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::predict", "label": "predict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::predict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Run prediction and returns predictions and potential metrics.\nDepending on the dataset and your use case, your test dataset may contain labels. In that case, this method\nwill also return metrics, like in `evaluate()`.\nArgs:\n    test_dataset (`Dataset`):\n        Dataset to run the predictions on. If \u2026", "x": -50.72164985994501, "y": -658.0481093624426}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop", "label": "evaluation_loop()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\nWorks both with or without labels.", "x": -160.515856369252, "y": -640.1833017613359}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather", "label": "_nested_gather()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Gather value of `tensors` (tensor or list/tuple of nested tensors) and convert them to numpy before\nconcatenating them to `gathered`", "x": -324.3103408112771, "y": -574.8241494951942}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_pad_across_processes", "label": "_pad_across_processes()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_pad_across_processes\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\nthey can safely be gathered.", "x": -312.83572762038324, "y": -581.148696569325}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "label": "prediction_step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::prediction_step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform an evaluation step on `model` using `inputs`.\nSubclass and override to inject custom behavior.\nArgs:\n    model (`nn.Module`):\n        The model to evaluate.\n    inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n        The inputs and targets of the model.\n        The dictionary will be unpacke\u2026", "x": -37.64888556670326, "y": -658.9253079185723}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::floating_point_ops", "label": "floating_point_ops()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::floating_point_ops\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: For models that inherit from [`PreTrainedModel`], uses that method to compute the number of floating point\noperations for every backward + forward pass. If using another model, either implement such a method in the\nmodel or subclass and override this method.\nArgs:\n    inputs (`Dict[str, Union[torch.\u2026", "x": -154.153566191391, "y": -641.7450257154132}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo", "label": "init_git_repo()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a git repo in `self.args.hub_model_id`.\nArgs:\n    at_init (`bool`, *optional*, defaults to `False`):\n        Whether this function is called before any training or not. If `self.args.overwrite_output_dir` is\n        `True` and `at_init` is `True`, the path to the repo (which is `self.arg\u2026", "x": -115.68291680441918, "y": -649.7826273144134}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card", "label": "create_model_card()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_model_card\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Creates a draft of a model card using the information available to the `Trainer`.\nArgs:\n    language (`str`, *optional*):\n        The language of the model (if applicable)\n    license (`str`, *optional*):\n        The license of the model. Will default to the license of the pretrained model used, if \u2026", "x": -192.07760249623394, "y": -631.4318606305029}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "label": "_push_from_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -295.3940727268024, "y": -590.2053386727983}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "label": "push_to_hub()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Upload *self.model* and *self.tokenizer* to the \ud83e\udd17 model hub on the repo *self.args.hub_model_id*.\nParameters:\n    commit_message (`str`, *optional*, defaults to `\"End of training\"`):\n        Message to commit while pushing.\n    blocking (`bool`, *optional*, defaults to `True`):\n        Whether the f\u2026", "x": -31.106617248374075, "y": -659.2665457638232}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "label": "prediction_loop()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\nWorks both with or without labels.", "x": -44.18744450887398, "y": -658.5191491124425}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_gather_and_numpify", "label": "_gather_and_numpify()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_gather_and_numpify\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Gather value of `tensors` (tensor or list/tuple of nested tensors) and convert them to numpy before\nconcatenating them to `gathered`", "x": -400.80733399736533, "y": -524.3600680962695}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore", "label": "_add_sm_patterns_to_gitignore()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add SageMaker Checkpointing patterns to .gitignore file.", "x": -405.9923243093974, "y": -520.3558711130806}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::patched_optimizer_step", "label": "patched_optimizer_step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::patched_optimizer_step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -63.7744251371446, "y": -656.911579056441}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::auto_wrapper_callable", "label": "auto_wrapper_callable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::auto_wrapper_callable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -223.1663281860899, "y": -621.1254220879534}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::opt_load_hook", "label": "opt_load_hook()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::opt_load_hook\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": -70.29170903175645, "y": -656.2462004776827}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "label": "main()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/memory_safe_dpov2_align.py\u003cbr\u003eKind: Function", "x": -460.2776713406169, "y": -473.0163477780224}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "label": "main()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/memory_safe_vllm_inference.py\u003cbr\u003eKind: Function", "x": -455.55989321716686, "y": -477.561706685077}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "label": "CustomMultiModalDataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Dataset for Multi Modal data", "x": 506.9902367226435, "y": 422.56466945062726}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava", "label": "preprocess_multimodal_llava()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 462.6195833677516, "y": 470.7261635862701}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token", "label": "tokenizer_image_token()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 453.1841433269572, "y": 479.81676944122313}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "label": "preprocess_llama_from_llava_plain()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function just add the image in the front of text.\nAnd don\u0027t add any prompt.\nArgs:\n    sources: The input data with text and image.\n    tokenizer: The tokenizer to process text.\n    has_image: Whether the input data has image.\nReturns:\n    The input_ids and labels for the model.", "x": 471.87270855287994, "y": 461.45004813410605}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "label": "preprocess_llama_from_llava_v1()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function add the prompt and then put the image after the prompt.\nSo it needs additional code to generate the target label.\nArgs:\n    sources: The input data with text and image.\n    tokenizer: The tokenizer to process text.\n    has_image: Whether the input data has image.\nReturns:\n    The input\u2026", "x": 467.2691649298498, "y": 466.1110677786582}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::DataCollatorForSupervisedDataset", "label": "DataCollatorForSupervisedDataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::DataCollatorForSupervisedDataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Collate examples for supervised fine-tuning.", "x": 502.77093472135704, "y": 427.57617707189087}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 489.8175012973786, "y": 442.3559826913077}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__len__", "label": "__len__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__len__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 485.4025990693462, "y": 447.19606082424684}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer", "label": "register_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 457.9244219690426, "y": 475.2948808522118}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "label": "__getitem__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__getitem__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 494.18414399969936, "y": 437.47232120362133}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::insert_separator", "label": "insert_separator()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::insert_separator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 476.4297606702969, "y": 456.7435638820143}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__call__", "label": "__call__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 498.50209695055037, "y": 432.5455575264923}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::expand2square", "label": "expand2square()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::expand2square\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 480.9398722961552, "y": 451.9920787312074}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::Dataset", "label": "Dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::Dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the Dataset object with the given parameters.\n\nParameters\n------------\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nbackend : str,  default=\"huggingface\"\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nargs : Op\u2026", "x": 583.4614868888706, "y": 308.5007185039093}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function", "x": 580.3706028084569, "y": 314.2768896940219}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::__len__", "label": "__len__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::__len__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function", "x": 577.2225374106048, "y": 320.0220965890682}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::_check_instance_format", "label": "_check_instance_format()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::_check_instance_format\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Checks if data (instances) have required fields. \nRaises messages with hints if not matched.", "x": 570.7561089250106, "y": 331.4173564024392}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::_check_hf_json_format", "label": "_check_hf_json_format()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::_check_hf_json_format\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function", "x": 574.0176008601056, "y": 325.7357731395317}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::from_dict", "label": "from_dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::from_dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Create a Dataset object from a dictionary.\n\nReturn a Dataset given a dict with format:\n    {\n        \"type\": TYPE,\n        \"instances\": [\n            {\n                \"key_1\": VALUE_1.1,\n                \"key_2\": VALUE_1.2,\n                ...\n            },\n            {\n                \"key_1\": VA\u2026", "x": 560.6355418843889, "y": 348.2639647968157}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::create_from_dict", "label": "create_from_dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::create_from_dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n--------\n\nReturns a Dataset object given a dict.", "x": 567.4383829455198, "y": 337.0662865968259}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::to_dict", "label": "to_dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::to_dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nReturn a dict represents the dataset:\n    {\n        \"type\": TYPE,\n        \"instances\": [\n            {\n                \"key_1\": VALUE_1.1,\n                \"key_2\": VALUE_1.2,\n                ...\n            },\n            {\n                \"key_1\": VALUE_2.1,\n                \"key_\u2026", "x": 519.3467956679491, "y": 407.28234166169483}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::to_list", "label": "to_list()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::to_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns a list of instances.", "x": 515.2785755023979, "y": 412.41725185571426}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::map", "label": "map()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::map\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Parameters\n------------\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n---------\n\nself : Dataset object.", "x": 535.1040548011024, "y": 386.34654202596244}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_backend", "label": "get_backend()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_backend\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.backend", "x": 557.1510970562252, "y": 353.81160954531254}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_backend_dataset", "label": "get_backend_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_backend_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.backend_dataset", "x": 553.6117586245819, "y": 359.32439481977525}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_fingerprint", "label": "get_fingerprint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_fingerprint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nFingerprint of the backend_dataset which controls the cache", "x": 546.369801185606, "y": 370.2432178344411}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_data_args", "label": "get_data_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_data_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.data_args", "x": 550.0178753046303, "y": 364.80177747014903}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_type", "label": "get_type()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_type\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.type", "x": 542.6678956959211, "y": 375.6481797918911}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::save", "label": "save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save the dataset to a json file.\n\nParameters\n------------\nfile_path : str.\n    The path to the file where the dataset will be saved.", "x": 523.3638469186036, "y": 402.10730376177014}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::sample", "label": "sample()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::sample\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Sample n instances from the dataset.\n\nParameters\n------------\nn : int.\n    The number of instances to sample from the dataset.\n\nReturns\n---------\n\nsample_dataset : Dataset object.\n    A new dataset object containing the sampled instances.", "x": 531.2428646273523, "y": 391.63888824084444}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::train_test_split", "label": "train_test_split()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::train_test_split\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Split the dataset into training and testing sets.\n\nParameters\n------------\ntest_size : float, default=0.2.\n    The proportion of the dataset that will be used for testing.\n\nReturns\n---------\n\ntrain_dataset : Dataset object.\n    A new dataset object containing the training instances.\n\ntest_dataset : \u2026", "x": 511.15958724547136, "y": 417.5115284241135}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::drop_instances", "label": "drop_instances()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::drop_instances\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Drop instances from the dataset.\n\nParameters\n------------\nindices : list.\n    A list of indices of the instances to drop from the dataset.", "x": 564.0647498023221, "y": 342.6820071588874}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::sanity_check", "label": "sanity_check()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::sanity_check\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform a sanity check on the dataset.", "x": 527.3293334722841, "y": 396.89264802925817}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::hf_dataset_sanity_check", "label": "hf_dataset_sanity_check()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::hf_dataset_sanity_check\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform a sanity check on the HuggingFace dataset.", "x": 538.9125235677517, "y": 381.016130815793}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.lamb::Lamb", "label": "Lamb()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lamb::Lamb\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lamb\u003cbr\u003eFile: v2/src/lmflow/optim/lamb.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements Lamb algorithm.\n\nIt has been proposed in `Large Batch Optimization for Deep Learning:\nTraining BERT in 76 minutes`\nhttps://arxiv.org/abs/1904.00962\n\nNote:\n    Reference code: https://github.com/cybertronai/pytorch-lamb", "x": -395.5828539329477, "y": 528.3126022292712}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.lamb::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lamb::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lamb\u003cbr\u003eFile: v2/src/lmflow/optim/lamb.py\u003cbr\u003eKind: Function", "x": -400.80733399736545, "y": 524.3600680962694}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.lamb::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lamb::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lamb\u003cbr\u003eFile: v2/src/lmflow/optim/lamb.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": -405.99232430939736, "y": 520.3558711130809}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::Adan", "label": "Adan()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::Adan\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements a pytorch variant of Adan.\n\nAdan was proposed in\nAdan : Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models.\nhttps://arxiv.org/abs/2208.06677", "x": -341.28122073597956, "y": 564.9133813010271}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::_single_tensor_adan", "label": "_single_tensor_adan()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::_single_tensor_adan\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": -363.4357803764405, "y": 550.9214404451579}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::_multi_tensor_adan", "label": "_multi_tensor_adan()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::_multi_tensor_adan\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": -357.94949633956884, "y": 554.501720529566}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": -346.8716707950582, "y": 561.4980356153036}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": -352.4279451412007, "y": 558.0273680417035}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::restart_opt", "label": "restart_opt()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::restart_opt\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": -368.88625671280903, "y": 547.2868805374486}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.", "x": -374.3003883376406, "y": 543.5983989033554}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.lars::LARS", "label": "LARS()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::LARS\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Extends SGD in PyTorch with LARS scaling from the paper\n`Large batch training of Convolutional Networks`__.\n.. note::\n    The application of momentum in the SGD part is modified according to\n    the PyTorch standards. LARS scaling fits into the equation in the\n    following fashion.\n\n    .. math::\n \u2026", "x": -411.1373140151588, "y": 516.300405795309}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.lars::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Function", "x": -416.24179620184594, "y": 512.1940717097973}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.lars::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Function", "x": -421.30526794767934, "y": 508.037273435261}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.lars::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": -426.3272303714545, "y": 503.8304205224261}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::Adamax", "label": "Adamax()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::Adamax\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Class", "x": -247.64524123761032, "y": 611.7776021499691}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Function", "x": -253.7054727028249, "y": 609.2893673129674}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Function", "x": -259.7407077035383, "y": 606.7411019221172}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Function", "x": -265.75035161506315, "y": 604.1330570465999}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree", "label": "SGDScheduleFree()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Schedule-Free SGD\nAs the name suggests, no scheduler is needed with this optimizer. \nTo add warmup, rather than using a learning rate schedule you can just\nset the warmup_steps parameter.\n\nThis optimizer requires that .train() and .eval() be called before the\nbeginning of training and evaluation res\u2026", "x": -504.8868037898688, "y": 425.07565839371534}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function", "x": -509.081181708904, "y": 420.04327209213324}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::eval", "label": "eval()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::eval\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function", "x": -513.2254021380313, "y": 414.9695008072954}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::train", "label": "train()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function", "x": -521.3617422626364, "y": 404.6998068999642}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": -517.3190567657639, "y": 409.8548444351736}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::AdamP", "label": "AdamP()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::AdamP\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements AdamP algorithm.\n\nIt has been proposed in `Slowing Down the Weight Norm Increase in\nMomentum-based Optimizers`\nhttps://arxiv.org/abs/2006.08217\n\nNote:\n    Reference code: https://github.com/clovaai/AdamP", "x": -271.7338123340874, "y": 601.4654896454018}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": -277.6905003370117, "y": 598.7386625419975}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_channel_view", "label": "_channel_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_channel_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": -283.61982873803237, "y": 595.952844398455}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_layer_view", "label": "_layer_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_layer_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": -295.394072726802, "y": 590.2053386727986}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_cosine_similarity", "label": "_cosine_similarity()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_cosine_similarity\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": -289.521213346965, "y": 593.1083096889649}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_projection", "label": "_projection()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_projection\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": -301.23782825099875, "y": 587.2442173666948}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": -307.0519041604832, "y": 584.2252375166803}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::AdaBelief", "label": "AdaBelief()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::AdaBelief\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements AdaBelief algorithm. Modified from Adam in PyTorch\nreference: AdaBelief Optimizer, adapting stepsizes by the belief in observed gradients, NeurIPS 2020", "x": -134.97808210503325, "y": 646.0502436740094}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function", "x": -141.38404999764833, "y": 644.67864118975}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function", "x": -147.77608795272948, "y": 643.2435214049086}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::reset", "label": "reset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::reset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function", "x": -154.1535661913913, "y": 641.7450257154131}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": -160.51585636925196, "y": 640.1833017613359}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adagrad::AdaGrad", "label": "AdaGrad()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adagrad::AdaGrad\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adagrad\u003cbr\u003eFile: v2/src/lmflow/optim/adagrad.py\u003cbr\u003eKind: Class", "x": -210.79252855376157, "y": 625.433057893418}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adagrad::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adagrad::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adagrad\u003cbr\u003eFile: v2/src/lmflow/optim/adagrad.py\u003cbr\u003eKind: Function", "x": -216.990117902401, "y": 623.3099459600353}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adagrad::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adagrad::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adagrad\u003cbr\u003eFile: v2/src/lmflow/optim/adagrad.py\u003cbr\u003eKind: Function", "x": -223.1663281860899, "y": 621.1254220879534}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.novograd::NovoGrad", "label": "NovoGrad()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::NovoGrad\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Class", "x": -469.5767199384937, "y": 463.7862698396811}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.novograd::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Function", "x": -474.15707421929, "y": 459.10246020665454}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.novograd::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Function", "x": -478.69071192614996, "y": 454.37341726341754}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.optim.novograd::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Function", "x": -483.1771863800456, "y": 449.59960694140153}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.yogi::Yogi", "label": "Yogi()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.yogi::Yogi\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.yogi\u003cbr\u003eFile: v2/src/lmflow/optim/yogi.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements Yogi Optimizer Algorithm.\nIt has been proposed in `Adaptive methods for Nonconvex Optimization`.\n\nhttps://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization  # noqa\n\nNote:\n    Reference code: https://github.com/4rtemi5/Yogi-Optimizer_Keras", "x": -569.104254890252, "y": 334.2459379944819}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.yogi::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.yogi::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.yogi\u003cbr\u003eFile: v2/src/lmflow/optim/yogi.py\u003cbr\u003eKind: Function", "x": -572.393904362099, "y": 328.5806114929978}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.yogi::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.yogi::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.yogi\u003cbr\u003eFile: v2/src/lmflow/optim/yogi.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": -575.6271584248974, "y": 322.8829114147698}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.radam::RAdam", "label": "RAdam()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::RAdam\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements RAdam optimization algorithm.\n\nNote:\n    Deprecated, please use version provided by PyTorch_.\n\nIt has been proposed in `On the Variance of the Adaptive Learning\nRate and Beyond`.\nhttps://arxiv.org/abs/1908.03265\n\nNote:\n    Reference code: https://github.com/LiyuanLucasLiu/RAdam", "x": -487.61605554873245, "y": 444.7814995827676}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.radam::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Function", "x": -492.0068820903022, "y": 439.9195698940654}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.radam::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Function", "x": -496.34923339627187, "y": 435.014296899462}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.radam::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": -500.6426816342057, "y": 430.0661638935471}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adam::Adam", "label": "Adam()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adam::Adam\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adam\u003cbr\u003eFile: v2/src/lmflow/optim/adam.py\u003cbr\u003eKind: Class", "x": -229.32055089047734, "y": 618.8797015085306}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adam::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adam::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adam\u003cbr\u003eFile: v2/src/lmflow/optim/adam.py\u003cbr\u003eKind: Function", "x": -235.45217966754984, "y": 616.5730054825623}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adam::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adam::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adam\u003cbr\u003eFile: v2/src/lmflow/optim/adam.py\u003cbr\u003eKind: Function", "x": -241.56061039537246, "y": 614.205561278482}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree", "label": "AdamWScheduleFree()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Schedule-Free AdamW\nAs the name suggests, no scheduler is needed with this optimizer. \nTo add warmup, rather than using a learning rate schedule you can just\nset the warmup_steps parameter.\n\nThis optimizer requires that .train() and .eval() be called before the\nbeginning of training and evaluation r\u2026", "x": -312.83572762038335, "y": 581.148696569325}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function", "x": -318.58872877646473, "y": 578.0148976424364}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::eval", "label": "eval()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::eval\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function", "x": -324.31034081127723, "y": 574.8241494951941}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::train", "label": "train()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function", "x": -335.65714576598333, "y": 568.2730686001522}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": -330.00000000000017, "y": 571.5767664977295}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sophia::SophiaG", "label": "SophiaG()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::SophiaG\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training.\nCode from: https://github.com/Liuhong99/Sophia/", "x": -551.8216130706157, "y": 362.06754528422414}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sophia::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": -555.3882678725001, "y": 356.5723936448026}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sophia::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": -558.9002027545728, "y": 351.04211052364843}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sophia::update_hessian", "label": "update_hessian()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::update_hessian\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": -565.7585341237929, "y": 339.8783327399632}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sophia::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": -562.3570717016111, "y": 345.4772407948012}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adabound::AdaBound", "label": "AdaBound()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::AdaBound\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements AdaBound algorithm.\n\nIt has been proposed in `Adaptive Gradient Methods with Dynamic Bound of\nLearning Rate\nhttps://arxiv.org/abs/1902.09843\nNote:\n    Reference code: https://github.com/Luolc/AdaBound", "x": -166.8623316383414, "y": 638.5585034123469}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adabound::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Function", "x": -173.1923667088616, "y": 636.8707907525538}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adabound::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Function", "x": -179.50533791079366, "y": 635.1203300647302}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adabound::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": -185.80062325534593, "y": 633.3072938139312}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.nadam::NAdam", "label": "NAdam()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::NAdam\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Class", "x": -450.7972308167738, "y": 482.0600135749992}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.nadam::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Function", "x": -455.559893217167, "y": 477.5617066850769}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.nadam::__setstate__", "label": "__setstate__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Function", "x": -460.27767134061685, "y": 473.01634777802246}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.nadam::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Function", "x": -464.9501003655643, "y": 468.4243846877015}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.optim.muon::zeropower_via_newtonschulz5", "label": "zeropower_via_newtonschulz5()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::zeropower_via_newtonschulz5\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a\nquintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose\nof minimizing steps, it turns out to be empirically effective to keep increasing the slope at\nzero even beyon\u2026", "x": -445.99015338324324, "y": 486.51082524974834}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.optim.muon::Muon", "label": "Muon()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::Muon\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Adam optimizer with orthogonalization step.", "x": -431.3071886816957, "y": 499.5739274536774}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.optim.muon::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Function", "x": -436.2446522254028, "y": 495.2682136022232}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.optim.muon::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArgs:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": -441.1391345363959, "y": 490.91370319077424}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::SGDP", "label": "SGDP()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::SGDP\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements SGDP algorithm.\n\nIt has been proposed in `Slowing Down the Weight Norm Increase in\nMomentum-based Optimizers`.\nhttps://arxiv.org/abs/2006.08217\n\nNote:\n    Reference code: https://github.com/clovaai/AdamP", "x": -525.3530603209443, "y": 399.50489610443844}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": -529.2926176939866, "y": 394.2706238799023}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_channel_view", "label": "_channel_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_channel_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": -533.1800262348107, "y": 388.99750593576636}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_layer_view", "label": "_layer_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_layer_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": -540.7968699596867, "y": 378.3368148116249}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_cosine_similarity", "label": "_cosine_similarity()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_cosine_similarity\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": -537.0149029344554, "y": 383.68606180873627}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_projection", "label": "_projection()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_projection\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": -544.5255546902234, "y": 372.9502919817927}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": -548.200589755451, "y": 367.52702402922114}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.dummy::Dummy", "label": "Dummy()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.dummy::Dummy\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.dummy\u003cbr\u003eFile: v2/src/lmflow/optim/dummy.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: An dummy optimizer that does nothing.\n\nParameters:\n    params (:obj:`Iterable[nn.parameter.Parameter]`):\n        Iterable of parameters to optimize or dictionaries defining parameter groups.\n    lr (:obj:`float`, `optional`, defaults to 0):\n        The learning rate to use.", "x": -379.67764182078236, "y": 539.8563589524622}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.dummy::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.dummy::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.dummy\u003cbr\u003eFile: v2/src/lmflow/optim/dummy.py\u003cbr\u003eKind: Function", "x": -385.0174873655205, "y": 536.0611293712138}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.dummy::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.dummy::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.dummy\u003cbr\u003eFile: v2/src/lmflow/optim/dummy.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure (:obj:`Callable`, `optional`): A closure that reevaluates the model and returns the loss.", "x": -390.31939886077737, "y": 532.2130840865916}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.adadelta::Adadelta", "label": "Adadelta()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adadelta::Adadelta\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adadelta\u003cbr\u003eFile: v2/src/lmflow/optim/adadelta.py\u003cbr\u003eKind: Class", "x": -192.0776024962338, "y": 631.4318606305029}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.adadelta::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adadelta::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adadelta\u003cbr\u003eFile: v2/src/lmflow/optim/adadelta.py\u003cbr\u003eKind: Function", "x": -198.33565719079212, "y": 629.4942152924812}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.adadelta::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adadelta::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adadelta\u003cbr\u003eFile: v2/src/lmflow/optim/adadelta.py\u003cbr\u003eKind: Function", "x": -204.57417076090644, "y": 627.4945487073873}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::SeparatorStyle", "label": "SeparatorStyle()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::SeparatorStyle\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Different separator style.", "x": 634.672930588542, "y": -181.08084155468143}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "label": "Conversation()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::Conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A class that keeps all conversation history.", "x": 632.8442781175412, "y": -187.3716084519959}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt", "label": "get_prompt()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::get_prompt\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 644.3258105740354, "y": -142.98339004273282}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::append_message", "label": "append_message()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::append_message\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 636.4390515768353, "y": -174.77223357266604}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::get_images", "label": "get_images()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::get_images\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 642.8748333130075, "y": -149.371847055504}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::to_gradio_chatbot", "label": "to_gradio_chatbot()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::to_gradio_chatbot\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 645.7133052973022, "y": -136.5808455166132}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::copy", "label": "copy()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::copy\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 638.142467074426, "y": -168.4464060648523}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::dict", "label": "dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 639.7830092514107, "y": -162.10398228670792}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::expand2square", "label": "expand2square()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::expand2square\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 641.3605164725128, "y": -155.7455871288543}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.multimodal::update_custom_config", "label": "update_custom_config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.multimodal::update_custom_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.multimodal\u003cbr\u003eFile: v2/src/lmflow/utils/multimodal.py\u003cbr\u003eKind: Function", "x": 650.6258188381568, "y": -110.84242807326991}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.multimodal::load_llava_pretrain_model", "label": "load_llava_pretrain_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.multimodal::load_llava_pretrain_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.multimodal\u003cbr\u003eFile: v2/src/lmflow/utils/multimodal.py\u003cbr\u003eKind: Function", "x": 649.4935585575447, "y": -117.29500156552814}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.multimodal::adapt_llava_model_to_lmflow_type", "label": "adapt_llava_model_to_lmflow_type()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.multimodal::adapt_llava_model_to_lmflow_type\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.multimodal\u003cbr\u003eFile: v2/src/lmflow/utils/multimodal.py\u003cbr\u003eKind: Function", "x": 648.2973065840966, "y": -123.73601850635815}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.model::check_homogeneity", "label": "check_homogeneity()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.model::check_homogeneity\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.model\u003cbr\u003eFile: v2/src/lmflow/utils/model.py\u003cbr\u003eKind: Function", "x": 647.0371807791644, "y": -130.16484429119484}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::set_random_seed", "label": "set_random_seed()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::set_random_seed\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Set the random seed for `random`, `numpy`, `torch`, `torch.cuda`.\n\nParameters\n------------\nseed : int\n    The default seed.\n    ", "x": 523.3638469186035, "y": -402.1073037617703}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::load_data", "label": "load_data()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::load_data\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load data with file name.\n\nParameters\n------------\nfile_name : str.\n    The dataset file name.\n\nReturns\n------------\ninputs : list.\n    The input texts of the dataset.\noutputs : list.\n    The output texts file datasets.    \nlen : int.\n    The length of the dataset.", "x": 511.1595872454711, "y": -417.51152842411386}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::batchlize", "label": "batchlize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::batchlize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Convert examples to a dataloader.\n\nParameters\n------------\nexamples : list.\n    Data list.\nbatch_size : int.\n\nrandom_shuffle : bool\n    If true, the dataloader shuffle the training data.\n\nReturns\n------------\ndataloader:\n    Dataloader with batch generator.", "x": 498.5020969505503, "y": -432.54555752649236}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::preview_file", "label": "preview_file()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::preview_file\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the first and last specified number of characters from a file\nwithout loading the entire file into memory, working with any file type.\n\nArgs:\n    file_path (str): Path to the file to be previewed\n    chars (int, optional): Number of characters to show from start and end. Defaults to 100.\n\nRe\u2026", "x": 515.2785755023978, "y": -412.4172518557143}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast", "label": "get_dataset_type_fast()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::get_dataset_type_fast\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Get the type values from the first and last n lines of a large json dataset.\n    ", "x": 506.99023672264343, "y": -422.56466945062743}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast", "label": "check_dataset_instances_key_fast()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Check if the dataset instances key matches the instance_key.\n    ", "x": 502.7709347213568, "y": -427.57617707189115}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::answer_extraction", "label": "answer_extraction()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::answer_extraction\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Use this funtion to extract answers from generated text\n\nParameters\n------------\nargs : \n    Arguments.\nresponse : str\n    plain string response.\n\n\nReturns\n------------\nanswer:\n    Decoded answer (such as A, B, C, D, E for mutiple-choice QA).", "x": 494.1841439996991, "y": -437.4723212036217}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::process_image_flag", "label": "process_image_flag()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::process_image_flag\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function", "x": 519.3467956679492, "y": -407.2823416616947}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::VLLMInferenceResultWithInput", "label": "VLLMInferenceResultWithInput()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::VLLMInferenceResultWithInput\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Class", "x": 489.8175012973786, "y": -442.35598269130776}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::RewardModelInferenceResultWithInput", "label": "RewardModelInferenceResultWithInput()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::RewardModelInferenceResultWithInput\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Class", "x": 485.4025990693459, "y": -447.1960608242471}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass", "label": "make_shell_args_from_dataclass()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.common::make_shell_args_from_dataclass\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return a string or a list of strings that can be used as shell arguments.\n\nParameters\n----------\ndataclass_objects : List\n    A list of dataclass objects.\nformat : str, optional\n    Return format, can be \"shell\" or \"subprocess\", by default \"subprocess\".\nskip_default : bool, optional\n    Whether to s\u2026", "x": 268.74539178000657, "y": -602.8066973723921}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.common::create_copied_dataclass", "label": "create_copied_dataclass()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.common::create_copied_dataclass\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Create a copied dataclass with new field names and default values.\n\nParameters\n----------\noriginal_dataclass : dataclass\nfield_prefix : str\n    The prefix to add to the **field** names of the copied dataclass.\nclass_prefix : str\n    The prefix to add to the **class** name of the copied dataclass.\nne\u2026", "x": 262.74876561168594, "y": -605.4445359977537}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.common::remove_dataclass_attr_prefix", "label": "remove_dataclass_attr_prefix()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.common::remove_dataclass_attr_prefix\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Remove the prefix from the attribute names of a dataclass instance.\n\nParameters\n----------\ndata_instance : dataclass\nprefix : str\n    The prefix to remove from the attribute names of the dataclass instance.\n\nReturns\n-------\nDict", "x": 280.6586210635007, "y": -597.3531103315144}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.common::add_dataclass_attr_prefix", "label": "add_dataclass_attr_prefix()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.common::add_dataclass_attr_prefix\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add the prefix to the attribute names of a dataclass instance.\n\nParameters\n----------\ndata_instance : dataclass\nprefix : str\n    The prefix to add to the attribute names of the dataclass instance.\n\nReturns\n-------\nDict", "x": 256.7262519836968, "y": -608.0227228832845}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.common::print_banner", "label": "print_banner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.common::print_banner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function", "x": 274.7155396679271, "y": -600.1094669016309}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::get_python_version", "label": "get_python_version()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::get_python_version\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 656.7512996996079, "y": -65.40436027418797}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::_is_package_available", "label": "_is_package_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::_is_package_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 655.3235616364859, "y": -78.42849969284615}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::_is_packages_available", "label": "_is_packages_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::_is_packages_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 656.0697504758405, "y": -71.91997296000865}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_package_version_at_least", "label": "is_package_version_at_least()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_package_version_at_least\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 659.1873245905679, "y": -32.742496837129124}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_gradio_available", "label": "is_gradio_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_gradio_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 658.4074700597743, "y": -45.82142915151678}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_ray_available", "label": "is_ray_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_ray_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 659.4798493016842, "y": -26.197869474976905}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_vllm_available", "label": "is_vllm_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_vllm_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 659.8699495124444, "y": -13.101516341409624}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_flash_attn_available", "label": "is_flash_attn_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_flash_attn_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 657.3681421577941, "y": -58.88230358953578}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_flask_available", "label": "is_flask_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_flask_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 657.920217075673, "y": -52.354445495099725}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_trl_available", "label": "is_trl_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_trl_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 659.7073984154415, "y": -19.650660954021316}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_multimodal_available", "label": "is_multimodal_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_multimodal_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 658.8298531032427, "y": -39.283898227640734}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplate", "label": "Llama2ConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.llama\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/llama.py\u003cbr\u003eKind: Class", "x": 457.9244219690423, "y": -475.2948808522121}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplateForTool", "label": "Llama2ConversationTemplateForTool()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplateForTool\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.llama\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/llama.py\u003cbr\u003eKind: Class", "x": 462.61958336775115, "y": -470.72616358627056}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.llama::_encode", "label": "_encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.llama::_encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.llama\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/llama.py\u003cbr\u003eKind: Function", "x": 471.8727085528799, "y": -461.4500481341061}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.zephyr::ZephyrConversationTemplate", "label": "ZephyrConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.zephyr::ZephyrConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.zephyr\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/zephyr.py\u003cbr\u003eKind: Class", "x": 476.4297606702966, "y": -456.7435638820146}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.zephyr::_encode", "label": "_encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.zephyr::_encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.zephyr\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/zephyr.py\u003cbr\u003eKind: Function", "x": 480.93987229615516, "y": -451.9920787312074}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.gemma::GemmaConversationTemplate", "label": "GemmaConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.gemma::GemmaConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.gemma\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/gemma.py\u003cbr\u003eKind: Class", "x": 438.69729627426364, "y": -493.09703126428474}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.gemma::encode_conversation", "label": "encode_conversation()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.gemma::encode_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.gemma\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/gemma.py\u003cbr\u003eKind: Function", "x": 443.57010686558044, "y": -488.7182831604089}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::TemplateComponent", "label": "TemplateComponent()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::TemplateComponent\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The minimal unit of a template, which can be a token, a string, or a list of tools.\n\nParameters\n----------\ntype : Literal[\u0027token\u0027, \u0027token_id\u0027, \u0027string\u0027, \u0027tools\u0027]\n    - Type of the component.  \n    \n    - When the component is a token or a string, the content should be `string`. \n    The difference b\u2026", "x": 315.7161164843221, "y": -579.5889351877397}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::Formatter", "label": "Formatter()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::Formatter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 304.14861202895804, "y": -585.7419413025316}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::EmptyFormatter", "label": "EmptyFormatter()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::EmptyFormatter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 298.31962452366946, "y": -588.7320287058084}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::StringFormatter", "label": "StringFormatter()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::StringFormatter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 309.947633133039, "y": -582.6941433678796}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "label": "ConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::ConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 286.574050421523, "y": -594.537899233516}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "label": "ConversationTemplateForTool()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 292.46124492121896, "y": -591.6641109777834}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::__post_init__", "label": "__post_init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::__post_init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 338.473351809671, "y": -566.6002030662597}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::__repr__", "label": "__repr__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::__repr__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 344.08068338279367, "y": -563.21264485346}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::__str__", "label": "__str__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::__str__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 349.65411422647566, "y": -559.7695958200112}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::format", "label": "format()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::format\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 418.77868965522384, "y": -510.1219551152977}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::has_placeholder", "label": "has_placeholder()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::has_placeholder\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 423.8214688457179, "y": -505.94007801859124}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::encode_conversation", "label": "encode_conversation()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::encode_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Messages here should be guaranteed to be in pairs, with the first message being the user message and the second message being the system message.\nData example: \n```json\n{\n    \"conversation_id\": 2,\n    \"system\": \"sysinfo1\",\n    \"tools\": [\"tool_1_desc\"],\n    \"messages\": [\n        {\n            \"role\":\u2026", "x": 403.4047973925786, "y": -522.3644029225696}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_encode", "label": "_encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 360.6970806189439, "y": -552.7183876378378}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_encode_template", "label": "_encode_template()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_encode_template\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Encode template components into token ids.\n\nParameters\n----------\ntemplate : List[TemplateComponent]\n    Formatted template components.\ntokenizer : PreTrainedTokenizer\n    Tokenizer to convert tokens into token ids.\n\nReturns\n-------\nList[int]\n    Encoded token ids.", "x": 371.5978990380962, "y": -545.4493573471995}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "label": "post_process_pairs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::post_process_pairs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 428.82249080414385, "y": -501.7083529108619}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator", "label": "remove_last_separator()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::remove_last_separator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 433.78126280219453, "y": -497.4271967250418}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::add_special_starter", "label": "add_special_starter()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::add_special_starter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 387.6732176058862, "y": -534.1436851176836}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper", "label": "add_special_stopper()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::add_special_stopper\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 392.9559659506939, "y": -530.2693738315999}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list", "label": "_ensure_id_list()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_ensure_id_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Make sure the object is a list of integers. Useful for handling token ids.\n        ", "x": 376.99365804498933, "y": -541.7340507978594}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_handle_tools", "label": "_handle_tools()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_handle_tools\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 382.35227355438565, "y": -537.9653696175918}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.hymba::HymbaConversationTemplate", "label": "HymbaConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.hymba::HymbaConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.hymba\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/hymba.py\u003cbr\u003eKind: Class", "x": 448.3992144799298, "y": -484.29138383186404}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.hymba::_handle_tools", "label": "_handle_tools()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.hymba::_handle_tools\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.hymba\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/hymba.py\u003cbr\u003eKind: Function", "x": 453.1841433269572, "y": -479.81676944122324}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::CondenseRotaryEmbedding", "label": "CondenseRotaryEmbedding()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::CondenseRotaryEmbedding\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Class", "x": 651.6939758693958, "y": -104.37893377276558}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::replace_llama_with_condense", "label": "replace_llama_with_condense()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::replace_llama_with_condense\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Function", "x": 654.5128067001903, "y": -84.92929921669837}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Function", "x": 652.6979244105313, "y": -97.90515548317325}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Function", "x": 653.6375655470077, "y": -91.42173103688819}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt2_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt2_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt2_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt2_flash_attention.py\u003cbr\u003eKind: Function", "x": 567.4383829455196, "y": -337.06628659682616}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt2_flash_attention::_prepare_decoder_attention_mask", "label": "_prepare_decoder_attention_mask()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt2_flash_attention::_prepare_decoder_attention_mask\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt2_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt2_flash_attention.py\u003cbr\u003eKind: Function", "x": 564.0647498023221, "y": -342.68200715888736}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt2_flash_attention::replace_gpt2_attn_with_flash_attn", "label": "replace_gpt2_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt2_flash_attention::replace_gpt2_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt2_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt2_flash_attention.py\u003cbr\u003eKind: Function", "x": 570.7561089250106, "y": -331.4173564024393}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::_attn", "label": "_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt_neo_flash_attention.py\u003cbr\u003eKind: Function", "x": 574.0176008601055, "y": -325.73577313953194}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt_neo_flash_attention.py\u003cbr\u003eKind: Function", "x": 577.2225374106048, "y": -320.0220965890682}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::replace_gpt_neo_attn_with_flash_attn", "label": "replace_gpt_neo_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::replace_gpt_neo_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt_neo_flash_attention.py\u003cbr\u003eKind: Function", "x": 580.3706028084567, "y": -314.27688969402215}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.bloom_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.bloom_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.bloom_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/bloom_flash_attention.py\u003cbr\u003eKind: Function", "x": 557.1510970562252, "y": -353.8116095453125}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.bloom_flash_attention::_prepare_attn_mask", "label": "_prepare_attn_mask()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.bloom_flash_attention::_prepare_attn_mask\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.bloom_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/bloom_flash_attention.py\u003cbr\u003eKind: Function", "x": 553.6117586245817, "y": -359.3243948197755}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.bloom_flash_attention::replace_bloom_attn_with_flash_attn", "label": "replace_bloom_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.bloom_flash_attention::replace_bloom_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.bloom_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/bloom_flash_attention.py\u003cbr\u003eKind: Function", "x": 560.6355418843891, "y": -348.26396479681534}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_fwd_kernel", "label": "_fwd_kernel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_fwd_kernel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 615.9868305638805, "y": -236.98148571537212}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_preprocess_do_o_dot", "label": "_bwd_preprocess_do_o_dot()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_preprocess_do_o_dot\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 606.0946850929282, "y": -261.24554101860605}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv", "label": "_bwd_store_dk_dv()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 608.6579191231787, "y": -255.21664814161747}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block", "label": "_bwd_kernel_one_col_block()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 603.4717352665668, "y": -267.2486945419166}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero", "label": "init_to_zero()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 630.953274332775, "y": -193.64391446350692}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "label": "_bwd_kernel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 600.7893280715996, "y": -273.22551724770483}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward", "label": "_flash_attn_forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 613.6042355278613, "y": -243.08402280336932}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward", "label": "_flash_attn_backward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 611.1611848133439, "y": -249.16260991077627}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc", "label": "FlashAttnQKVPackedFunc()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Class", "x": 598.047727793599, "y": -279.1754202663861}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc", "label": "FlashAttnKVPackedFunc()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Class", "x": 595.247204550168, "y": -285.0978173806499}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc", "label": "FlashAttnFunc()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Class", "x": 592.3880342643247, "y": -290.9921250832216}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: qkv: (batch, seqlen, 3, nheads, headdim)\nbias: optional, shape broadcastible to (batch, nheads, seqlen, seqlen).\n    For example, ALiBi mask for causal would have shape (1, nheads, 1, seqlen).\n    ALiBi mask for non-causal would have shape (1, nheads, seqlen, seqlen)", "x": 629.0001055463806, "y": -199.89714160698253}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::backward", "label": "backward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::backward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 622.7695640570365, "y": -218.53619856721366}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.llama_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.llama_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.llama_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/llama_flash_attention.py\u003cbr\u003eKind: Function", "x": 586.4948851208738, "y": -302.6941521190209}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.llama_flash_attention::_prepare_decoder_attention_mask", "label": "_prepare_decoder_attention_mask()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.llama_flash_attention::_prepare_decoder_attention_mask\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.llama_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/llama_flash_attention.py\u003cbr\u003eKind: Function", "x": 583.4614868888704, "y": -308.50071850390987}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.llama_flash_attention::replace_llama_attn_with_flash_attn", "label": "replace_llama_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.llama_flash_attention::replace_llama_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.llama_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/llama_flash_attention.py\u003cbr\u003eKind: Function", "x": 589.4704986373183, "y": -296.8577626343488}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::Timer", "label": "Timer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::Timer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Class", "x": 527.3293334722841, "y": -396.89264802925805}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 531.2428646273522, "y": -391.6388882408446}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::start", "label": "start()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::start\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 550.0178753046304, "y": -364.80177747014903}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::end", "label": "end()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::end\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 538.9125235677515, "y": -381.01613081579325}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::get_runtime", "label": "get_runtime()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::get_runtime\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 542.6678956959212, "y": -375.6481797918911}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::show", "label": "show()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::show\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 546.3698011856059, "y": -370.2432178344412}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::_to_readable", "label": "_to_readable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::_to_readable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 535.1040548011025, "y": -386.3465420259623}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "label": "HFEncoderDecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a HFEncoderDecoderModel instance.\n\nParameters\n------------\n\nmodel_args :\n    Model arguments such as model name, path, revision, etc.\n\ntune_strategy : str or none,  default=\"normal\".\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nds_config :\n    Deepspeed conf\u2026", "x": 327.15919962187445, "y": 573.2075174862717}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFDecoderModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.\n:param tune_strategy: tuning strategy: normal, none, lora or adapter\n:param ds_config: deepspeed configuration for distributed training", "x": 321.4534937399667, "y": 576.4266227043727}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::tokenize", "label": "tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize the full dataset.\n\nParameters\n------------\ndataset :\n    Text dataset.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\ntokenized_datasets :\n    The tokenized dataset.", "x": 268.74539178000686, "y": 602.806697372392}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::encode", "label": "encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform encoding process of the tokenizer.\n\nParameters\n------------\ninputs : str or list.\n    The text sequence.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The tokenized inputs.", "x": 309.9476331330392, "y": 582.6941433678795}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::decode", "label": "decode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::decode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform decoding process of the tokenizer.\n\nParameters\n------------\ninputs : list.\n    The token sequence.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The text decoded from the token inputs.", "x": 315.71611648432247, "y": 579.5889351877395}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The sequence used as a prompt for the generation or as model inputs to the model.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The generated se\u2026", "x": 286.574050421523, "y": 594.537899233516}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::merge_lora_weights", "label": "merge_lora_weights()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::merge_lora_weights\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function", "x": 280.65862106350096, "y": 597.3531103315142}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::save", "label": "save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ndir :\n    The directory to save model and tokenizer\n\nsave_full_model : Optional.\n    Whether to save full model.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The generated sequence output", "x": 274.7155396679271, "y": 600.1094669016309}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::get_max_length", "label": "get_max_length()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::get_max_length\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return max acceptable input length in terms of tokens.", "x": 298.31962452367003, "y": 588.7320287058083}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer", "label": "get_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the tokenizer of the model.", "x": 292.46124492121925, "y": 591.6641109777833}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model", "label": "get_backend_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the backend model.", "x": 304.1486120289583, "y": 585.7419413025315}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::TextRegressionModel", "label": "TextRegressionModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::TextRegressionModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a TextRegressionModel instance.\n\nParameters\n------------\n\nmodel_args : \n    Model arguments such as model name, path, revision, etc.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    ", "x": 73.54779401278986, "y": 655.8892604669269}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a TextRegressionModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.", "x": 67.0338926582045, "y": 656.5869761387963}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::register_inference_function", "label": "register_inference_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::register_inference_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Registers a regression function.", "x": 53.98691873720143, "y": 657.7882733868572}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Gets regression results of a given dataset.\n\n:inputs: Dataset object, only accept type \"text_only\".", "x": 60.51338675425589, "y": 657.2200012351494}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.models.auto_model::AutoModel", "label": "AutoModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.auto_model::AutoModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.auto_model\u003cbr\u003eFile: v2/src/lmflow/models/auto_model.py\u003cbr\u003eKind: Class", "x": 448.39921447993, "y": 484.2913838318639}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.models.auto_model::get_model", "label": "get_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.auto_model::get_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.auto_model\u003cbr\u003eFile: v2/src/lmflow/models/auto_model.py\u003cbr\u003eKind: Function", "x": 443.57010686558044, "y": 488.7182831604089}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "label": "HFDecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::HFDecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a HFDecoderModel instance.\n\nParameters\n------------\n\nmodel_args : \n    Model arguments such as model name, path, revision, etc.\n\ntune_strategy : str or none,  default=\"normal\".\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nds_config :   \n    Deepspeed configu\u2026", "x": 408.56985101306833, "y": 518.3345221410195}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFDecoderModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.\n:param tune_strategy: tuning strategy: normal, none, lora or adapter\n:param ds_config: deepspeed configuration for distributed training", "x": 398.1999981032623, "y": 526.3428174778886}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::tokenize", "label": "tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize the full dataset.\n\nParameters\n------------\ndataset : lmflow.datasets.Dataset.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\ntokenized_datasets :\n    The tokenized dataset, without any leading or trailing special\n    tokens (\u2026", "x": 332.83267197238695, "y": 569.9319366974635}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::encode", "label": "encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform encoding process of the tokenizer.\n\nParameters\n------------\ninputs : str or list.\n    The text sequence.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    if string input,return the tokenized inputs.\n    \"Hello,\u2026", "x": 371.59789903809616, "y": 545.4493573471995}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::decode", "label": "decode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::decode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform decoding process of the tokenizer.\n\nParameters\n------------\ninputs : list or tensor.\n    The token sequence.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The text decoded from the token inputs.\n    if batch\u2026", "x": 376.9936580449895, "y": 541.7340507978593}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The sequence used as a prompt for the generation or as model inputs to the model.\n    When using vllm inference, this should be a string or a list of strings.\n    When using normal inference, this should be a tensor.\nrele\u2026", "x": 360.69708061894426, "y": 552.7183876378375}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__inference", "label": "__inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The **tokenized** sequence used as a prompt for the generation or as model inputs to the model.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs \u2026", "x": 403.40479739257853, "y": 522.3644029225696}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference", "label": "__vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform VLLM inference process of the model.\n\nParameters\n----------\ninputs : Union[str, List[str]]\n    Prompt(s), string or a list of strings.\nsampling_params : Optional[SamplingParams], optional\n    vllm SamplingParams object, by default None.\n\nReturns\n-------\nList[VLLMInferenceResultWithInput]\n   \u2026", "x": 382.35227355438553, "y": 537.9653696175919}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "label": "prepare_inputs_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare inputs for inference.\n\nParameters\n------------\ndataset : lmflow.datasets.Dataset.\n    The dataset used for inference.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The prepared inputs for inference.", "x": 349.654114226476, "y": 559.769595820011}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "label": "__prepare_inputs_for_vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 387.6732176058863, "y": 534.1436851176836}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_inference", "label": "__prepare_inputs_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 392.95596595069384, "y": 530.2693738316}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::merge_lora_weights", "label": "merge_lora_weights()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::merge_lora_weights\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 355.1930952155266, "y": 556.2713951941209}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "label": "get_peft_without_qlora()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 366.16552815368595, "y": 549.1109232130901}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::save", "label": "save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ndir :\n    The directory to save model and tokenizer\n    \nsave_full_model : Optional.\n    Whether to save full model.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The generated sequence output ", "x": 338.4733518096712, "y": 566.6002030662595}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::preprocess_conversation", "label": "preprocess_conversation()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::preprocess_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 344.08068338279384, "y": 563.2126448534599}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.encoder_decoder_model::EncoderDecoderModel", "label": "EncoderDecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.encoder_decoder_model::EncoderDecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/encoder_decoder_model.py\u003cbr\u003eKind: Class", "x": 418.77868965522356, "y": 510.12195511529785}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.encoder_decoder_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.encoder_decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/encoder_decoder_model.py\u003cbr\u003eKind: Function", "x": 413.6946500751201, "y": 514.253572179352}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.models.base_model::BaseModel", "label": "BaseModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.base_model::BaseModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.base_model\u003cbr\u003eFile: v2/src/lmflow/models/base_model.py\u003cbr\u003eKind: Class", "x": 438.69729627426386, "y": 493.0970312642845}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.models.base_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.base_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.base_model\u003cbr\u003eFile: v2/src/lmflow/models/base_model.py\u003cbr\u003eKind: Function", "x": 433.78126280219453, "y": 497.4271967250418}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "label": "HFTextRegressionModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a HFTextRegressionModel instance.\n\nParameters\n------------\n\nmodel_args : \n    Model arguments such as model name, path, revision, etc.\n\ntune_strategy : str or none,  default=\"normal\".\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nds_config :   \n    Deepspeed \u2026", "x": 157.33664900171664, "y": 640.9720578004244}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFTextRegressionModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.\n:param tune_strategy: tuning strategy: normal, none, lora or adapter\n:param ds_config: deepspeed configuration for distributed training", "x": 144.58184961145562, "y": 643.96901226917}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "label": "tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize the full dataset.\n\nParameters\n------------\ndataset : lmflow.datasets.Dataset.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\ntokenized_datasets :\n    The tokenized dataset, without any leading or trailing special\n    tokens (\u2026", "x": 99.52452931481446, "y": 652.4529623387916}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The sequence used as a prompt for the generation or as model inputs to the model.\n    When using vllm inference, this should be a string or a list of strings.\n    When using normal inference, this should be a tensor.\nrele\u2026", "x": 131.77007161503226, "y": 646.7121834530174}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::__inference", "label": "__inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::__inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The **tokenized** sequence used as a prompt for the generation or as model inputs to the model.\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The generated sequence output ", "x": 150.9666863424841, "y": 642.5021864669178}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::__vllm_inference", "label": "__vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::__vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform VLLM inference process of the model.\n\nParameters\n----------\ninputs : Union[str, List[str]]\n    Prompt(s), string or a list of strings.\nsampling_params : Optional[SamplingParams], optional\n    vllm SamplingParams object, by default None.\n\nReturns\n-------", "x": 138.1827678780127, "y": 645.372390687401}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "label": "prepare_inputs_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 112.45662012469575, "y": 650.348759197809}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "label": "postprocess_inference_outputs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 118.90636403661243, "y": 649.2004902890883}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs", "label": "postprocess_distributed_inference_outputs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 125.34439263677056, "y": 647.9882585622358}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::save", "label": "save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ndir :\n    The directory to save model and tokenizer\n\nkwargs : Optional.\n    Keyword arguments.    ", "x": 105.99579636541539, "y": 651.4329521546031}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "label": "HFModelMixin()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::HFModelMixin\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Class", "x": 262.74876561168594, "y": 605.4445359977537}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFModel instance.\n\nParameters\n----------\nmodel_args : \n    Dictionary with model arguments such as model name, path, revision, etc.\ndo_train : bool\n    To prepare the model for training or inference.\nds_config : optional\n    Deepspeed configuration for distributed training, by default \u2026", "x": 256.72625198369656, "y": 608.0227228832847}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "label": "__prepare_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 195.20903399234945, "y": 630.4708026925384}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_dtype", "label": "__prepare_dtype()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_dtype\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 244.60593832605642, "y": 612.9991312682503}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config", "label": "__prepare_model_config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare model configuration for hf auto register,\nParameters\n----------\nmodel_args : ModelArguments\n    LMFlow model arguments.\nhf_auto_model_additional_args : Optional[Dict], optional\n    Special configurations such as `num_labels` in `AutoModelForSequenceClassification` \n    (commonly used in rewa\u2026", "x": 238.50933245665314, "y": 615.3968624644439}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_quant_config", "label": "__prepare_quant_config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_quant_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 201.4573950780405, "y": 628.5021224851753}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config", "label": "__prepare_peft_config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_peft_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 207.685907468428, "y": 626.4715187772031}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject", "label": "__model_module_inject()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__model_module_inject\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Override some model modules with custom implementations.\n\nCurrent implementations:\n- Position interpolation (model_args.do_rope_scaling): \n    replace llama embeddings with condense embeddings.", "x": 250.67844426734638, "y": 610.5410040117723}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "label": "__prepare_model_for_training()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 226.24622593392206, "y": 620.0101976989223}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "label": "__prepare_model_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 232.38922733042142, "y": 617.7339613626319}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference", "label": "__prepare_model_for_vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 220.0809335095833, "y": 622.2253472059382}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process", "label": "__prepare_model_post_process()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 213.8939574960686, "y": 624.3791916349151}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference", "label": "activate_model_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::activate_model_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 188.94143983440162, "y": 632.3773654340446}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference", "label": "deactivate_model_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Deactivate the model and release the resources.\n\nNOTE: Currently, VLLM doesn\u0027t have an official way to do this, and the\nimplementation below cannot release all gpu resources by our observation.\nThus this method is just a placeholder for future implementation. See: \n[Github issue](https://github.com/\u2026", "x": 182.6552301221922, "y": 634.2216228646016}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::get_max_length", "label": "get_max_length()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::get_max_length\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return max acceptable input length in terms of tokens.", "x": 170.02944321648337, "y": 637.7225011237197}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::get_tokenizer", "label": "get_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::get_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the tokenizer of the model.", "x": 163.69110998524795, "y": 639.3787770264175}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::get_backend_model", "label": "get_backend_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::get_backend_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the backend model.", "x": 176.35102420782354, "y": 636.0033932777809}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.regression_model::RegressionModel", "label": "RegressionModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.regression_model::RegressionModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.regression_model\u003cbr\u003eFile: v2/src/lmflow/models/regression_model.py\u003cbr\u003eKind: Class", "x": 86.55321664565713, "y": 654.3000387347458}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.regression_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.regression_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.regression_model\u003cbr\u003eFile: v2/src/lmflow/models/regression_model.py\u003cbr\u003eKind: Function", "x": 80.05444903247147, "y": 655.1269229623427}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "label": "CustomAutoVision2SeqModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Class", "x": 47.45513163071878, "y": 658.2917366046084}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: TODO update the docs\nArgs:\n    config:\n    # the below varaible are used to overwrite the model in config\n    image_encoder_name_or_path:\n    qformer_name_or_path:\n    language_model_name_or_path:\nReturns:", "x": 40.91866898255169, "y": 658.730341284426}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::get_backend_model", "label": "get_backend_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::get_backend_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 21.28766979453743, "y": 659.6566039347433}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::vision_model_from_pretrained", "label": "vision_model_from_pretrained()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::vision_model_from_pretrained\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": -37.64888556670265, "y": 658.9253079185723}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::qformer_from_pretrained", "label": "qformer_from_pretrained()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::qformer_from_pretrained\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": -11.464003286811968, "y": 659.9004293290313}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained", "label": "language_model_from_pretrained()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::language_model_from_pretrained\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 8.18877547937771, "y": 659.9491980115956}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::vision_feature_select", "label": "vision_feature_select()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::vision_feature_select\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": -31.106617248373766, "y": 659.2665457638232}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::register_prompt_cache", "label": "register_prompt_cache()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::register_prompt_cache\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Udpate the prompt id and embedding for reuse in the future\n\nArgs:\n    prompt_ids (torch.LongTensor): The id of the prompt.\n    prompt_keys_values (torch.FloatTensor): The embedding of the prompt.\n\nReturns:\n    None", "x": -18.01353110684564, "y": 659.7541304888229}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::save_prompt_cache", "label": "save_prompt_cache()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::save_prompt_cache\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save prompt embedding and id.\n\nArgs:\n    path: The path to save the prompt embedding and id.\n\nReturns:\n    None", "x": -24.561284134297633, "y": 659.5428290275578}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::load_prompt_cache", "label": "load_prompt_cache()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::load_prompt_cache\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load prompt embedding and id.\nArgs:\n    path: The path to load the prompt embedding and id.\n\nReturns:\n    None", "x": 1.6377954370883572, "y": 659.997967895437}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::get_tokenizer", "label": "get_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::get_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 14.738948718276376, "y": 659.835406287568}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 34.3781748011041, "y": 659.1040442125543}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4", "label": "processor_image_token_in_minigpt4()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": -4.913345969853598, "y": 659.9817111340136}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::generate", "label": "generate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::generate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Overrides `generate` function to be able to use the model as a conditional generator.\n\nArgs:\n    pixel_values (`torch.FloatTensor` of shape (batch_size, num_channels, height, width)):\n        Input images to be processed.\n    input_ids (`torch.LongTensor` of shape (batch_size, sequence_length), *opt\u2026", "x": 27.83429349198888, "y": 659.4128085697166}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.models.decoder_model::DecoderModel", "label": "DecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.decoder_model::DecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/decoder_model.py\u003cbr\u003eKind: Class", "x": 428.8224908041436, "y": 501.7083529108621}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.models.decoder_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/decoder_model.py\u003cbr\u003eKind: Function", "x": 423.8214688457179, "y": 505.94007801859124}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.interfaces.tunable::Tunable", "label": "Tunable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.interfaces.tunable::Tunable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.interfaces.tunable\u003cbr\u003eFile: v2/src/lmflow/models/interfaces/tunable.py\u003cbr\u003eKind: Class", "x": 93.04345655786642, "y": 653.4086892533373}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower", "label": "build_vision_tower()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -57.2508578339126, "y": 657.5122350780107}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "label": "CLIPVisionTower()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Class", "x": -44.187444508873675, "y": 658.5191491124425}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -50.721649859944705, "y": 658.0481093624426}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model", "label": "load_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::load_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -115.68291680441874, "y": 649.7826273144135}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images", "label": "encode_images()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::encode_images\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -89.79944255070737, "y": 653.8624168107402}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::feature_select", "label": "feature_select()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::feature_select\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -96.28517876209732, "y": 652.9388672385425}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -102.76142842584896, "y": 651.9509865226672}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::dummy_feature", "label": "dummy_feature()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::dummy_feature\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -83.30485880223436, "y": 654.7215442460557}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::dtype", "label": "dtype()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::dtype\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -76.8020673989417, "y": 655.5161648985084}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::device", "label": "device()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::device\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -70.29170903175628, "y": 656.2462004776827}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::config", "label": "config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -63.77442513714414, "y": 656.911579056441}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::hidden_size", "label": "hidden_size()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::hidden_size\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -109.22755346607421, "y": 650.8988719945794}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::num_patches", "label": "num_patches()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::num_patches\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": -122.12688242283069, "y": 648.6023624607608}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal", "label": "prepare_inputs_labels_for_multimodal()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Copy from the LLAVA code base.\nShould be polished.", "x": -128.55881542622416, "y": 647.3581937198339}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_decoder_model::blocking", "label": "blocking()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_decoder_model::blocking\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 195.2090339923493, "y": -630.4708026925385}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_decoder_model::tokenize_function", "label": "tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_decoder_model::tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels text_only and text2text datasets tokenization", "x": 207.68590746842787, "y": -626.4715187772032}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function", "label": "conversation_tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels conversation datasets tokenization", "x": 201.45739507804063, "y": -628.5021224851753}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_paired", "label": "blocking_paired()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::blocking_paired\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 220.08093350958302, "y": -622.2253472059383}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking", "label": "blocking()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::blocking\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 213.8939574960686, "y": -624.3791916349151}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_text_to_textlist", "label": "blocking_text_to_textlist()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::blocking_text_to_textlist\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 226.24622593392203, "y": -620.0101976989223}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::paired_conversation_tokenize_function", "label": "paired_conversation_tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::paired_conversation_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 238.50933245665325, "y": -615.3968624644439}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::conversation_tokenize_function", "label": "conversation_tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::conversation_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels conversation datasets tokenization\n    ", "x": 232.38922733042114, "y": -617.733961362632}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function", "label": "tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels text_only and text2text datasets tokenization\n    ", "x": 250.67844426734635, "y": -610.5410040117723}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::text_to_textlist_tokenize_function", "label": "text_to_textlist_tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::text_to_textlist_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: For rm inference, and don\u0027t need attn mask and labels.\nNOTE: input_ids here refers to the tokenized input_ids of the input **and** output", "x": 244.6059383260567, "y": -612.9991312682502}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::set_seed", "label": "set_seed()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::set_seed\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 247.68535729383498, "y": 363.66463092006256}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::LLaDAEvalHarness", "label": "LLaDAEvalHarness()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::LLaDAEvalHarness\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Class", "x": 380.30583248668455, "y": 221.28595476579585}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::__init__\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Args:\n    model_path: LLaDA-8B-Base model path.\n    mask_id: The token id of [MASK] is 126336.\n    max_length: the max sequence length.\n    batch_size: mini batch size.\n    mc_num: Monte Carlo estimation iterations\n    is_check_greedy: For certain metrics like LAMBADA, the evaluation requires the mo\u2026", "x": 371.0256704100682, "y": 236.5162825193214}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::rank", "label": "rank()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::rank\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 262.21960365214113, "y": 353.32828850873807}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::world_size", "label": "world_size()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::world_size\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 217.4205737426825, "y": 382.5288147491673}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::_forward_process", "label": "_forward_process()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::_forward_process\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 350.6528124936826, "y": 265.7867662060514}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::get_logits", "label": "get_logits()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::get_logits\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 315.82037549193063, "y": 306.36169868985894}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::get_loglikelihood", "label": "get_loglikelihood()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::get_loglikelihood\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 303.1454443933021, "y": 318.9088263808128}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::suffix_greedy_prediction", "label": "suffix_greedy_prediction()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::suffix_greedy_prediction\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 232.74416454386346, "y": 373.4034732976904}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::_encode_pair", "label": "_encode_pair()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::_encode_pair\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 361.1359141312016, "y": 251.35801464170856}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::loglikelihood", "label": "loglikelihood()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::loglikelihood\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 289.97244612553004, "y": 330.93198770740884}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::loglikelihood_rolling", "label": "loglikelihood_rolling()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::loglikelihood_rolling\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 276.323023890179, "y": 342.4114286471577}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::generate_until", "label": "generate_until()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::generate_until\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 327.9764145429022, "y": 293.3112195323976}, {"color": "#F6BD16", "fixed": true, "id": "llada.eval_llada::_tokenize", "label": "_tokenize()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::_tokenize\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 339.5935892059753, "y": 279.77883081141664}, {"color": "#6DC8EC", "fixed": true, "id": "llada.postprocess_code::pass_at_1", "label": "pass_at_1()", "shape": "dot", "title": "\u003cb\u003ellada.postprocess_code::pass_at_1\u003c/b\u003e\u003cbr\u003eModule: llada.postprocess_code\u003cbr\u003eFile: llada/postprocess_code.py\u003cbr\u003eKind: Function", "x": 396.9774115183877, "y": -189.7602032675995}, {"color": "#6DC8EC", "fixed": true, "id": "llada.postprocess_code::read_jsonl", "label": "read_jsonl()", "shape": "dot", "title": "\u003cb\u003ellada.postprocess_code::read_jsonl\u003c/b\u003e\u003cbr\u003eModule: llada.postprocess_code\u003cbr\u003eFile: llada/postprocess_code.py\u003cbr\u003eKind: Function", "x": 404.3414371129015, "y": -173.51657624986024}, {"color": "#6DC8EC", "fixed": true, "id": "llada.postprocess_code::write_jsonl", "label": "write_jsonl()", "shape": "dot", "title": "\u003cb\u003ellada.postprocess_code::write_jsonl\u003c/b\u003e\u003cbr\u003eModule: llada.postprocess_code\u003cbr\u003eFile: llada/postprocess_code.py\u003cbr\u003eKind: Function", "x": 411.04113078795217, "y": -156.98786195296}, {"color": "#269A99", "fixed": true, "id": "llada.generate::add_gumbel_noise", "label": "add_gumbel_noise()", "shape": "dot", "title": "\u003cb\u003ellada.generate::add_gumbel_noise\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: The Gumbel max is a method for sampling categorical distributions.\nAccording to arXiv:2409.02908, for MDM, low-precision Gumbel Max improves perplexity score but reduces generation quality.\nThus, we use float64.", "x": 201.73976150974195, "y": 391.02566236244957}, {"color": "#269A99", "fixed": true, "id": "llada.generate::get_num_transfer_tokens", "label": "get_num_transfer_tokens()", "shape": "dot", "title": "\u003cb\u003ellada.generate::get_num_transfer_tokens\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: block_mask_index: (B, L) bool \u2013 which positions are masked in the current block\nreturns: (B, steps) int \u2013 how many tokens to transfer at each step per batch item", "x": 135.96747752497689, "y": 418.46486716986755}, {"color": "#269A99", "fixed": true, "id": "llada.generate::generate", "label": "generate()", "shape": "dot", "title": "\u003cb\u003ellada.generate::generate\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Args:\n    model: Mask predictor.\n    prompt: A tensor of shape (1, L).\n    steps: Sampling steps, less than or equal to gen_length.\n    gen_length: Generated answer length.\n    block_length: Block length, less than or equal to gen_length. If less than gen_length, it means using semi_autoregressive r\u2026", "x": 185.72749137836607, "y": 398.8800558392196}, {"color": "#269A99", "fixed": true, "id": "llada.generate::generate_with_prefix_cache", "label": "generate_with_prefix_cache()", "shape": "dot", "title": "\u003cb\u003ellada.generate::generate_with_prefix_cache\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Args:\n    model: Mask predictor.\n    prompt: A tensor of shape (1, L).\n    steps: Sampling steps, less than or equal to gen_length.\n    gen_length: Generated answer length.\n    block_length: Block length, less than or equal to gen_length. If less than gen_length, it means using semi_autoregressive r\u2026", "x": 152.81431125172102, "y": 412.61093814471536}, {"color": "#269A99", "fixed": true, "id": "llada.generate::generate_with_dual_cache", "label": "generate_with_dual_cache()", "shape": "dot", "title": "\u003cb\u003ellada.generate::generate_with_dual_cache\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function", "x": 169.41007146633586, "y": 406.07909043161897}, {"color": "#269A99", "fixed": true, "id": "llada.generate::get_transfer_index", "label": "get_transfer_index()", "shape": "dot", "title": "\u003cb\u003ellada.generate::get_transfer_index\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns:\n    x0: (B, L) long \u2014 proposed tokens\n    transfer_index: (B, L) bool \u2014 which positions to update this step", "x": 118.89724958968064, "y": 423.63125951705825}, {"color": "#269A99", "fixed": true, "id": "llada.generate::get_transfer_index_dynamic", "label": "get_transfer_index_dynamic()", "shape": "dot", "title": "\u003cb\u003ellada.generate::get_transfer_index_dynamic\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function", "x": 101.63167378550702, "y": 428.101626817227}, {"color": "#269A99", "fixed": true, "id": "llada.generate::main", "label": "main()", "shape": "dot", "title": "\u003cb\u003ellada.generate::main\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function", "x": 84.19911740816681, "y": 431.86862426863763}, {"color": "#E8684A", "fixed": true, "id": "llada.chat::chat", "label": "chat()", "shape": "dot", "title": "\u003cb\u003ellada.chat::chat\u003c/b\u003e\u003cbr\u003eModule: llada.chat\u003cbr\u003eFile: llada/chat.py\u003cbr\u003eKind: Function", "x": 388.9611530791265, "y": 205.69205476963936}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::parse_constraints", "label": "parse_constraints()", "shape": "dot", "title": "\u003cb\u003ellada.app::parse_constraints\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Parse constraints in format: \u0027position:word, position:word, ...\u0027", "x": 404.3414371129015, "y": 173.51657624986015}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::format_chat_history", "label": "format_chat_history()", "shape": "dot", "title": "\u003cb\u003ellada.app::format_chat_history\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Format chat history for the LLaDA model\n\nArgs:\n    history: List of [user_message, assistant_message] pairs\n    \nReturns:\n    Formatted conversation for the model", "x": 430.99317415109755, "y": 88.57134883901043}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::add_gumbel_noise", "label": "add_gumbel_noise()", "shape": "dot", "title": "\u003cb\u003ellada.app::add_gumbel_noise\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: The Gumbel max is a method for sampling categorical distributions.\nAccording to arXiv:2409.02908, for MDM, low-precision Gumbel Max improves perplexity score but reduces generation quality.\nThus, we use float64.", "x": 440.0, "y": 0.0}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::get_num_transfer_tokens", "label": "get_num_transfer_tokens()", "shape": "dot", "title": "\u003cb\u003ellada.app::get_num_transfer_tokens\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: In the reverse process, the interval [0, 1] is uniformly discretized into steps intervals.\nFurthermore, because LLaDA employs a linear noise schedule (as defined in Eq. (8)),\nthe expected number of tokens transitioned at each step should be consistent.\n\nThis function is designed to precompute the nu\u2026", "x": 417.065484964424, "y": 140.20121701108667}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::generate_response_with_visualization_cache_and_parallel", "label": "generate_response_with_visualization_cache_and_parallel()", "shape": "dot", "title": "\u003cb\u003ellada.app::generate_response_with_visualization_cache_and_parallel\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate text with LLaDA model with visualization using the same sampling as in generate.py\n\nArgs:\n    messages: List of message dictionaries with \u0027role\u0027 and \u0027content\u0027\n    gen_length: Length of text to generate\n    steps: Number of denoising steps\n    constraints: Dictionary mapping positions to wor\u2026", "x": 422.40460164422336, "y": 123.18422183780275}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::get_transfer_index", "label": "get_transfer_index()", "shape": "dot", "title": "\u003cb\u003ellada.app::get_transfer_index\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function", "x": 411.0411307879523, "y": 156.98786195295963}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::generate_response_with_visualization", "label": "generate_response_with_visualization()", "shape": "dot", "title": "\u003cb\u003ellada.app::generate_response_with_visualization\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate text with LLaDA model with visualization using the same sampling as in generate.py\n\nArgs:\n    messages: List of message dictionaries with \u0027role\u0027 and \u0027content\u0027\n    gen_length: Length of text to generate\n    steps: Number of denoising steps\n    constraints: Dictionary mapping positions to wor\u2026", "x": 427.04970867266474, "y": 105.96483531149458}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::create_chatbot_demo", "label": "create_chatbot_demo()", "shape": "dot", "title": "\u003cb\u003ellada.app::create_chatbot_demo\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function", "x": 434.2285189760954, "y": 71.03233987295309}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::add_message", "label": "add_message()", "shape": "dot", "title": "\u003cb\u003ellada.app::add_message\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add a message pair to the history and return the updated history", "x": 439.63854057767264, "y": 17.831254547397695}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::user_message_submitted", "label": "user_message_submitted()", "shape": "dot", "title": "\u003cb\u003ellada.app::user_message_submitted\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Process a submitted user message", "x": 396.9774115183877, "y": 189.76020326759934}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::bot_response", "label": "bot_response()", "shape": "dot", "title": "\u003cb\u003ellada.app::bot_response\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate bot response for the latest message", "x": 438.5547561875723, "y": 35.633212390395045}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::clear_conversation", "label": "clear_conversation()", "shape": "dot", "title": "\u003cb\u003ellada.app::clear_conversation\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Clear the conversation history", "x": 436.7504274846062, "y": 53.376624959000125}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::refine_text", "label": "refine_text()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::refine_text\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 436.7504274846062, "y": -53.37662495900046}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::syntax_check", "label": "syntax_check()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::syntax_check\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 439.63854057767264, "y": -17.831254547397876}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::extract_longest_valid_code", "label": "extract_longest_valid_code()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::extract_longest_valid_code\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 417.065484964424, "y": -140.20121701108664}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::get_deps", "label": "get_deps()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::get_deps\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 427.04970867266474, "y": -105.96483531149474}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::get_function_dependency", "label": "get_function_dependency()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::get_function_dependency\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 430.99317415109755, "y": -88.57134883901053}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::get_definition_name", "label": "get_definition_name()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::get_definition_name\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 422.40460164422336, "y": -123.18422183780264}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::has_return_statement", "label": "has_return_statement()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::has_return_statement\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 434.2285189760954, "y": -71.03233987295312}, {"color": "#F6BD16", "fixed": true, "id": "llada.sanitize::sanitize", "label": "sanitize()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::sanitize\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 438.5547561875723, "y": -35.63321239039492}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::scaled_dot_product_attention", "label": "scaled_dot_product_attention()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::scaled_dot_product_attention\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 327.97641454290226, "y": -293.31121953239756}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::ModuleType", "label": "ModuleType()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::ModuleType\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -393.050013107074, "y": 197.7667494715149}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::init_weights", "label": "init_weights()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::init_weights\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initialize weights of a linear or embedding module.\n\n:param config: The model config.\n:param module: The linear or embedding submodule to initialize.\n:param d: The effective input dimensionality of the weights. This could be smaller than the actual dimensions\n    for fused layers.\n:param layer_id: W\u2026", "x": 101.63167378550683, "y": -428.10162681722704}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::ensure_finite_", "label": "ensure_finite_()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::ensure_finite_\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Modify ``x`` in place to replace ``float(\"-inf\")`` with the minimum value of the dtype when ``check_neg_inf``\nis ``True`` and to replace ``float(\"inf\")`` with the maximum value of the dtype when ``check_pos_inf`` is ``True``.", "x": -255.00485739087463, "y": -358.5701084963158}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::activation_checkpoint_function", "label": "activation_checkpoint_function()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::activation_checkpoint_function\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -393.05001310707394, "y": -197.76674947151497}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::BufferCache", "label": "BufferCache()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::BufferCache\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Cache for attention biases and other things that would normally be stored as buffers.\nWe avoid using buffers because we\u0027ve run into various issues doing so with FSDP.\nIn general it appears the way FSDP handles buffers is not well-defined.\nIt doesn\u0027t shard them but apparently it does synchronize them\u2026", "x": -209.62322334863575, "y": 386.8566972832808}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::_non_meta_init_device", "label": "_non_meta_init_device()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::_non_meta_init_device\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -407.7750392167534, "y": -165.28616818044765}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::Dropout", "label": "Dropout()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::Dropout\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -225.12860960637616, "y": 378.0437926176012}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LayerNormBase", "label": "LayerNormBase()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LayerNormBase\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -384.7125111036161, "y": 213.53286351367566}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LayerNorm", "label": "LayerNorm()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LayerNorm\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The default :class:`LayerNorm` implementation which can optionally run in low precision.", "x": -375.7429274545872, "y": 228.94814362177476}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::RMSLayerNorm", "label": "RMSLayerNorm()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::RMSLayerNorm\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: RMS layer norm, a simplified :class:`LayerNorm` implementation", "x": -400.74173497106165, "y": 181.67570517926555}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::GemmaRMSLayerNorm", "label": "GemmaRMSLayerNorm()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::GemmaRMSLayerNorm\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Gemma RMS layer norm, a simplified :class:`LayerNorm` implementation", "x": -255.00485739087475, "y": 358.57010849631575}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::RotaryEmbedding", "label": "RotaryEmbedding()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::RotaryEmbedding\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: [Rotary positional embeddings (RoPE)](https://arxiv.org/abs/2104.09864).", "x": -414.1383701437414, "y": 148.62506644131554}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::Activation", "label": "Activation()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::Activation\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -193.77342668535914, "y": 395.0339974111263}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::GELU", "label": "GELU()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::GELU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -240.26411014967258, "y": 368.60976299331253}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::ReLU", "label": "ReLU()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::ReLU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -407.7750392167534, "y": 165.28616818044776}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::SiLU", "label": "SiLU()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::SiLU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -419.82127281602146, "y": 131.71977410827753}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::SwiGLU", "label": "SwiGLU()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::SwiGLU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -424.8144102394252, "y": 114.59806653224736}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::causal_attention_bias", "label": "causal_attention_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::causal_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -309.5464894807772, "y": -312.6994896863874}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::get_causal_attention_bias", "label": "get_causal_attention_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_causal_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 31.187070301583933, "y": -438.8933431324791}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::alibi_attention_bias", "label": "alibi_attention_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::alibi_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -384.7125111036162, "y": -213.53286351367555}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDABlock", "label": "LLaDABlock()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDABlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A base class for transformer block implementations.", "x": -269.32663232097167, "y": 347.9413242525874}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDASequentialBlock", "label": "LLaDASequentialBlock()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDASequentialBlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is a typical transformer block where the output is computed as ``MLP(LN(x + Attention(LN(x))))``\n(plus another skip connection).", "x": -366.15599916237056, "y": 243.98726253107168}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDALlamaBlock", "label": "LLaDALlamaBlock()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDALlamaBlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is a transformer block where the output is computed as ``MLP(LN(x + Attention(LN(x))))``\n(plus another skip connection). This block is similar to `LLaDASequentialBlock`\nbut some operations have slightly different implementations to imitate the\nbehavior of Llama.", "x": -321.9645251675229, "y": 299.8980569020939}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDABlockDiffBlock", "label": "LLaDABlockDiffBlock()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDABlockDiffBlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is a transformer block where the output is computed as ``MLP(LN(x + Attention(LN(x))))``\n(plus another skip connection). This block is similar to `LLaDASequentialBlock`\nbut some operations have slightly different implementations to imitate the\nbehavior of Llama.", "x": -283.2059043013589, "y": 336.7408733267311}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDAOutput", "label": "LLaDAOutput()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAOutput\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -355.96747752497686, "y": 258.62551100868825}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDAGenerateOutput", "label": "LLaDAGenerateOutput()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAGenerateOutput\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -309.54648948077715, "y": 312.6994896863874}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDABlockGroup", "label": "LLaDABlockGroup()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDABlockGroup\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -296.6198697246168, "y": 324.9871580302079}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDAModel", "label": "LLaDAModel()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAModel\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": -333.8535739848279, "y": 286.60389239777794}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::create_model_config_from_pretrained_config", "label": "create_model_config_from_pretrained_config()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::create_model_config_from_pretrained_config\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Utility function", "x": -296.61986972461705, "y": -324.98715803020775}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::LLaDAModelLM", "label": "LLaDAModelLM()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAModelLM\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Extremely barebones HF model wrapper.", "x": -345.19410225670356, "y": 272.8388384508124}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::forward\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -4.458958409668719, "y": -439.97740588568956}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::__init__\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -424.8144102394251, "y": -114.59806653224746}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::build", "label": "build()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::build\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -333.8535739848279, "y": -286.6038923977778}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::_cast_if_autocast_enabled", "label": "_cast_if_autocast_enabled()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::_cast_if_autocast_enabled\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -414.1383701437414, "y": -148.62506644131545}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::reset_parameters", "label": "reset_parameters()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::reset_parameters\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 303.14544439330206, "y": -318.9088263808128}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::get_rotary_embedding", "label": "get_rotary_embedding()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_rotary_embedding\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 84.19911740816691, "y": -431.86862426863763}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::rotate_half", "label": "rotate_half()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::rotate_half\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 315.82037549193063, "y": -306.36169868985894}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::apply_rotary_pos_emb", "label": "apply_rotary_pos_emb()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::apply_rotary_pos_emb\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -375.7429274545873, "y": -228.94814362177468}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::output_multiplier", "label": "output_multiplier()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::output_multiplier\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 185.72749137836618, "y": -398.88005583921955}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::set_activation_checkpointing", "label": "set_activation_checkpointing()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::set_activation_checkpointing\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 361.13591413120156, "y": -251.35801464170868}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::_cast_attn_bias", "label": "_cast_attn_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::_cast_attn_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -419.8212728160215, "y": -131.71977410827742}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::_scaled_dot_product_attention", "label": "_scaled_dot_product_attention()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::_scaled_dot_product_attention\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Computes scaled dot product attention on query, key and value tensors, using an optional\nattention mask if passed, and applying dropout if a probability greater than 0.0 is specified.", "x": -400.7417349710617, "y": -181.67570517926526}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::attention", "label": "attention()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::attention\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -366.1559991623706, "y": -243.98726253107156}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::cross_attn_flex", "label": "cross_attn_flex()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::cross_attn_flex\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -283.20590430135894, "y": -336.74087332673105}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::device", "label": "device()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::device\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -269.32663232097156, "y": -347.9413242525874}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::get_alibi_attention_bias", "label": "get_alibi_attention_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_alibi_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 13.375043526654565, "y": -439.7966668935317}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::can_generate", "label": "can_generate()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::can_generate\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": -321.96452516752294, "y": -299.8980569020938}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::prepare_inputs_for_generation", "label": "prepare_inputs_for_generation()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::prepare_inputs_for_generation\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 201.73976150974178, "y": -391.0256623624497}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::get_input_embeddings", "label": "get_input_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 48.947856801898325, "y": -437.2689187610993}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::set_input_embeddings", "label": "set_input_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::set_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 371.02567041006796, "y": -236.51628251932175}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::get_output_embeddings", "label": "get_output_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 66.62822210201334, "y": -434.92606270436903}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::set_output_embeddings", "label": "set_output_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::set_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 380.30583248668455, "y": -221.28595476579576}, {"color": "#269A99", "fixed": true, "id": "llada.model.modeling_llada::tie_weights", "label": "tie_weights()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::tie_weights\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 388.9611530791264, "y": -205.69205476963955}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::StrEnum", "label": "StrEnum()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::StrEnum\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is equivalent to Python\u0027s :class:`enum.StrEnum` since version 3.11.\nWe include this here for compatibility with older version of Python.", "x": -57.799911308984484, "y": 436.1870817122781}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::LayerNormType", "label": "LayerNormType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::LayerNormType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": -22.285634289033563, "y": 439.4352631552632}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::ActivationType", "label": "ActivationType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::ActivationType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 48.94785680189843, "y": 437.2689187610993}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::BlockType", "label": "BlockType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::BlockType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 31.187070301584043, "y": 438.8933431324791}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::InitFnType", "label": "InitFnType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::InitFnType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 13.375043526654867, "y": 439.7966668935317}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::ModelConfig", "label": "ModelConfig()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::ModelConfig\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: LLaDA (model) configuration.", "x": -40.07569492977872, "y": 438.17112944133515}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::ActivationCheckpointingStrategy", "label": "ActivationCheckpointingStrategy()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::ActivationCheckpointingStrategy\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 66.62822210201375, "y": 434.92606270436903}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::LLaDAConfig", "label": "LLaDAConfig()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::LLaDAConfig\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": -4.458958409668806, "y": 439.97740588568956}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::__str__", "label": "__str__()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::__str__\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": -110.28711419383698, "y": 425.9539323011299}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::__repr__", "label": "__repr__()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::__repr__\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": -92.93448394630713, "y": 430.0734608106313}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::effective_n_kv_heads", "label": "effective_n_kv_heads()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::effective_n_kv_heads\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": -127.4585430023365, "y": 421.13456259932116}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::__init__\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": -75.42916258567962, "y": 433.48637975330104}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::num_attention_heads", "label": "num_attention_heads()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::num_attention_heads\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": -161.145289919206, "y": 409.42910929348324}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::num_hidden_layers", "label": "num_hidden_layers()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::num_hidden_layers\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": -177.60526079084553, "y": 402.56225771849967}, {"color": "#5B8FF9", "fixed": true, "id": "llada.model.configuration_llada::hidden_size", "label": "hidden_size()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::hidden_size\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": -144.42055775936197, "y": 415.62326991697034}, {"color": "#5B8FF9", "fixed": true, "id": "dream.postprocess_code::pass_at_1", "label": "pass_at_1()", "shape": "dot", "title": "\u003cb\u003edream.postprocess_code::pass_at_1\u003c/b\u003e\u003cbr\u003eModule: dream.postprocess_code\u003cbr\u003eFile: dream/postprocess_code.py\u003cbr\u003eKind: Function", "x": 188.70029420005983, "y": -113.10260372250882}, {"color": "#5B8FF9", "fixed": true, "id": "dream.postprocess_code::read_jsonl", "label": "read_jsonl()", "shape": "dot", "title": "\u003cb\u003edream.postprocess_code::read_jsonl\u003c/b\u003e\u003cbr\u003eModule: dream.postprocess_code\u003cbr\u003eFile: dream/postprocess_code.py\u003cbr\u003eKind: Function", "x": 194.02267815663805, "y": -103.70728210171956}, {"color": "#5B8FF9", "fixed": true, "id": "dream.postprocess_code::write_jsonl", "label": "write_jsonl()", "shape": "dot", "title": "\u003cb\u003edream.postprocess_code::write_jsonl\u003c/b\u003e\u003cbr\u003eModule: dream.postprocess_code\u003cbr\u003eFile: dream/postprocess_code.py\u003cbr\u003eKind: Function", "x": 198.87764448715748, "y": -94.06212055466216}, {"color": "#9270CA", "fixed": true, "id": "dream.demo_multiturn_chat::generation_tokens_hook_func", "label": "generation_tokens_hook_func()", "shape": "dot", "title": "\u003cb\u003edream.demo_multiturn_chat::generation_tokens_hook_func\u003c/b\u003e\u003cbr\u003eModule: dream.demo_multiturn_chat\u003cbr\u003eFile: dream/demo_multiturn_chat.py\u003cbr\u003eKind: Function", "x": 220.0, "y": 0.0}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::Dream", "label": "Dream()", "shape": "dot", "title": "\u003cb\u003edream.eval::Dream\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Class", "x": 219.73500036513792, "y": 10.794888352031963}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.eval::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 218.94063986788333, "y": 21.563770872503333}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::batch_size", "label": "batch_size()", "shape": "dot", "title": "\u003cb\u003edream.eval::batch_size\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 188.70029420005986, "y": 113.10260372250876}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::device", "label": "device()", "shape": "dot", "title": "\u003cb\u003edream.eval::device\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 176.7056569257419, "y": 131.05384698833535}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::rank", "label": "rank()", "shape": "dot", "title": "\u003cb\u003edream.eval::rank\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 139.566522516002, "y": 170.06229973980214}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::world_size", "label": "world_size()", "shape": "dot", "title": "\u003cb\u003edream.eval::world_size\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 103.70728210171951, "y": 194.02267815663808}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::_create_model_and_tokenizer", "label": "_create_model_and_tokenizer()", "shape": "dot", "title": "\u003cb\u003edream.eval::_create_model_and_tokenizer\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 217.61883219225183, "y": 32.280704380179586}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::tok_decode", "label": "tok_decode()", "shape": "dot", "title": "\u003cb\u003edream.eval::tok_decode\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 131.05384698833535, "y": 176.70565692574186}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::tok_encode", "label": "tok_encode()", "shape": "dot", "title": "\u003cb\u003edream.eval::tok_encode\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 122.2254512643125, "y": 182.92331470655995}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::create_from_arg_string", "label": "create_from_arg_string()", "shape": "dot", "title": "\u003cb\u003edream.eval::create_from_arg_string\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Creates an instance of the LM class using the given argument string and additional config.\n\nParameters:\n- arg_string: A string containing arguments in the format key1=value1,key2=value2.\n- additional_config: Optional dictionary containing additional configuration parameters.\n\nReturns:\n- Instance of \u2026", "x": 182.92331470655995, "y": 122.22545126431248}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::apply_chat_template", "label": "apply_chat_template()", "shape": "dot", "title": "\u003cb\u003edream.eval::apply_chat_template\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Method to apply a chat template to a list of chat history between user and model.", "x": 194.0226781566381, "y": 103.70728210171949}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::tokenizer_name", "label": "tokenizer_name()", "shape": "dot", "title": "\u003cb\u003edream.eval::tokenizer_name\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 113.10260372250876, "y": 188.70029420005986}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::_generate_batch", "label": "_generate_batch()", "shape": "dot", "title": "\u003cb\u003edream.eval::_generate_batch\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 203.25349715248308, "y": 84.19035512031975}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::generate_until", "label": "generate_until()", "shape": "dot", "title": "\u003cb\u003edream.eval::generate_until\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 170.06229973980214, "y": 139.566522516002}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::_forward_process", "label": "_forward_process()", "shape": "dot", "title": "\u003cb\u003edream.eval::_forward_process\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 207.13969434026458, "y": 74.11576774628841}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::get_logits", "label": "get_logits()", "shape": "dot", "title": "\u003cb\u003edream.eval::get_logits\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: prompt_index : 1D bool tensor, length=batch.shape[1]", "x": 163.00924757809102, "y": 147.74297006634404}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::_eval_target_nll_mc", "label": "_eval_target_nll_mc()", "shape": "dot", "title": "\u003cb\u003edream.eval::_eval_target_nll_mc\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 210.52687386108593, "y": 63.862628995981716}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::_eval_target_nll_ar", "label": "_eval_target_nll_ar()", "shape": "dot", "title": "\u003cb\u003edream.eval::_eval_target_nll_ar\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 213.40687570279968, "y": 53.45563957871805}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::_encode_pair", "label": "_encode_pair()", "shape": "dot", "title": "\u003cb\u003edream.eval::_encode_pair\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 215.7727616887107, "y": 42.91987084354822}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::loglikelihood", "label": "loglikelihood()", "shape": "dot", "title": "\u003cb\u003edream.eval::loglikelihood\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 155.56349186104046, "y": 155.56349186104043}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::loglikelihood_rolling", "label": "loglikelihood_rolling()", "shape": "dot", "title": "\u003cb\u003edream.eval::loglikelihood_rolling\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 147.74297006634404, "y": 163.009247578091}, {"color": "#5AD8A6", "fixed": true, "id": "dream.eval::_tokenize", "label": "_tokenize()", "shape": "dot", "title": "\u003cb\u003edream.eval::_tokenize\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 198.87764448715754, "y": 94.06212055466206}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::refine_text", "label": "refine_text()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::refine_text\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 217.6188321922518, "y": -32.28070438017973}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::syntax_check", "label": "syntax_check()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::syntax_check\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 219.73500036513792, "y": -10.79488835203198}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::extract_longest_valid_code", "label": "extract_longest_valid_code()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::extract_longest_valid_code\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 203.25349715248302, "y": -84.1903551203199}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::get_deps", "label": "get_deps()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::get_deps\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 210.52687386108593, "y": -63.86262899598175}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::get_function_dependency", "label": "get_function_dependency()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::get_function_dependency\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 213.40687570279968, "y": -53.45563957871812}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::get_definition_name", "label": "get_definition_name()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::get_definition_name\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 207.13969434026458, "y": -74.1157677462884}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::has_return_statement", "label": "has_return_statement()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::has_return_statement\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 215.77276168871066, "y": -42.91987084354832}, {"color": "#F6BD16", "fixed": true, "id": "dream.sanitize::sanitize", "label": "sanitize()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::sanitize\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 218.94063986788333, "y": -21.563770872503312}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::BaseModelOutputWithPast", "label": "BaseModelOutputWithPast()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::BaseModelOutputWithPast\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -210.52687386108593, "y": 63.86262899598172}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::MaskedLMOutputWithPastKeyValues", "label": "MaskedLMOutputWithPastKeyValues()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::MaskedLMOutputWithPastKeyValues\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -215.7727616887107, "y": -42.91987084354824}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamRMSNorm", "label": "DreamRMSNorm()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamRMSNorm\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -219.73500036513792, "y": -10.794888352031899}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamRotaryEmbedding", "label": "DreamRotaryEmbedding()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamRotaryEmbedding\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -218.94063986788333, "y": -21.56377087250333}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::rotate_half", "label": "rotate_half()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::rotate_half\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Rotates half the hidden dims of the input.", "x": 21.56377087250322, "y": -218.94063986788333}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::apply_rotary_pos_emb", "label": "apply_rotary_pos_emb()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::apply_rotary_pos_emb\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Applies Rotary Position Embedding to the query and key tensors.\n\nArgs:\n    q (`torch.Tensor`): The query tensor.\n    k (`torch.Tensor`): The key tensor.\n    cos (`torch.Tensor`): The cosine part of the rotary embedding.\n    sin (`torch.Tensor`): The sine part of the rotary embedding.\n    position_id\u2026", "x": -155.5634918610405, "y": -155.56349186104043}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamMLP", "label": "DreamMLP()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamMLP\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -218.9406398678833, "y": 21.563770872503383}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::repeat_kv", "label": "repeat_kv()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::repeat_kv\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\nnum_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)", "x": -10.794888352031967, "y": -219.73500036513792}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamAttention", "label": "DreamAttention()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamAttention\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Multi-headed attention from \u0027Attention Is All You Need\u0027 paper. Modified to use sliding window attention: Longformer\nand \"Generating Long Sequences with Sparse Transformers\".", "x": -213.40687570279968, "y": 53.45563957871809}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamSdpaAttention", "label": "DreamSdpaAttention()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamSdpaAttention\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Dream attention module using torch.nn.functional.scaled_dot_product_attention. This module inherits from\n`DreamAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to\nSDPA API.", "x": -217.61883219225183, "y": -32.28070438017955}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamDecoderLayer", "label": "DreamDecoderLayer()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamDecoderLayer\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -217.61883219225183, "y": 32.2807043801796}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamPreTrainedModel", "label": "DreamPreTrainedModel()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamPreTrainedModel\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -220.0, "y": 2.694222958124177e-14}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamBaseModel", "label": "DreamBaseModel()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamBaseModel\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`DreamDecoderLayer`]\n\nArgs:\n    config: DreamConfig", "x": -215.7727616887107, "y": 42.919870843548296}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::DreamModel", "label": "DreamModel()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamModel\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": -219.73500036513792, "y": 10.794888352031952}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -176.7056569257419, "y": -131.05384698833532}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::forward\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -74.11576774628838, "y": -207.13969434026458}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::extra_repr", "label": "extra_repr()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::extra_repr\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -147.7429700663441, "y": -163.00924757809096}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::reset_parameters", "label": "reset_parameters()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::reset_parameters\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -4.0413344371862656e-14, "y": -220.0}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::_dynamic_frequency_update", "label": "_dynamic_frequency_update()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::_dynamic_frequency_update\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: dynamic RoPE layers should recompute `inv_freq` in the following situations:\n1 - growing beyond the cached sequence length (allow scaling)\n2 - the current sequence length is in the original scale (avoid losing precision with small sequences)", "x": -170.06229973980217, "y": -139.56652251600195}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::_init_weights", "label": "_init_weights()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::_init_weights\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -163.009247578091, "y": -147.74297006634407}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::from_pretrained", "label": "from_pretrained()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::from_pretrained\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -63.86262899598174, "y": -210.52687386108593}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::get_input_embeddings", "label": "get_input_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::get_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -32.28070438017971, "y": -217.6188321922518}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::set_input_embeddings", "label": "set_input_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::set_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 53.45563957871803, "y": -213.40687570279968}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::reset_rope_parameters", "label": "reset_rope_parameters()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::reset_rope_parameters\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 10.794888352031885, "y": -219.73500036513792}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::get_output_embeddings", "label": "get_output_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::get_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -21.563770872503298, "y": -218.94063986788333}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::set_output_embeddings", "label": "set_output_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::set_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 63.86262899598165, "y": -210.52687386108596}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::set_decoder", "label": "set_decoder()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::set_decoder\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 32.28070438017963, "y": -217.6188321922518}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.modeling_dream::get_decoder", "label": "get_decoder()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::get_decoder\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": -53.455639578718106, "y": -213.40687570279968}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::top_p_logits", "label": "top_p_logits()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::top_p_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": -74.11576774628838, "y": 207.13969434026458}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::top_k_logits", "label": "top_k_logits()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::top_k_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": -63.86262899598167, "y": 210.52687386108596}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::sample_tokens", "label": "sample_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::sample_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": -53.45563957871805, "y": 213.40687570279968}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::DreamModelOutput", "label": "DreamModelOutput()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::DreamModelOutput\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Class", "x": 53.45563957871808, "y": 213.40687570279968}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::DreamGenerationConfig", "label": "DreamGenerationConfig()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::DreamGenerationConfig\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Class", "x": 74.11576774628841, "y": 207.13969434026458}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::DreamGenerationMixin", "label": "DreamGenerationMixin()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::DreamGenerationMixin\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Class", "x": 63.862628995981716, "y": 210.52687386108593}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 42.91987084354823, "y": 215.7727616887107}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::validate", "label": "validate()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::validate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": -84.19035512031974, "y": 203.25349715248308}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::_expand_inputs_for_generation", "label": "_expand_inputs_for_generation()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_expand_inputs_for_generation\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Expands tensors from [batch_size, ...] to [batch_size * expand_size, ...]", "x": 32.280704380179586, "y": 217.61883219225183}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::_validate_generated_length", "label": "_validate_generated_length()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_validate_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs validation related to the resulting generated length", "x": -32.28070438017956, "y": 217.61883219225183}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::_prepare_generated_length", "label": "_prepare_generated_length()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_prepare_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepared max and min length in generation configs to avoid clashes between similar attributes", "x": 21.56377087250337, "y": 218.9406398678833}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::_prepare_generation_config", "label": "_prepare_generation_config()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_prepare_generation_config\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the base generation config, then applies any generation configuration options from kwargs. This\nfunction handles retrocompatibility with respect to configuration files.", "x": 10.794888352031988, "y": 219.73500036513792}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::_prepare_special_tokens", "label": "_prepare_special_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_prepare_special_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the special tokens for generation, overwriting the generation config with their processed versions\nconverted to tensor.\nNote that `generation_config` is changed in place and stops being serializable after this method is called.\nThat is no problem if called within `generate` (`generation_con\u2026", "x": 1.3471114790620885e-14, "y": 220.0}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::diffusion_generate", "label": "diffusion_generate()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::diffusion_generate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": -42.9198708435482, "y": 215.7727616887107}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::_sample", "label": "_sample()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_sample\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": -10.794888352031961, "y": 219.73500036513792}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils::_tensor_or_none", "label": "_tensor_or_none()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_tensor_or_none\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": -21.56377087250334, "y": 218.94063986788333}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::bytes_to_unicode", "label": "bytes_to_unicode()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::bytes_to_unicode\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns list of utf-8 byte and a mapping to unicode strings. We specifically avoids mapping to whitespace/control\ncharacters the bpe code barfs on.\n\nThe reversible bpe codes work on unicode strings. This means you need a large # of unicode characters in your vocab\nif you want to avoid UNKs. When you\u2026", "x": 131.05384698833524, "y": -176.70565692574195}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::get_pairs", "label": "get_pairs()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::get_pairs\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return set of symbol pairs in a word.\n\nWord is represented as tuple of symbols (symbols being variable-length strings).", "x": 155.5634918610404, "y": -155.5634918610405}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::DreamTokenizer", "label": "DreamTokenizer()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::DreamTokenizer\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Construct a Dream tokenizer. Based on byte-level Byte-Pair-Encoding.\n\nSame with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will\nbe encoded differently whether it is at the beginning of the sentence (without space) or not:\n\n```python\n\u003e\u003e\u003e from tra\u2026", "x": 74.11576774628831, "y": -207.1396943402646}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 84.19035512031981, "y": -203.25349715248305}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::vocab_size", "label": "vocab_size()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::vocab_size\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 182.92331470655995, "y": -122.22545126431248}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::get_vocab", "label": "get_vocab()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::get_vocab\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 163.00924757809094, "y": -147.7429700663441}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::bpe", "label": "bpe()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::bpe\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 122.22545126431241, "y": -182.92331470656}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::_tokenize", "label": "_tokenize()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::_tokenize\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize a string.", "x": 113.10260372250875, "y": -188.7002942000599}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::_convert_token_to_id", "label": "_convert_token_to_id()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::_convert_token_to_id\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Converts a token (str) in an id using the vocab.", "x": 103.70728210171947, "y": -194.0226781566381}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::_convert_id_to_token", "label": "_convert_id_to_token()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::_convert_id_to_token\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Converts an index (integer) in a token (str) using the vocab.", "x": 94.06212055466207, "y": -198.87764448715754}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::convert_tokens_to_string", "label": "convert_tokens_to_string()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::convert_tokens_to_string\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Converts a sequence of tokens (string) in a single string.", "x": 139.56652251600204, "y": -170.0622997398021}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::decode", "label": "decode()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::decode\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 147.74297006634407, "y": -163.009247578091}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::save_vocabulary", "label": "save_vocabulary()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::save_vocabulary\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 176.70565692574192, "y": -131.05384698833532}, {"color": "#9270CA", "fixed": true, "id": "dream.model.tokenization_dream::prepare_for_tokenization", "label": "prepare_for_tokenization()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::prepare_for_tokenization\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 170.06229973980206, "y": -139.5665225160021}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::get_num_transfer_tokens", "label": "get_num_transfer_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::get_num_transfer_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: In the reverse process, the interval [0, 1] is uniformly discretized into steps intervals.\nFurthermore, because LLaDA employs a linear noise schedule (as defined in Eq. (8)),\nthe expected number of tokens transitioned at each step should be consistent.\n\nThis function is designed to precompute the nu\u2026", "x": -188.70029420005983, "y": 113.10260372250879}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::top_p_logits", "label": "top_p_logits()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::top_p_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -203.25349715248308, "y": 84.19035512031978}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::top_k_logits", "label": "top_k_logits()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::top_k_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -198.87764448715754, "y": 94.06212055466204}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::sample_tokens", "label": "sample_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::sample_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -194.02267815663808, "y": 103.70728210171953}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::DreamModelOutput", "label": "DreamModelOutput()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::DreamModelOutput\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Class", "x": -113.10260372250876, "y": 188.70029420005986}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::DreamGenerationConfig", "label": "DreamGenerationConfig()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::DreamGenerationConfig\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Class", "x": -94.06212055466202, "y": 198.87764448715757}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::DreamGenerationMixin", "label": "DreamGenerationMixin()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::DreamGenerationMixin\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Class", "x": -103.7072821017195, "y": 194.0226781566381}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -122.22545126431243, "y": 182.92331470655998}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::validate", "label": "validate()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::validate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -207.13969434026455, "y": 74.11576774628847}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::_expand_inputs_for_generation", "label": "_expand_inputs_for_generation()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_expand_inputs_for_generation\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Expands tensors from [batch_size, ...] to [batch_size * expand_size, ...]", "x": -131.05384698833535, "y": 176.7056569257419}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::_validate_generated_length", "label": "_validate_generated_length()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_validate_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs validation related to the resulting generated length", "x": -176.70565692574186, "y": 131.05384698833535}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::_prepare_generated_length", "label": "_prepare_generated_length()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_prepare_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepared max and min length in generation configs to avoid clashes between similar attributes", "x": -139.56652251600198, "y": 170.06229973980217}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::_prepare_generation_config", "label": "_prepare_generation_config()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_prepare_generation_config\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the base generation config, then applies any generation configuration options from kwargs. This\nfunction handles retrocompatibility with respect to configuration files.", "x": -147.74297006634407, "y": 163.009247578091}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::_prepare_special_tokens", "label": "_prepare_special_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_prepare_special_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the special tokens for generation, overwriting the generation config with their processed versions\nconverted to tensor.\nNote that `generation_config` is changed in place and stops being serializable after this method is called.\nThat is no problem if called within `generate` (`generation_con\u2026", "x": -155.56349186104043, "y": 155.56349186104046}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::diffusion_generate", "label": "diffusion_generate()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::diffusion_generate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -182.92331470655998, "y": 122.22545126431248}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::_sample", "label": "_sample()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_sample\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -163.00924757809096, "y": 147.74297006634407}, {"color": "#5D7092", "fixed": true, "id": "dream.model.generation_utils_block::_tensor_or_none", "label": "_tensor_or_none()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_tensor_or_none\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": -170.06229973980214, "y": 139.566522516002}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.configuration_dream::DreamConfig", "label": "DreamConfig()", "shape": "dot", "title": "\u003cb\u003edream.model.configuration_dream::DreamConfig\u003c/b\u003e\u003cbr\u003eModule: dream.model.configuration_dream\u003cbr\u003eFile: dream/model/configuration_dream.py\u003cbr\u003eKind: Class", "x": 94.06212055466209, "y": 198.87764448715754}, {"color": "#6DC8EC", "fixed": true, "id": "dream.model.configuration_dream::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.model.configuration_dream::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.configuration_dream\u003cbr\u003eFile: dream/model/configuration_dream.py\u003cbr\u003eKind: Function", "x": 84.19035512031977, "y": 203.25349715248308}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "v2.app::generate_response_with_visualization_fast_dllm", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.app::generate_response_with_visualization_fast_dllm", "to": "v2.generation_functions::mdm_sample_with_visualization"}, {"arrows": "to", "from": "v2.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::create_chatbot_demo", "to": "v2.app::add_message"}, {"arrows": "to", "from": "v2.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::add_message", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::user_message_submitted", "to": "v2.app::add_message"}, {"arrows": "to", "from": "v2.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::accelerated_response", "to": "v2.app::format_chat_history"}, {"arrows": "to", "from": "v2.app::accelerated_response", "to": "v2.app::generate_response_with_visualization_fast_dllm"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::__init__"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::_forward_process"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::get_logits"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.eval::get_loglikelihood", "to": "v2.eval::_forward_process"}, {"arrows": "to", "from": "v2.eval::get_loglikelihood", "to": "v2.eval::get_logits"}, {"arrows": "to", "from": "v2.eval::loglikelihood", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.eval::loglikelihood", "to": "v2.eval::_encode_pair"}, {"arrows": "to", "from": "v2.eval::loglikelihood", "to": "v2.eval::get_loglikelihood"}, {"arrows": "to", "from": "v2.eval::_tokenize", "to": "v2.eval::_encode_pair"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.args::get_pipeline_args_class"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.pipeline.auto_pipeline::get_pipeline"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.models.auto_model::get_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::align", "to": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::align", "to": "v2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::align", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference", "to": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "to": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::InferencerWithOffloading", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::inference", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::inference", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::scheduling_strategy_fn", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.pipeline.inferencer::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.args::DatasetArguments"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::predict_next_token"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::sample"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::speculative_sampling"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::ToolInferencer", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::__init__", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::to_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "to": "v2.src.lmflow.pipeline.inferencer::predict_next_token"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "to": "v2.src.lmflow.pipeline.inferencer::sample"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::sample"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_top", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_local", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::group_texts", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::flatten_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__init__", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "to": "v2.src.lmflow.utils.versioning::is_ray_available"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::flatten_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__post_process_model_output"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::compress_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::scheduling_strategy_fn", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__call__", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.finetuner::group_text"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.finetuner::group_text"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.rm_tuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::on_step_begin", "to": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers", "to": "v2.src.lmflow.pipeline.rm_tuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "to": "v2.src.lmflow.utils.common::add_dataclass_attr_prefix"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::__init__", "to": "v2.src.lmflow.utils.common::add_dataclass_attr_prefix"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::align", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::align", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards_fast"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::group_text", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::group_text", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer", "to": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::CustomizedOptimTrainer", "to": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::create_optimizer", "to": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.finetuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.finetuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::on_step_begin", "to": "v2.src.lmflow.pipeline.finetuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::switch_active_layers", "to": "v2.src.lmflow.pipeline.finetuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::__init__", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::create_dataloader", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_ppl"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_ppl", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.pipeline.evaluator::get_nll"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.pipeline.evaluator::get_nll"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.rm_trainer::RewardTrainer", "to": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.rm_trainer::PeftRewardTrainer", "to": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.rm_trainer::compute_loss", "to": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::__init__", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_loss_metrics", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::on_epoch_end", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::on_save", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::pop_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::remove_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device", "to": "llada.model.modeling_llada::tie_weights"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_scheduler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::train"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_hp_search_setup"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::call_model_init"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_local_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load", "to": "llada.model.modeling_llada::tie_weights"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::on_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::dtype"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::train"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero", "to": "v2.eval::rank"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_tpu"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::predict", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::predict", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_pad_across_processes", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_gather_and_numpify"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.utils.common::remove_dataclass_attr_prefix"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.args::ModelArguments"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.args::get_pipeline_args_class"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.models.auto_model::get_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::expand2square"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token", "to": "v2.src.lmflow.datasets.multi_modal_dataset::insert_separator"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::append_message"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::DataCollatorForSupervisedDataset", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::expand2square"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__call__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.args::DatasetArguments"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::_check_hf_json_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::train_test_split"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.datasets.dataset::_check_hf_json_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.utils.versioning::is_multimodal_available"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::_check_hf_json_format", "to": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::_check_hf_json_format", "to": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::from_dict", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::create_from_dict", "to": "v2.src.lmflow.args::DatasetArguments"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::create_from_dict", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::create_from_dict", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::to_dict", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::to_list", "to": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::save", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::sample", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::sample", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::sanity_check", "to": "v2.src.lmflow.datasets.dataset::hf_dataset_sanity_check"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lamb::Lamb", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lamb::Lamb", "to": "v2.src.lmflow.optim.lamb::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lamb::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.optim.adan::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.optim.adan::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::step", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::step", "to": "v2.src.lmflow.optim.adan::_multi_tensor_adan"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::step", "to": "v2.src.lmflow.optim.adan::_single_tensor_adan"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::LARS", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::LARS", "to": "v2.src.lmflow.optim.lars::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::LARS", "to": "v2.src.lmflow.optim.lars::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::Adamax", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::Adamax", "to": "v2.src.lmflow.optim.adamax::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::Adamax", "to": "v2.src.lmflow.optim.adamax::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree", "to": "v2.src.lmflow.optim.sgd_schedule_free::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgd_schedule_free::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::AdamP", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::AdamP", "to": "v2.src.lmflow.optim.adamp::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::AdamP", "to": "v2.src.lmflow.optim.adamp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::_projection", "to": "v2.src.lmflow.optim.adamp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::step", "to": "v2.src.lmflow.optim.adamp::_projection"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::AdaBelief", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::AdaBelief", "to": "v2.src.lmflow.optim.adabelief::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::AdaBelief", "to": "v2.src.lmflow.optim.adabelief::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adagrad::AdaGrad", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adagrad::AdaGrad", "to": "v2.src.lmflow.optim.adagrad::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adagrad::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::NovoGrad", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::NovoGrad", "to": "v2.src.lmflow.optim.novograd::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::NovoGrad", "to": "v2.src.lmflow.optim.novograd::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.yogi::Yogi", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.yogi::Yogi", "to": "v2.src.lmflow.optim.yogi::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.yogi::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::RAdam", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::RAdam", "to": "v2.src.lmflow.optim.radam::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::RAdam", "to": "v2.src.lmflow.optim.radam::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adam::Adam", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adam::Adam", "to": "v2.src.lmflow.optim.adam::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adam::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree", "to": "v2.src.lmflow.optim.adamw_schedule_free::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamw_schedule_free::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::SophiaG", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::SophiaG", "to": "v2.src.lmflow.optim.sophia::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::SophiaG", "to": "v2.src.lmflow.optim.sophia::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::AdaBound", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::AdaBound", "to": "v2.src.lmflow.optim.adabound::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::AdaBound", "to": "v2.src.lmflow.optim.adabound::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::NAdam", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::NAdam", "to": "v2.src.lmflow.optim.nadam::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::NAdam", "to": "v2.src.lmflow.optim.nadam::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::Muon", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::Muon", "to": "v2.src.lmflow.optim.muon::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::Muon", "to": "v2.src.lmflow.optim.muon::zeropower_via_newtonschulz5"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::step", "to": "v2.src.lmflow.optim.muon::zeropower_via_newtonschulz5"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::SGDP", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::SGDP", "to": "v2.src.lmflow.optim.sgdp::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::SGDP", "to": "v2.src.lmflow.optim.sgdp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::_projection", "to": "v2.src.lmflow.optim.sgdp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::step", "to": "v2.src.lmflow.optim.sgdp::_projection"}, {"arrows": "to", "from": "v2.src.lmflow.optim.dummy::Dummy", "to": "v2.src.lmflow.optim.dummy::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adadelta::Adadelta", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adadelta::Adadelta", "to": "v2.src.lmflow.optim.adadelta::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adadelta::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "to": "v2.src.lmflow.utils.llava_conversation_lib::get_images"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::get_images", "to": "v2.src.lmflow.utils.llava_conversation_lib::expand2square"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::copy", "to": "v2.src.lmflow.utils.llava_conversation_lib::Conversation"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::dict", "to": "v2.src.lmflow.utils.llava_conversation_lib::get_images"}, {"arrows": "to", "from": "v2.src.lmflow.utils.multimodal::update_custom_config", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.utils.multimodal::load_llava_pretrain_model", "to": "v2.src.lmflow.utils.multimodal::adapt_llava_model_to_lmflow_type"}, {"arrows": "to", "from": "v2.src.lmflow.utils.model::check_homogeneity", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast", "to": "v2.src.lmflow.utils.data_utils::preview_file"}, {"arrows": "to", "from": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast", "to": "v2.src.lmflow.utils.data_utils::preview_file"}, {"arrows": "to", "from": "v2.src.lmflow.utils.common::create_copied_dataclass", "to": "v2.src.lmflow.utils.versioning::get_python_version"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::_is_packages_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::_is_packages_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_gradio_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_ray_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_vllm_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_flash_attn_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_flask_available", "to": "v2.src.lmflow.utils.versioning::_is_packages_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_trl_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_multimodal_available", "to": "v2.src.lmflow.utils.versioning::_is_packages_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.gemma::GemmaConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.gemma::encode_conversation"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::EmptyFormatter", "to": "v2.src.lmflow.utils.conversation_template.base::has_placeholder"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::StringFormatter", "to": "v2.src.lmflow.utils.conversation_template.base::has_placeholder"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::StringFormatter", "to": "v2.src.lmflow.utils.conversation_template.base::TemplateComponent"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_starter"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "to": "v2.src.lmflow.utils.conversation_template.base::_handle_tools"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "to": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::format", "to": "v2.src.lmflow.utils.conversation_template.base::TemplateComponent"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::encode_conversation", "to": "v2.src.lmflow.utils.conversation_template.base::_handle_tools"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::encode_conversation", "to": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::_encode_template", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::_encode_template", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "to": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_starter"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_starter", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_starter", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::CondenseRotaryEmbedding", "to": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::forward", "to": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::_attn"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::forward", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::backward", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.debug.profiler::Timer", "to": "v2.src.lmflow.utils.debug.profiler::_to_readable"}, {"arrows": "to", "from": "v2.src.lmflow.utils.debug.profiler::show", "to": "v2.src.lmflow.utils.debug.profiler::_to_readable"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::decode"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.multimodal::load_llava_pretrain_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.multimodal::update_custom_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::merge_lora_weights", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::save", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::save", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::AutoModel", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::AutoModel", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::AutoModel", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::get_model", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::get_model", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::get_model", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::decode"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.models.hf_decoder_model::encode"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_fingerprint"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_decoder_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.utils.versioning::is_vllm_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.utils.versioning::is_ray_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::merge_lora_weights", "to": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::preprocess_conversation", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::tokenize"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::sanity_check"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_fingerprint"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.models.hf_text_regression_model::tokenize"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.datasets.dataset::sanity_check"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.utils.versioning::is_ray_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_dtype"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_quant_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_dtype"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_quant_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "to": "dream.model.tokenization_dream::get_vocab"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject", "to": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::replace_llama_with_condense"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference", "to": "v2.src.lmflow.utils.versioning::is_vllm_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision2seq_model::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision2seq_model::register_prompt_cache"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::vision_model_from_pretrained", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::qformer_from_pretrained", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::save_prompt_cache", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::load_prompt_cache", "to": "v2.src.lmflow.models.vision2seq_model::register_prompt_cache"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::forward", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::forward", "to": "v2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::generate", "to": "v2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::generate", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::forward", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::feature_select"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::forward", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::feature_select"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::tokenize_function", "to": "v2.src.lmflow.tokenization.hf_decoder_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::tokenize_function", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_decoder_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::paired_conversation_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_paired"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::conversation_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::text_to_textlist_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_text_to_textlist"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "llada.eval_llada::__init__"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.eval_llada::get_loglikelihood", "to": "llada.eval_llada::_forward_process"}, {"arrows": "to", "from": "llada.eval_llada::get_loglikelihood", "to": "llada.eval_llada::get_logits"}, {"arrows": "to", "from": "llada.eval_llada::suffix_greedy_prediction", "to": "llada.eval_llada::get_logits"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "llada.eval_llada::_encode_pair"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "llada.eval_llada::get_loglikelihood"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "llada.eval_llada::suffix_greedy_prediction"}, {"arrows": "to", "from": "llada.eval_llada::_tokenize", "to": "llada.eval_llada::_encode_pair"}, {"arrows": "to", "from": "llada.generate::add_gumbel_noise", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "llada.generate::generate", "to": "llada.generate::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.generate::generate", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::add_gumbel_noise"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::get_transfer_index", "to": "llada.generate::add_gumbel_noise"}, {"arrows": "to", "from": "llada.generate::get_transfer_index_dynamic", "to": "llada.generate::add_gumbel_noise"}, {"arrows": "to", "from": "llada.generate::main", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.generate::main", "to": "llada.generate::generate_with_dual_cache"}, {"arrows": "to", "from": "llada.generate::main", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.chat::chat", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.chat::chat", "to": "llada.generate::generate"}, {"arrows": "to", "from": "llada.chat::chat", "to": "llada.generate::generate_with_dual_cache"}, {"arrows": "to", "from": "llada.chat::chat", "to": "llada.generate::generate_with_prefix_cache"}, {"arrows": "to", "from": "llada.chat::chat", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.app::add_gumbel_noise", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::get_transfer_index"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::add_gumbel_noise"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::get_transfer_index"}, {"arrows": "to", "from": "llada.app::get_transfer_index", "to": "llada.app::add_gumbel_noise"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization", "to": "llada.app::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization", "to": "llada.app::add_gumbel_noise"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::add_message", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::format_chat_history"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::parse_constraints"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::generate_response_with_visualization"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::generate_response_with_visualization_cache_and_parallel"}, {"arrows": "to", "from": "llada.sanitize::extract_longest_valid_code", "to": "llada.sanitize::syntax_check"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::refine_text"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::extract_longest_valid_code"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::get_deps"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::get_function_dependency"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::has_return_statement"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::get_definition_name"}, {"arrows": "to", "from": "llada.model.modeling_llada::_non_meta_init_device", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.model.modeling_llada::_non_meta_init_device", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::LayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::LayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::RMSLayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::GemmaRMSLayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNorm", "to": "llada.model.modeling_llada::_cast_if_autocast_enabled"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNorm", "to": "llada.model.modeling_llada::_cast_if_autocast_enabled"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNorm", "to": "llada.model.modeling_llada::_cast_if_autocast_enabled"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::get_rotary_embedding"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::_non_meta_init_device"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::get_rotary_embedding"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::apply_rotary_pos_emb"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::apply_rotary_pos_emb"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::GELU"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::ReLU"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::SiLU"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::SwiGLU"}, {"arrows": "to", "from": "llada.model.modeling_llada::get_causal_attention_bias", "to": "llada.model.modeling_llada::causal_attention_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::Dropout"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::_scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::RotaryEmbedding"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::activation_checkpoint_function"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::ensure_finite_"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDASequentialBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDASequentialBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDASequentialBlock", "to": "llada.model.modeling_llada::attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockGroup", "to": "llada.model.modeling_llada::activation_checkpoint_function"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::BufferCache"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::activation_checkpoint_function"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::LLaDAOutput"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::get_causal_attention_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::get_alibi_attention_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::_non_meta_init_device"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::create_model_config_from_pretrained_config", "to": "llada.model.configuration_llada::ModelConfig"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModelLM", "to": "llada.model.modeling_llada::create_model_config_from_pretrained_config"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModelLM", "to": "llada.model.modeling_llada::LLaDAModel"}, {"arrows": "to", "from": "llada.model.modeling_llada::__init__", "to": "llada.model.modeling_llada::create_model_config_from_pretrained_config"}, {"arrows": "to", "from": "llada.model.modeling_llada::__init__", "to": "llada.model.modeling_llada::LLaDAModel"}, {"arrows": "to", "from": "llada.model.modeling_llada::build", "to": "llada.model.modeling_llada::LLaDASequentialBlock"}, {"arrows": "to", "from": "llada.model.modeling_llada::build", "to": "llada.model.modeling_llada::LLaDALlamaBlock"}, {"arrows": "to", "from": "llada.model.modeling_llada::reset_parameters", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::reset_parameters", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::reset_parameters", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::apply_rotary_pos_emb", "to": "llada.model.modeling_llada::rotate_half"}, {"arrows": "to", "from": "llada.model.modeling_llada::_cast_attn_bias", "to": "llada.model.modeling_llada::ensure_finite_"}, {"arrows": "to", "from": "llada.model.modeling_llada::_scaled_dot_product_attention", "to": "llada.model.modeling_llada::scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::attention", "to": "llada.model.modeling_llada::_scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::attention", "to": "llada.model.modeling_llada::_cast_attn_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::device", "to": "llada.model.modeling_llada::_non_meta_init_device"}, {"arrows": "to", "from": "llada.model.modeling_llada::get_alibi_attention_bias", "to": "llada.model.modeling_llada::alibi_attention_bias"}, {"arrows": "to", "from": "llada.model.configuration_llada::LLaDAConfig", "to": "llada.model.configuration_llada::ModelConfig"}, {"arrows": "to", "from": "llada.model.configuration_llada::LLaDAConfig", "to": "llada.model.configuration_llada::__init__"}, {"arrows": "to", "from": "llada.model.configuration_llada::__init__", "to": "llada.model.configuration_llada::ModelConfig"}, {"arrows": "to", "from": "dream.demo_multiturn_chat::generation_tokens_hook_func", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.eval::__init__"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.eval::_create_model_and_tokenizer"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.eval::apply_chat_template"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::_create_model_and_tokenizer"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::_create_model_and_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.eval::_create_model_and_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.eval::tok_decode", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::_generate_batch", "to": "dream.eval::apply_chat_template"}, {"arrows": "to", "from": "dream.eval::_generate_batch", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::generate_until", "to": "dream.eval::_generate_batch"}, {"arrows": "to", "from": "dream.eval::_eval_target_nll_mc", "to": "dream.eval::_forward_process"}, {"arrows": "to", "from": "dream.eval::_eval_target_nll_mc", "to": "dream.eval::get_logits"}, {"arrows": "to", "from": "dream.eval::_eval_target_nll_ar", "to": "dream.eval::get_logits"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "dream.eval::_encode_pair"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "dream.eval::_eval_target_nll_mc"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "dream.eval::_eval_target_nll_ar"}, {"arrows": "to", "from": "dream.eval::_tokenize", "to": "dream.eval::_encode_pair"}, {"arrows": "to", "from": "dream.sanitize::extract_longest_valid_code", "to": "dream.sanitize::syntax_check"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::refine_text"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::extract_longest_valid_code"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::get_deps"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::get_function_dependency"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::has_return_statement"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::get_definition_name"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamRotaryEmbedding", "to": "dream.model.modeling_dream::_dynamic_frequency_update"}, {"arrows": "to", "from": "dream.model.modeling_dream::apply_rotary_pos_emb", "to": "dream.model.modeling_dream::rotate_half"}, {"arrows": "to", "from": "dream.model.modeling_dream::apply_rotary_pos_emb", "to": "dream.model.modeling_dream::rotate_half"}, {"arrows": "to", "from": "dream.model.modeling_dream::apply_rotary_pos_emb", "to": "dream.model.modeling_dream::rotate_half"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::DreamRotaryEmbedding"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::apply_rotary_pos_emb"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "llada.model.modeling_llada::scaled_dot_product_attention"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::apply_rotary_pos_emb"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::apply_rotary_pos_emb"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamSdpaAttention"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamMLP"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamRMSNorm"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamRMSNorm"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamPreTrainedModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamPreTrainedModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::DreamRMSNorm"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::DreamRotaryEmbedding"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::BaseModelOutputWithPast"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::DreamDecoderLayer"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::DreamBaseModel"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::MaskedLMOutputWithPastKeyValues"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.modeling_dream::__init__", "to": "dream.model.modeling_dream::DreamBaseModel"}, {"arrows": "to", "from": "dream.model.modeling_dream::forward", "to": "dream.model.modeling_dream::MaskedLMOutputWithPastKeyValues"}, {"arrows": "to", "from": "dream.model.modeling_dream::reset_rope_parameters", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.modeling_dream::reset_rope_parameters", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.generation_utils::sample_tokens", "to": "dream.model.generation_utils::top_p_logits"}, {"arrows": "to", "from": "dream.model.generation_utils::sample_tokens", "to": "dream.model.generation_utils::top_k_logits"}, {"arrows": "to", "from": "dream.model.generation_utils::sample_tokens", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationConfig", "to": "dream.model.generation_utils::validate"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.demo_multiturn_chat::generation_tokens_hook_func"}, {"arrows": "to", "from": "dream.model.generation_utils::__init__", "to": "dream.model.generation_utils::validate"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_generated_length", "to": "dream.model.generation_utils::DreamGenerationConfig"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.demo_multiturn_chat::generation_tokens_hook_func"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.demo_multiturn_chat::generation_tokens_hook_func"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.model.generation_utils::DreamModelOutput"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.model.generation_utils::sample_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.model.generation_utils::sample_tokens"}, {"arrows": "to", "from": "dream.model.tokenization_dream::bytes_to_unicode", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::bytes_to_unicode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::__init__"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::get_pairs"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::__init__", "to": "dream.model.tokenization_dream::bytes_to_unicode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::get_vocab", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::bpe", "to": "dream.model.tokenization_dream::get_pairs"}, {"arrows": "to", "from": "dream.model.tokenization_dream::bpe", "to": "dream.model.tokenization_dream::get_pairs"}, {"arrows": "to", "from": "dream.model.tokenization_dream::_tokenize", "to": "dream.model.tokenization_dream::bpe"}, {"arrows": "to", "from": "dream.model.tokenization_dream::convert_tokens_to_string", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.model.generation_utils_block::sample_tokens", "to": "dream.model.generation_utils_block::top_p_logits"}, {"arrows": "to", "from": "dream.model.generation_utils_block::sample_tokens", "to": "dream.model.generation_utils_block::top_k_logits"}, {"arrows": "to", "from": "dream.model.generation_utils_block::sample_tokens", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationConfig", "to": "dream.model.generation_utils_block::validate"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils_block::__init__", "to": "dream.model.generation_utils_block::validate"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_generated_length", "to": "dream.model.generation_utils_block::DreamGenerationConfig"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::sample_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::DreamModelOutput"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::sample_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::sample_tokens"}, {"arrows": "to", "from": "dream.model.configuration_dream::DreamConfig", "to": "dream.model.configuration_dream::__init__"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"physics": {"enabled": false}, "interaction": {"dragNodes": true, "navigationButtons": true, "multiselect": true}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>