{
  "repo": {
    "full_name": "FoundationAgents/MetaGPT",
    "stars": 59151,
    "forks": 7184,
    "language": "Python",
    "description": "ðŸŒŸ The Multi-Agent Framework: First AI Software Company, Towards Natural Language Programming",
    "topics": [
      "agent",
      "gpt",
      "llm",
      "metagpt",
      "multi-agent"
    ],
    "url": "https://github.com/FoundationAgents/MetaGPT",
    "created_at": "2023-06-30T09:04:55Z",
    "updated_at": "2025-10-31T03:21:41Z"
  },
  "readme_file": "dataset/readmes/MetaGPT_README.md",
  "task_file": "dataset/tasks/MetaGPT_tasks.json",
  "num_tasks": 1,
  "num_setup_commands": 1,
  "num_docker_commands": 0,
  "has_docker_files": true,
  "docker_files_list": [
    "Dockerfile",
    ".dockerignore"
  ],
  "docker_setup_descriptions": {
    "Dockerfile": "To build and run the Docker image for the FoundationAgents/MetaGPT repository, follow these steps:\n\n### Purpose of the Image\nThe Docker image is designed to provide an environment for running MetaGPT, a project that likely involves machine learning or natural language processing tasks. The image includes essential dependencies such as Python 3.9 and Node.js 20, along with libraries and tools necessary for the project to function correctly.\n\n### Building the Image\n1. **Base Image**: The build process starts with a lightweight base image that includes both Python 3.9 and Node.js 20. This ensures that the environment is suitable for running applications that require both programming languages.\n\n2. **Install System Dependencies**: The image installs several Debian packages that are critical for the operation of MetaGPT. This includes libraries for handling fonts, Chromium for rendering, and Git for version control. The installation is performed in a single command to minimize the final image size by cleaning up unnecessary files afterward.\n\n3. **Install Mermaid CLI**: The Mermaid CLI is installed globally using npm. This tool is likely used for generating diagrams and visualizations, which can be an integral part of the MetaGPT project. The installation process also includes cleaning the npm cache to further reduce the image size.\n\n4. **Copy Project Files**: The contents of the repository are copied into the image, specifically into the `/app/metagpt` directory. This step ensures that all necessary project files are available within the container.\n\n5. **Install Python Dependencies**: The image sets the working directory to where the project files are located and installs the required Python packages listed in the `requirements.txt` file. Additionally, the project itself is installed in editable mode, allowing for easy modifications during development.\n\n6. **Final Command**: The image is configured to run indefinitely using a command that keeps the container alive. This is useful for debugging or for running the application in a controlled environment.\n\n### Running the Image\nAfter building the image, you can run it using Docker. The container will start and remain active, allowing you to interact with it or execute further commands as needed.\n\n### Summary\nIn summary, this Docker image provides a robust environment for the MetaGPT project, bundling together necessary programming languages, libraries, and tools while maintaining a small footprint. Follow the standard Docker commands to build and run the image, ensuring you have Docker installed and configured on your machine.",
    ".dockerignore": "To build and run a Docker image for the FoundationAgents/MetaGPT repository, follow these steps:\n\n### Purpose of the Docker Image\nThe Docker image is designed to encapsulate the MetaGPT application, which serves as a foundation for building and deploying generative pre-trained transformers. The image includes all necessary dependencies, configurations, and runtime environments required to ensure the application operates seamlessly in a containerized environment.\n\n### Building Steps\n\n1. **Prepare the Environment**: Ensure that Docker is installed on your machine. You should also have access to the FoundationAgents/MetaGPT repository.\n\n2. **Create a .dockerignore File**: This file is crucial as it specifies which files and directories should be excluded from the Docker build context. For this repository, the .dockerignore file includes entries such as `workspace`, `tmp`, `build`, `dist`, `data`, and `geckodriver.log`. This helps to reduce the image size and build time by omitting unnecessary files.\n\n3. **Build the Docker Image**: Navigate to the root directory of the repository in your terminal. Use the Docker build command to create the image. The build process will read the Dockerfile and .dockerignore file, incorporating only the relevant files and dependencies into the image.\n\n4. **Dependencies**: The image will typically include essential libraries and tools required for running the MetaGPT application, such as Python, necessary Python packages (like TensorFlow or PyTorch), and any other dependencies specified in the project documentation.\n\n5. **Run the Docker Container**: Once the image is built, you can run it as a container. This step involves specifying the necessary environment variables, port mappings, and any volume mounts required for persistent data storage or configuration.\n\n### Final Notes\nAfter successfully running the container, you should be able to access the MetaGPT application via the specified ports. Ensure to consult the repository's README for any specific commands or configurations that may be necessary for optimal operation."
  },
  "processed_at": "2025-10-30T23:38:52.792391"
}