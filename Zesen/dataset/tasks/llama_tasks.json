{
  "tasks": [
    {
      "task_title": "聊天完成任务",
      "task_description": "该任务使用预训练的Llama模型进行聊天完成。通过指定检查点目录、分词器路径、最大序列长度和批量大小来进行配置。",
      "example_code": null,
      "running_command": "torchrun --nproc_per_node 1 example_chat_completion.py --ckpt_dir llama-2-7b-chat/ --tokenizer_path tokenizer.model --max_seq_len 512 --max_batch_size 6",
      "expected_input": "用户输入的聊天文本",
      "expected_output": "模型生成的聊天回复"
    }
  ],
  "setup": {
    "setup_commands": [
      "    pip install -e ."
    ],
    "docker_commands": [],
    "docker_files": {},
    "docker_setup_descriptions": null
  },
  "input_to_gpt": {
    "repo_name": "meta-llama/llama",
    "num_code_blocks": 1,
    "total_length": 170,
    "code_blocks": [
      "torchrun --nproc_per_node 1 example_chat_completion.py \\\n    --ckpt_dir llama-2-7b-chat/ \\\n    --tokenizer_path tokenizer.model \\\n    --max_seq_len 512 --max_batch_size 6"
    ]
  }
}