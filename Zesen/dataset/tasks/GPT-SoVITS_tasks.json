{
  "tasks": [
    {
      "task_title": "音频切片",
      "task_description": "该任务用于将原始音频文件或目录中的音频分割成多个子片段，基于音量阈值、最小长度和间隔等参数进行切割。",
      "example_code": null,
      "running_command": "python audio_slicer.py",
      "expected_input": "<path_to_original_audio_file_or_directory>, <directory_where_subdivided_audio_clips_will_be_saved>, <volume_threshold>, <minimum_duration_of_each_subclip>, <shortest_time_gap_between_adjacent_subclips>, <step_size_for_computing_volume_curve>",
      "expected_output": "切割后的音频片段将保存在指定目录中"
    },
    {
      "task_title": "语音识别（FunASR）",
      "task_description": "该任务用于对输入音频进行语音识别，输出识别结果。",
      "example_code": null,
      "running_command": "python tools/asr/funasr_asr.py",
      "expected_input": "<input>, <output>",
      "expected_output": "识别的文本结果"
    },
    {
      "task_title": "语音识别（FasterWhisper）",
      "task_description": "该任务用于对输入音频进行语音识别，支持指定语言和精度设置，输出识别结果。",
      "example_code": null,
      "running_command": "python ./tools/asr/fasterwhisper_asr.py",
      "expected_input": "<input>, <output>, <language>, <precision>",
      "expected_output": "识别的文本结果"
    }
  ],
  "setup": {
    "setup_commands": [],
    "docker_commands": [],
    "docker_files": {
      "Dockerfile": "ARG CUDA_VERSION=12.6\nARG TORCH_BASE=full\n\nFROM xxxxrt666/torch-base:cu${CUDA_VERSION}-${TORCH_BASE}\n\nLABEL maintainer=\"XXXXRT\"\nLABEL version=\"V4\"\nLABEL description=\"Docker image for GPT-SoVITS\"\n\nARG CUDA_VERSION=12.6\n\nENV CUDA_VERSION=${CUDA_VERSION}\n\nSHELL [\"/bin/bash\", \"-c\"]\n\nWORKDIR /workspace/GPT-SoVITS\n\nCOPY Docker /workspace/GPT-SoVITS/Docker/\n\nARG LITE=false\nENV LITE=${LITE}\n\nARG WORKFLOW=false\nENV WORKFLOW=${WORKFLOW}\n\nARG TARGETPLATFORM\nENV TARGETPLATFORM=${TARGETPLATFORM}\n\nRUN bash Docker/miniconda_install.sh\n\nCOPY extra-req.txt /workspace/GPT-SoVITS/\n\nCOPY requirements.txt /workspace/GPT-SoVITS/\n\nCOPY install.sh /workspace/GPT-SoVITS/\n\nRUN bash Docker/install_wrapper.sh\n\nEXPOSE 9871 9872 9873 9874 9880\n\nENV PYTHONPATH=\"/workspace/GPT-SoVITS\"\n\nRUN conda init bash && echo \"conda activate base\" >> ~/.bashrc\n\nWORKDIR /workspace\n\nRUN rm -rf /workspace/GPT-SoVITS\n\nWORKDIR /workspace/GPT-SoVITS\n\nCOPY . /workspace/GPT-SoVITS\n\nCMD [\"/bin/bash\", \"-c\", \"\\\n  rm -rf /workspace/GPT-SoVITS/GPT_SoVITS/pretrained_models && \\\n  rm -rf /workspace/GPT-SoVITS/GPT_SoVITS/text/G2PWModel && \\\n  rm -rf /workspace/GPT-SoVITS/tools/asr/models && \\\n  rm -rf /workspace/GPT-SoVITS/tools/uvr5/uvr5_weights && \\\n  ln -s /workspace/models/pretrained_models /workspace/GPT-SoVITS/GPT_SoVITS/pretrained_models && \\\n  ln -s /workspace/models/G2PWModel /workspace/GPT-SoVITS/GPT_SoVITS/text/G2PWModel && \\\n  ln -s /workspace/models/asr_models /workspace/GPT-SoVITS/tools/asr/models && \\\n  ln -s /workspace/models/uvr5_weights /workspace/GPT-SoVITS/tools/uvr5/uvr5_weights && \\\n  exec bash\"]",
      "docker-compose.yaml": "version: \"3.8\"\n\nservices:\n  GPT-SoVITS-CU126:\n    image: xxxxrt666/gpt-sovits:latest-cu126\n    container_name: GPT-SoVITS-CU126\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia\n  GPT-SoVITS-CU126-Lite:\n    image: xxxxrt666/gpt-sovits:latest-cu126-lite\n    container_name: GPT-SoVITS-CU126-Lite\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n      - tools/asr/models:/workspace/models/asr_models\n      - tools/uvr5/uvr5_weights:/workspace/models/uvr5_weights\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia\n  GPT-SoVITS-CU128:\n    image: xxxxrt666/gpt-sovits:latest-cu128\n    container_name: GPT-SoVITS-CU128\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia\n  GPT-SoVITS-CU128-Lite:\n    image: xxxxrt666/gpt-sovits:latest-cu128-lite\n    container_name: GPT-SoVITS-CU128-Lite\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n      - tools/asr/models:/workspace/models/asr_models\n      - tools/uvr5/uvr5_weights:/workspace/models/uvr5_weights\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia",
      ".dockerignore": "GPT_SoVITS/pretrained_models/*\ntools/asr/models/*\ntools/uvr5/uvr5_weights/*\n\n.git\n.DS_Store\n.vscode\n*.pyc\nenv\nruntime\n.idea\noutput\nlogs\nSoVITS_weights*/\nGPT_weights*/\nTEMP\nweight.json\nffmpeg*\nffprobe*\ncfg.json\nspeakers.json\nref_audios\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n**/__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\nPipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\nuv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\npoetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control\n.pdm.toml\n.pdm-python\n.pdm-build/\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n.idea/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n"
    },
    "docker_setup_descriptions": {
      "Dockerfile": "To build and run the Docker image for the GPT-SoVITS project from the RVC-Boss repository, follow these steps:\n\n### Purpose of the Image\nThe Docker image is designed to provide a consistent and isolated environment for running the GPT-SoVITS application, which is likely focused on voice synthesis or similar tasks. It includes necessary dependencies and configurations to ensure that the application runs smoothly.\n\n### Building Steps\n\n1. **Set Up Docker Environment**: Ensure that Docker is installed and running on your machine. You can verify this by running `docker --version` in your terminal.\n\n2. **Clone the Repository**: Clone the RVC-Boss/GPT-SoVITS repository to your local machine using Git:\n   ```bash\n   git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n   cd GPT-SoVITS\n   ```\n\n3. **Build the Docker Image**:\n   - Use the Docker command to build the image, specifying the Dockerfile located in the cloned repository. The image will be built with the necessary dependencies, including a specific version of CUDA and a base PyTorch environment.\n   - The image will also install Miniconda and additional Python packages required for the application, as specified in the `requirements.txt` and `extra-req.txt` files.\n\n4. **Image Dependencies**: The image relies on:\n   - A CUDA-enabled base image to leverage GPU acceleration.\n   - Miniconda for managing Python environments and dependencies.\n   - Various Python libraries necessary for the GPT-SoVITS application, which are defined in the `requirements.txt` file.\n\n5. **Expose Ports**: The image exposes several ports (9871, 9872, 9873, 9874, 9880) for communication, likely for serving the application or accessing its API.\n\n### Running the Docker Container\n\n1. **Run the Container**: After building the image, you can run it using the following command:\n   ```bash\n   docker run -it --rm -p 9871:9871 -p 9872:9872 -p 9873:9873 -p 9874:9874 -p 9880:9880 <image_name>\n   ```\n   Replace `<image_name>` with the name you assigned to the built image.\n\n2. **Environment Variables**: The container can be customized at runtime using environment variables such as `LITE` and `WORKFLOW`, which can be set to `true` or `false` depending on your needs.\n\n3. **Accessing the Application**: Once the container is running, you can access the application through the exposed ports using a web browser or API client.\n\n### Cleanup\nAfter you are done using the container, it will automatically be removed due to the `--rm` flag, keeping your environment clean.\n\nBy following these steps, you will successfully build and run the Docker image for the GPT-SoVITS project, enabling you to utilize its features in a controlled environment.",
      "docker-compose.yaml": "To build and run Docker containers using the `docker-compose.yaml` file from the RVC-Boss/GPT-SoVITS repository, follow these steps:\n\n### Purpose of the Docker Images\nThe Docker images defined in the `docker-compose.yaml` file are designed to facilitate the deployment of the GPT-SoVITS models, which are used for voice synthesis and transformation tasks. These images come in different versions optimized for various CUDA environments (CU126 and CU128) and include both standard and lightweight variants. The lightweight versions are tailored for lower resource usage while still providing essential functionalities.\n\n### Dependencies\nThe images rely on NVIDIA GPU support, which means they require the NVIDIA Container Toolkit to be installed on your host machine. Additionally, they utilize shared memory configurations and specific environment variables to optimize performance during model inference.\n\n### Building and Running Steps\n\n1. **Install Docker and Docker Compose**: Ensure that Docker and Docker Compose are installed on your machine. You can download them from the official Docker website.\n\n2. **Set Up NVIDIA Support**: If you haven't already, install the NVIDIA Container Toolkit to enable GPU support in your Docker containers. This is crucial for running the GPT-SoVITS models efficiently.\n\n3. **Clone the Repository**: Clone the RVC-Boss/GPT-SoVITS repository to your local machine using Git:\n   ```bash\n   git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n   cd GPT-SoVITS\n   ```\n\n4. **Configure Environment Variables**: If needed, adjust any environment variables in the `docker-compose.yaml` file to suit your specific requirements. The `is_half=true` setting indicates that the models will use half-precision for improved performance.\n\n5. **Build the Docker Images**: Navigate to the directory containing the `docker-compose.yaml` file and run the following command to build the images:\n   ```bash\n   docker-compose build\n   ```\n   This command will create the necessary Docker images based on the configurations specified in the `docker-compose.yaml` file.\n\n6. **Run the Docker Containers**: After the build process completes, start the containers using:\n   ```bash\n   docker-compose up -d\n   ```\n   The `-d` flag runs the containers in detached mode, allowing them to run in the background.\n\n7. **Access the Services**: The services will be accessible through the specified ports (9871 to 9880). You can interact with the models via these ports as per your application needs.\n\n8. **Monitor and Manage Containers**: Use Docker commands like `docker ps` to monitor running containers and `docker-compose logs` to view logs for troubleshooting.\n\n9. **Stopping the Containers**: When you are done, you can stop the containers with:\n   ```bash\n   docker-compose down\n   ```\n\nBy following these steps, you will successfully build and run the Docker containers for the GPT-SoVITS models, enabling you to leverage their capabilities for voice synthesis tasks.",
      ".dockerignore": "To build and run a Docker image for the RVC-Boss/GPT-SoVITS repository, follow these steps:\n\n### Purpose of the Image\nThe Docker image is designed to encapsulate the environment needed for running the GPT-SoVITS model, which is used for voice synthesis and transformation tasks. This image includes all necessary dependencies, libraries, and tools required to operate the model effectively.\n\n### Dependencies\nThe image typically includes:\n- Python and relevant libraries for machine learning and audio processing.\n- Tools for handling audio files, such as FFmpeg.\n- Pre-trained models and weights necessary for the voice synthesis tasks.\n\n### Building Steps\n1. **Clone the Repository**: Start by cloning the RVC-Boss/GPT-SoVITS repository to your local machine.\n\n2. **Create a `.dockerignore` File**: Ensure that the `.dockerignore` file is present in the root of your repository. This file is crucial as it specifies which files and directories should be excluded from the Docker build context, helping to keep the image lightweight and free from unnecessary files.\n\n3. **Prepare the Dockerfile**: While the exact content of the Dockerfile is not disclosed, ensure it is set up to:\n   - Use an appropriate base image (e.g., a Python image).\n   - Install required system packages and Python dependencies as defined in your project.\n   - Copy only the necessary files from your project into the image, excluding those specified in the `.dockerignore`.\n\n4. **Build the Docker Image**: Use the Docker command to build the image. This process will read the Dockerfile, install dependencies, and package your application into a single image.\n\n5. **Run the Docker Container**: Once the image is built, you can run a container from it. Ensure you pass any necessary environment variables or volume mounts to access data or configuration files required by the application.\n\n### Running the Image\nAfter building the image, you can run it using Docker commands. Make sure to specify any ports that need to be exposed and any configurations that the application requires to function correctly.\n\n### Conclusion\nBy following these steps, you will successfully build and run the Docker image for the RVC-Boss/GPT-SoVITS project, allowing you to leverage the capabilities of the GPT-SoVITS model in a contained environment."
    }
  },
  "input_to_gpt": {
    "repo_name": "RVC-Boss/GPT-SoVITS",
    "num_code_blocks": 3,
    "total_length": 533,
    "code_blocks": [
      "python audio_slicer.py \\\n    --input_path \"<path_to_original_audio_file_or_directory>\" \\\n    --output_root \"<directory_where_subdivided_audio_clips_will_be_saved>\" \\\n    --threshold <volume_threshold> \\\n    --min_length <minimum_duration_of_each_subclip> \\\n    --min_interval <shortest_time_gap_between_adjacent_subclips>\n    --hop_size <step_size_for_computing_volume_curve>",
      "python tools/asr/funasr_asr.py -i <input> -o <output>",
      "python ./tools/asr/fasterwhisper_asr.py -i <input> -o <output> -l <language> -p <precision>"
    ]
  }
}