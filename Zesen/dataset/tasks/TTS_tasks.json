{
  "tasks": [
    {
      "task_title": "List available TTS models",
      "task_description": "åˆ—å‡ºå¯ç”¨çš„æ–‡æœ¬åˆ°è¯­éŸ³æ¨¡å‹ã€‚",
      "example_code": "print(TTS().list_models())",
      "running_command": null,
      "expected_input": null,
      "expected_output": "['model1', 'model2', ...]"
    },
    {
      "task_title": "Run TTS with multilingual voice cloning",
      "task_description": "ä½¿ç”¨å¤šè¯­è¨€è¯­éŸ³å…‹éš†æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼Œå¹¶è¾“å‡ºä¸ºéŸ³é¢‘æ³¢å½¢ã€‚",
      "example_code": "wav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")",
      "running_command": null,
      "expected_input": {
        "text": "Hello world!",
        "speaker_wav": "my/cloning/audio.wav",
        "language": "en"
      },
      "expected_output": "éŸ³é¢‘æ³¢å½¢æ•°æ®"
    },
    {
      "task_title": "Run TTS and save output to file",
      "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶ä¸­ã€‚",
      "example_code": "tts.tts_to_file(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": {
        "text": "Hello world!",
        "speaker_wav": "my/cloning/audio.wav",
        "language": "en",
        "file_path": "output.wav"
      },
      "expected_output": "éŸ³é¢‘æ–‡ä»¶ output.wav"
    },
    {
      "task_title": "Voice cloning in multiple languages",
      "task_description": "ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹è¿›è¡Œè¯­éŸ³å…‹éš†ï¼Œå°†ä¸åŒè¯­è¨€çš„æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³å¹¶ä¿å­˜åˆ°æ–‡ä»¶ã€‚",
      "example_code": "tts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": {
        "text": "C'est le clonage de la voix.",
        "speaker_wav": "my/cloning/audio.wav",
        "language": "fr-fr",
        "file_path": "output.wav"
      },
      "expected_output": "éŸ³é¢‘æ–‡ä»¶ output.wav"
    },
    {
      "task_title": "Voice conversion",
      "task_description": "å°†æºéŸ³é¢‘çš„å£°éŸ³è½¬æ¢ä¸ºç›®æ ‡éŸ³é¢‘çš„å£°éŸ³ï¼Œå¹¶ä¿å­˜åˆ°æ–‡ä»¶ã€‚",
      "example_code": "tts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": {
        "source_wav": "my/source.wav",
        "target_wav": "my/target.wav",
        "file_path": "output.wav"
      },
      "expected_output": "éŸ³é¢‘æ–‡ä»¶ output.wav"
    },
    {
      "task_title": "Text-to-speech with voice conversion",
      "task_description": "å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³ï¼ŒåŒæ—¶è¿›è¡Œå£°éŸ³è½¬æ¢ï¼Œå¹¶ä¿å­˜åˆ°æ–‡ä»¶ã€‚",
      "example_code": "tts.tts_with_vc_to_file(\"Wie sage ich auf Italienisch, dass ich dich liebe?\", speaker_wav=\"target/speaker.wav\", file_path=\"output.wav\")",
      "running_command": null,
      "expected_input": {
        "text": "Wie sage ich auf Italienisch, dass ich dich liebe?",
        "speaker_wav": "target/speaker.wav",
        "file_path": "output.wav"
      },
      "expected_output": "éŸ³é¢‘æ–‡ä»¶ output.wav"
    }
  ],
  "setup": {
    "setup_commands": [
      "pip install TTS",
      "git clone https://github.com/coqui-ai/TTS\npip install -e .[all,dev,notebooks]  # Select the relevant extras"
    ],
    "docker_commands": [
      "docker run --rm -it -p 5002:5002 --entrypoint /bin/bash ghcr.io/coqui-ai/tts-cpu\npython3 TTS/server/server.py --list_models #To get the list of available models\npython3 TTS/server/server.py --model_name tts_models/en/vctk/vits # To start a server"
    ],
    "docker_files": {
      "Dockerfile": "ARG BASE=nvidia/cuda:11.8.0-base-ubuntu22.04\nFROM ${BASE}\n\nRUN apt-get update && apt-get upgrade -y\nRUN apt-get install -y --no-install-recommends gcc g++ make python3 python3-dev python3-pip python3-venv python3-wheel espeak-ng libsndfile1-dev && rm -rf /var/lib/apt/lists/*\nRUN pip3 install llvmlite --ignore-installed\n\n# Install Dependencies:\nRUN pip3 install torch torchaudio --extra-index-url https://download.pytorch.org/whl/cu118\nRUN rm -rf /root/.cache/pip\n\n# Copy TTS repository contents:\nWORKDIR /root\nCOPY . /root\n\nRUN make install\n\nENTRYPOINT [\"tts\"]\nCMD [\"--help\"]\n",
      ".dockerignore": ".git/\nDockerfile\nbuild/\ndist/\nTTS.egg-info/\ntests/outputs/*\ntests/train_outputs/*\n__pycache__/\n*.pyc"
    },
    "docker_setup_descriptions": {
      "Dockerfile": "To build and run a Docker image using the \"Dockerfile\" from the coqui-ai/TTS repository, follow these steps:\n\n### Purpose of the Image\nThe Docker image is designed to provide an isolated environment for running the Coqui TTS (Text-to-Speech) system. It includes all necessary dependencies to ensure that the TTS models can be executed efficiently, leveraging GPU capabilities with CUDA support.\n\n### Building the Image\n1. **Base Image**: The build process starts with a base image that includes NVIDIA's CUDA toolkit, specifically tailored for Ubuntu 22.04. This ensures that the image can utilize GPU acceleration for deep learning tasks.\n\n2. **System Dependencies**: The image installs essential system packages, including compilers (gcc, g++), Python 3, and various development libraries. These are crucial for building and running the TTS application and its dependencies.\n\n3. **Python Dependencies**: The image installs Python packages required for the TTS system, including PyTorch and Torchaudio, which are fundamental for handling audio processing and model inference. The installation is optimized for CUDA 11.8 to ensure compatibility with the base image.\n\n4. **Repository Setup**: The contents of the TTS repository are copied into the image, setting the working directory to facilitate access to the application files.\n\n5. **Installation**: The final step involves running a make command to install the TTS application, ensuring that all components are correctly set up within the Docker environment.\n\n### Running the Image\nOnce the image is built, you can run it using Docker. The entry point is set to the TTS command-line interface, allowing you to interact with the application directly. \n\n- To start a bash shell within the container for interactive use, you can override the entry point.\n- You can list available TTS models by executing a specific Python script within the container.\n- To start the TTS server with a specified model, you can run the server script with the desired model name.\n\n### Summary\nThis Docker image encapsulates the Coqui TTS system, providing a ready-to-use environment with all necessary dependencies for text-to-speech tasks. By following the outlined steps, you can build and run the image effectively, enabling you to leverage advanced TTS capabilities in your applications.",
      ".dockerignore": "To build and run a Docker image for the Coqui AI Text-to-Speech (TTS) project, follow these steps:\n\n### Purpose of the Image\nThe Docker image is designed to provide a consistent environment for running the Coqui AI TTS server. It encapsulates all necessary dependencies, including Python libraries and system packages required for text-to-speech synthesis. This allows developers and users to easily deploy the TTS service without worrying about local environment configurations.\n\n### Building the Image\n1. **Prepare Your Environment**: Ensure you have Docker installed on your machine. You should also have access to the Coqui AI TTS repository.\n\n2. **Create a .dockerignore File**: The `.dockerignore` file is crucial as it prevents unnecessary files and directories from being included in the Docker image. This includes version control files, build artifacts, test outputs, and Python cache files. By excluding these, you reduce the image size and improve build performance.\n\n3. **Build the Docker Image**: Use the Docker build command to create the image. This process will read the Dockerfile and the .dockerignore file to determine what to include in the image. The resulting image will contain all the necessary dependencies for running the TTS server.\n\n### Running the Image\n1. **Start the Docker Container**: Once the image is built, you can run it using the Docker run command. This command will start a new container from the image, mapping port 5002 on your host to port 5002 in the container, which is where the TTS server will listen for requests.\n\n2. **Access the Container**: You can enter the container's shell using the specified entry point. This allows you to interact with the environment directly.\n\n3. **List Available Models**: Inside the container, you can execute a command to list all available TTS models. This is useful for understanding what models you can use for text-to-speech synthesis.\n\n4. **Start the TTS Server**: Finally, you can start the TTS server by specifying a model name. This will initiate the service, allowing you to send text inputs for speech synthesis.\n\nBy following these steps, you will have a fully functional TTS server running in a Docker container, ready to process text and generate speech outputs."
    }
  },
  "input_to_gpt": {
    "repo_name": "coqui-ai/TTS",
    "num_code_blocks": 6,
    "total_length": 2187,
    "code_blocks": [
      "$ make system-deps  # intended to be used on Ubuntu (Debian). Let us know if you have a different OS.\n$ make install",
      "import torch\nfrom TTS.api import TTS\n\n# Get device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# List available ğŸ¸TTS models\nprint(TTS().list_models())\n\n# Init TTS\ntts = TTS(\"tts_models/multilingual/multi-dataset/xtts_v2\").to(device)\n\n# Run TTS\n# â— Since this model is multi-lingual voice cloning model, we must set the target speaker_wav and language\n# Text to speech list of amplitude values as output\nwav = tts.tts(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\")\n# Text to speech to a file\ntts.tts_to_file(text=\"Hello world!\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")",
      "# Init TTS with the target model name\ntts = TTS(model_name=\"tts_models/de/thorsten/tacotron2-DDC\", progress_bar=False).to(device)\n\n# Run TTS\ntts.tts_to_file(text=\"Ich bin eine Testnachricht.\", file_path=OUTPUT_PATH)\n\n# Example voice cloning with YourTTS in English, French and Portuguese\ntts = TTS(model_name=\"tts_models/multilingual/multi-dataset/your_tts\", progress_bar=False).to(device)\ntts.tts_to_file(\"This is voice cloning.\", speaker_wav=\"my/cloning/audio.wav\", language=\"en\", file_path=\"output.wav\")\ntts.tts_to_file(\"C'est le clonage de la voix.\", speaker_wav=\"my/cloning/audio.wav\", language=\"fr-fr\", file_path=\"output.wav\")\ntts.tts_to_file(\"Isso Ã© clonagem de voz.\", speaker_wav=\"my/cloning/audio.wav\", language=\"pt-br\", file_path=\"output.wav\")",
      "tts = TTS(model_name=\"voice_conversion_models/multilingual/vctk/freevc24\", progress_bar=False).to(\"cuda\")\ntts.voice_conversion_to_file(source_wav=\"my/source.wav\", target_wav=\"my/target.wav\", file_path=\"output.wav\")",
      "\ntts = TTS(\"tts_models/de/thorsten/tacotron2-DDC\")\ntts.tts_with_vc_to_file(\n    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n    speaker_wav=\"target/speaker.wav\",\n    file_path=\"output.wav\"\n)",
      "# TTS with on the fly voice conversion\napi = TTS(\"tts_models/deu/fairseq/vits\")\napi.tts_with_vc_to_file(\n    \"Wie sage ich auf Italienisch, dass ich dich liebe?\",\n    speaker_wav=\"target/speaker.wav\",\n    file_path=\"output.wav\"\n)"
    ]
  }
}