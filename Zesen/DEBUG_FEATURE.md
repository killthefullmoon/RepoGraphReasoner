# ğŸ” è°ƒè¯•åŠŸèƒ½ - Debug Feature (v2.5)

## ğŸ“‹ æ¦‚è¿°

æ–°å¢ `input_to_gpt` å­—æ®µï¼Œç”¨äºè®°å½•å‘é€ç»™GPTçš„åŸå§‹è¾“å…¥ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œç›‘æ§ã€‚

---

## âœ¨ æ–°å¢å­—æ®µ

### `input_to_gpt` ç»“æ„

```json
{
  "input_to_gpt": {
    "repo_name": "owner/repo",
    "num_code_blocks": 5,
    "total_length": 2345,
    "code_blocks": [
      "ç¬¬ä¸€ä¸ªä»£ç å—å†…å®¹...",
      "ç¬¬äºŒä¸ªä»£ç å—å†…å®¹...",
      "ç¬¬ä¸‰ä¸ªä»£ç å—å†…å®¹..."
    ]
  }
}
```

### å­—æ®µè¯´æ˜

- **`repo_name`**: ä»“åº“åç§°
- **`num_code_blocks`**: å‘é€ç»™GPTçš„ä»£ç å—æ€»æ•°
- **`total_length`**: å‘é€ç»™GPTçš„æ–‡æœ¬æ€»é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
- **`code_blocks`**: å‰3ä¸ªä»£ç å—çš„å†…å®¹ï¼ˆç”¨äºå¿«é€ŸæŸ¥çœ‹ï¼‰

---

## ğŸ“‚ è¾“å‡ºä½ç½®

### 1. ä»»åŠ¡æ–‡ä»¶ (`tasks/*.json`)

```json
{
  "tasks": [...],
  "setup": {...},
  "input_to_gpt": {
    "repo_name": "huggingface/transformers",
    "num_code_blocks": 8,
    "total_length": 3456,
    "code_blocks": [
      "from transformers import pipeline\n...",
      "pipeline = pipeline('text-generation')\n...",
      "..."
    ]
  }
}
```

### 2. æ•°æ®é›†æ–‡ä»¶ (`dataset.jsonl`)

```json
{
  "repo_name": "huggingface/transformers",
  "tasks": [...],
  "setup": {...},
  "input_to_gpt": {
    "repo_name": "huggingface/transformers",
    "num_code_blocks": 8,
    "total_length": 3456,
    "code_blocks": [...]
  },
  "timestamp": "..."
}
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### 1. è°ƒè¯•GPTè¾“å‡ºè´¨é‡

```python
import json

# è¯»å–ä»»åŠ¡æ–‡ä»¶
with open('dataset/tasks/huggingface_transformers_tasks.json') as f:
    data = json.load(f)

# æŸ¥çœ‹å‘é€ç»™GPTçš„å†…å®¹
gpt_input = data['input_to_gpt']
print(f"å‘é€äº† {gpt_input['num_code_blocks']} ä¸ªä»£ç å—")
print(f"æ€»é•¿åº¦: {gpt_input['total_length']} å­—ç¬¦")
print("\nå‰3ä¸ªä»£ç å—:")
for i, block in enumerate(gpt_input['code_blocks'], 1):
    print(f"\nä»£ç å— {i}:")
    print(block[:200] + "..." if len(block) > 200 else block)
```

### 2. åˆ†æä»£ç å—æ•°é‡ä¸ä»»åŠ¡è´¨é‡çš„å…³ç³»

```python
import json

# è¯»å–dataset.jsonl
with open('dataset/dataset.jsonl') as f:
    repos = [json.loads(line) for line in f]

# åˆ†æ
for repo in repos:
    num_blocks = repo['input_to_gpt']['num_code_blocks']
    num_tasks = len(repo['tasks'])
    print(f"{repo['repo_name']}: {num_blocks} blocks â†’ {num_tasks} tasks")
```

### 3. æ£€æŸ¥æ˜¯å¦å‘é€äº†è¿‡å¤š/è¿‡å°‘çš„ä»£ç 

```python
import json

# è¯»å–æ•°æ®é›†
with open('dataset/dataset.jsonl') as f:
    repos = [json.loads(line) for line in f]

# æ£€æŸ¥å¼‚å¸¸æƒ…å†µ
for repo in repos:
    gpt_input = repo['input_to_gpt']
    
    # ä»£ç å—å¤ªå°‘
    if gpt_input['num_code_blocks'] < 2:
        print(f"âš ï¸ {repo['repo_name']}: åªæœ‰ {gpt_input['num_code_blocks']} ä¸ªä»£ç å—")
    
    # å†…å®¹å¤ªçŸ­
    if gpt_input['total_length'] < 500:
        print(f"âš ï¸ {repo['repo_name']}: å†…å®¹å¤ªçŸ­ ({gpt_input['total_length']} å­—ç¬¦)")
    
    # å†…å®¹è¢«æˆªæ–­
    if gpt_input['total_length'] >= 8000:
        print(f"âš ï¸ {repo['repo_name']}: å†…å®¹å¯èƒ½è¢«æˆªæ–­")
```

### 4. å¯¹æ¯”è¾“å…¥å’Œè¾“å‡º

```python
import json

with open('dataset/dataset.jsonl') as f:
    repo = json.loads(f.readline())

gpt_input = repo['input_to_gpt']
tasks = repo['tasks']

print(f"ä»“åº“: {repo['repo_name']}")
print(f"\nè¾“å…¥:")
print(f"  - ä»£ç å—æ•°: {gpt_input['num_code_blocks']}")
print(f"  - æ€»é•¿åº¦: {gpt_input['total_length']}")

print(f"\nè¾“å‡º:")
print(f"  - ä»»åŠ¡æ•°: {len(tasks)}")
for i, task in enumerate(tasks, 1):
    print(f"  - Task {i}: {task['task_title']}")
```

---

## ğŸ“Š å®é™…ç¤ºä¾‹

### ç¤ºä¾‹1: æŸ¥çœ‹å…·ä½“å‘é€çš„ä»£ç 

```bash
# æŸ¥çœ‹æŸä¸ªrepoå‘é€ç»™GPTçš„ä»£ç 
python -c "
import json
with open('dataset/tasks/fastapi_fastapi_tasks.json') as f:
    data = json.load(f)
    gpt_input = data['input_to_gpt']
    print(f'Repo: {gpt_input[\"repo_name\"]}')
    print(f'ä»£ç å—æ•°: {gpt_input[\"num_code_blocks\"]}')
    print(f'æ€»é•¿åº¦: {gpt_input[\"total_length\"]} å­—ç¬¦')
    print('\nå‰3ä¸ªä»£ç å—:')
    for i, block in enumerate(gpt_input['code_blocks'], 1):
        print(f'\n=== ä»£ç å— {i} ===')
        print(block)
"
```

**è¾“å‡ºç¤ºä¾‹**:
```
Repo: fastapi/fastapi
ä»£ç å—æ•°: 5
æ€»é•¿åº¦: 2345 å­—ç¬¦

å‰3ä¸ªä»£ç å—:

=== ä»£ç å— 1 ===
@app.get("/")
def read_root():
    return {"Hello": "World"}

=== ä»£ç å— 2 ===
@app.get("/items/{item_id}")
def read_item(item_id: int, q: Union[str, None] = None):
    return {"item_id": item_id, "q": q}

=== ä»£ç å— 3 ===
...
```

### ç¤ºä¾‹2: ç»Ÿè®¡æ‰€æœ‰repoçš„ä»£ç å—æ•°é‡

```bash
python -c "
import json

with open('dataset/dataset.jsonl') as f:
    repos = [json.loads(line) for line in f]

print('ä»£ç å—æ•°é‡ç»Ÿè®¡:')
print('=' * 50)
for repo in repos:
    gpt_input = repo['input_to_gpt']
    print(f'{repo[\"repo_name\"]:40s} {gpt_input[\"num_code_blocks\"]:3d} blocks')
"
```

**è¾“å‡ºç¤ºä¾‹**:
```
ä»£ç å—æ•°é‡ç»Ÿè®¡:
==================================================
huggingface/transformers                   8 blocks
fastapi/fastapi                            5 blocks
yt-dlp/yt-dlp                             12 blocks
...
```

### ç¤ºä¾‹3: æŸ¥æ‰¾å†…å®¹è¢«æˆªæ–­çš„repo

```bash
python -c "
import json

with open('dataset/dataset.jsonl') as f:
    repos = [json.loads(line) for line in f]

print('å†…å®¹è¢«æˆªæ–­çš„ä»“åº“:')
for repo in repos:
    gpt_input = repo['input_to_gpt']
    if gpt_input['total_length'] >= 7500:  # æ¥è¿‘8000çš„é™åˆ¶
        print(f'{repo[\"repo_name\"]}: {gpt_input[\"total_length\"]} å­—ç¬¦')
"
```

---

## ğŸ’¡ è°ƒè¯•æŠ€å·§

### 1. éªŒè¯è¯­è¨€è¿‡æ»¤æ˜¯å¦ç”Ÿæ•ˆ

```python
import json

# æ£€æŸ¥æå–çš„ä»£ç å—æ˜¯å¦åªåŒ…å«é¢„æœŸçš„è¯­è¨€
with open('dataset/tasks/pytorch_pytorch_tasks.json') as f:
    data = json.load(f)
    
    for block in data['input_to_gpt']['code_blocks']:
        # æ£€æŸ¥æ˜¯å¦åŒ…å«éPythonä»£ç 
        if '{' in block and '"' in block and block.strip().startswith('{'):
            print("âš ï¸ å¯èƒ½åŒ…å«JSONä»£ç å—ï¼")
        elif 'version:' in block and 'services:' in block:
            print("âš ï¸ å¯èƒ½åŒ…å«YAMLä»£ç å—ï¼")
```

### 2. æ£€æŸ¥ä»£ç å—è´¨é‡

```python
import json

with open('dataset/dataset.jsonl') as f:
    repos = [json.loads(line) for line in f]

for repo in repos:
    gpt_input = repo['input_to_gpt']
    
    # æ£€æŸ¥ä»£ç å—æ˜¯å¦å¤ªçŸ­ï¼ˆå¯èƒ½æ˜¯æ— æ•ˆçš„ï¼‰
    for i, block in enumerate(gpt_input['code_blocks']):
        if len(block.strip()) < 50:
            print(f"âš ï¸ {repo['repo_name']}: ä»£ç å— {i+1} å¤ªçŸ­ ({len(block)} å­—ç¬¦)")
```

### 3. å¯¹æ¯”ä¸åŒç‰ˆæœ¬çš„è¾“å…¥

å¦‚æœä½ ä¿®æ”¹äº†ä»£ç å—æå–é€»è¾‘ï¼Œå¯ä»¥å¯¹æ¯”å‰åçš„å·®å¼‚ï¼š

```python
import json

# æ—§ç‰ˆæœ¬çš„è¾“å‡º
with open('dataset_old/tasks/repo_tasks.json') as f:
    old_data = json.load(f)

# æ–°ç‰ˆæœ¬çš„è¾“å‡º
with open('dataset_new/tasks/repo_tasks.json') as f:
    new_data = json.load(f)

old_input = old_data['input_to_gpt']
new_input = new_data['input_to_gpt']

print(f"ä»£ç å—æ•°: {old_input['num_code_blocks']} â†’ {new_input['num_code_blocks']}")
print(f"æ€»é•¿åº¦: {old_input['total_length']} â†’ {new_input['total_length']}")
```

---

## ğŸ”§ è‡ªå®šä¹‰è°ƒè¯•ä¿¡æ¯

å¦‚æœä½ æƒ³è¦è®°å½•æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥ä¿®æ”¹ä»£ç ä¸­çš„ `gpt_input` å­—å…¸ï¼š

```python
# åœ¨ batch_process_repos.py ä¸­
gpt_input = {
    "repo_name": repo_name,
    "num_code_blocks": len(example_code),
    "total_length": len(example_text),
    "code_blocks": example_code[:3],  # å¯ä»¥è°ƒæ•´è®°å½•çš„æ•°é‡
    
    # å¯é€‰ï¼šæ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
    "language_filter": self.code_block_languages,  # ä½¿ç”¨çš„è¯­è¨€è¿‡æ»¤å™¨
    "was_truncated": len(example_text) >= max_length,  # æ˜¯å¦è¢«æˆªæ–­
    "timestamp": datetime.now().isoformat()  # å¤„ç†æ—¶é—´
}
```

---

## ğŸ“ˆ ç‰ˆæœ¬å†å²

- **v2.0** - ä»£ç å—åˆ†ç±» + Setupæå–
- **v2.1** - Whileå¾ªç¯æœç´¢
- **v2.2** - ä¸¤æ­¥éªŒè¯æœºåˆ¶
- **v2.3** - å¢å¼ºæ•°æ®ç»“æ„
- **v2.4** - è¯­è¨€è¿‡æ»¤
- **v2.5** - **è°ƒè¯•åŠŸèƒ½** âœ¨ å½“å‰ç‰ˆæœ¬

---

## ğŸ¯ æœ€ä½³å®è·µ

1. **å®šæœŸæ£€æŸ¥ `input_to_gpt`**
   - ç¡®ä¿å‘é€ç»™GPTçš„ä»£ç è´¨é‡é«˜
   - éªŒè¯è¯­è¨€è¿‡æ»¤æ˜¯å¦æ­£ç¡®å·¥ä½œ

2. **åˆ†æä»£ç å—æ•°é‡ä¸ä»»åŠ¡è´¨é‡çš„å…³ç³»**
   - ä»£ç å—å¤ªå°‘ â†’ å¯èƒ½ç”Ÿæˆçš„ä»»åŠ¡ä¸å¤Ÿä¸°å¯Œ
   - ä»£ç å—å¤ªå¤š â†’ å¯èƒ½è¢«æˆªæ–­æˆ–åŒ…å«é‡å¤å†…å®¹

3. **ä½¿ç”¨ `code_blocks` å¿«é€Ÿé¢„è§ˆ**
   - ä¸éœ€è¦é‡æ–°è¯»å–README
   - å¿«é€Ÿäº†è§£å‘é€ç»™GPTçš„å†…å®¹

4. **ç›‘æ§å†…å®¹é•¿åº¦**
   - æ¥è¿‘8000å­—ç¬¦çš„é™åˆ¶æ—¶å¯èƒ½éœ€è¦è°ƒæ•´ç­–ç•¥
   - è€ƒè™‘æå–æ›´æœ‰ä»£è¡¨æ€§çš„ä»£ç å—

---

## ğŸš€ ç«‹å³ä½¿ç”¨

```bash
# è¿è¡Œè„šæœ¬
python batch_process_repos.py --max-repos 5

# æŸ¥çœ‹ç”Ÿæˆçš„è°ƒè¯•ä¿¡æ¯
cat dataset/tasks/huggingface_transformers_tasks.json | python -m json.tool | grep -A 10 "input_to_gpt"

# æˆ–è€…ä½¿ç”¨Pythonè„šæœ¬åˆ†æ
python -c "
import json
with open('dataset/dataset.jsonl') as f:
    repo = json.loads(f.readline())
    print(json.dumps(repo['input_to_gpt'], indent=2, ensure_ascii=False))
"
```

---

**çŠ¶æ€**: âœ… å®Œæˆ  
**ç”¨é€”**: è°ƒè¯•å’Œç›‘æ§  
**è¾“å‡ºä½ç½®**: `tasks/*.json` å’Œ `dataset.jsonl`
