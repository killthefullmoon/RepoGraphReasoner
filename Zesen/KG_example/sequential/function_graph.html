<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 750px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#9270CA", "fixed": true, "id": "v2.generation_functions::Fast_dLLM_QwenForCausalLM", "label": "Fast_dLLM_QwenForCausalLM()", "shape": "dot", "title": "\u003cb\u003ev2.generation_functions::Fast_dLLM_QwenForCausalLM\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -6712.5}, {"color": "#9270CA", "fixed": true, "id": "v2.generation_functions::setup_model_with_custom_generation", "label": "setup_model_with_custom_generation()", "shape": "dot", "title": "\u003cb\u003ev2.generation_functions::setup_model_with_custom_generation\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Set up custom generation functions for the model", "x": 0.0, "y": -6562.5}, {"color": "#9270CA", "fixed": true, "id": "v2.generation_functions::batch_sample", "label": "batch_sample()", "shape": "dot", "title": "\u003cb\u003ev2.generation_functions::batch_sample\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -6637.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.generation_functions::mdm_sample_with_visualization", "label": "mdm_sample_with_visualization()", "shape": "triangle", "title": "\u003cb\u003ev2.generation_functions::mdm_sample_with_visualization\u003c/b\u003e\u003cbr\u003eModule: v2.generation_functions\u003cbr\u003eFile: v2/generation_functions.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: MDM sampling function with visualization\nwith intermediate state output for Gradio visualization", "x": 460.0, "y": -37.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.app::fix_seed", "label": "fix_seed()", "shape": "dot", "title": "\u003cb\u003ev2.app::fix_seed\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7387.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.app::format_chat_history", "label": "format_chat_history()", "shape": "triangle", "title": "\u003cb\u003ev2.app::format_chat_history\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Format chat history for the LLaDA model\n\nArgs:\n    history: List of [user_message, assistant_message] pairs\n    \nReturns:\n    Formatted conversation for the model", "x": 230.0, "y": -1987.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.app::generate_response_with_visualization_fast_dllm", "label": "generate_response_with_visualization_fast_dllm()", "shape": "dot", "title": "\u003cb\u003ev2.app::generate_response_with_visualization_fast_dllm\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate text with Fast_dLLM model with visualization using custom generation function\n\nArgs:\n    messages: List of message dictionaries with \u0027role\u0027 and \u0027content\u0027\n    max_new_tokens: Maximum number of tokens to generate\n    temperature: Sampling temperature\n    block_length: Block size for generatio\u2026", "x": 230.0, "y": -1912.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.app::create_chatbot_demo", "label": "create_chatbot_demo()", "shape": "box", "title": "\u003cb\u003ev2.app::create_chatbot_demo\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7462.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.app::add_message", "label": "add_message()", "shape": "dot", "title": "\u003cb\u003ev2.app::add_message\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add a message pair to the history and return the updated history", "x": 230.0, "y": -2062.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.app::user_message_submitted", "label": "user_message_submitted()", "shape": "box", "title": "\u003cb\u003ev2.app::user_message_submitted\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Process a submitted user message", "x": 0.0, "y": -7312.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.app::accelerated_response", "label": "accelerated_response()", "shape": "box", "title": "\u003cb\u003ev2.app::accelerated_response\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate accelerated model response independently", "x": 0.0, "y": -7612.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.app::clear_conversation", "label": "clear_conversation()", "shape": "dot", "title": "\u003cb\u003ev2.app::clear_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.app\u003cbr\u003eFile: v2/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Clear the conversation history", "x": 0.0, "y": -7537.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.run_chatbot::fix_seed", "label": "fix_seed()", "shape": "dot", "title": "\u003cb\u003ev2.run_chatbot::fix_seed\u003c/b\u003e\u003cbr\u003eModule: v2.run_chatbot\u003cbr\u003eFile: v2/run_chatbot.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -6487.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::set_seed", "label": "set_seed()", "shape": "triangle", "title": "\u003cb\u003ev2.eval::set_seed\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -900.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::Fast_dLLM_v2EvalHarness", "label": "Fast_dLLM_v2EvalHarness()", "shape": "box", "title": "\u003cb\u003ev2.eval::Fast_dLLM_v2EvalHarness\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -7237.5}, {"color": "#E8684A", "fixed": true, "id": "v2.eval::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.eval::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1837.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::rank", "label": "rank()", "shape": "triangle", "title": "\u003cb\u003ev2.eval::rank\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 1610.0, "y": -487.5}, {"color": "#E8684A", "fixed": true, "id": "v2.eval::world_size", "label": "world_size()", "shape": "dot", "title": "\u003cb\u003ev2.eval::world_size\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -6787.5}, {"color": "#E8684A", "fixed": true, "id": "v2.eval::tokenizer_name", "label": "tokenizer_name()", "shape": "dot", "title": "\u003cb\u003ev2.eval::tokenizer_name\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -6862.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::apply_chat_template", "label": "apply_chat_template()", "shape": "triangle", "title": "\u003cb\u003ev2.eval::apply_chat_template\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -187.5}, {"color": "#E8684A", "fixed": true, "id": "v2.eval::loglikelihood_rolling", "label": "loglikelihood_rolling()", "shape": "dot", "title": "\u003cb\u003ev2.eval::loglikelihood_rolling\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -6937.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::_encode_pair", "label": "_encode_pair()", "shape": "triangle", "title": "\u003cb\u003ev2.eval::_encode_pair\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1762.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::_forward_process", "label": "_forward_process()", "shape": "triangle", "title": "\u003cb\u003ev2.eval::_forward_process\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -262.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::get_logits", "label": "get_logits()", "shape": "triangle", "title": "\u003cb\u003ev2.eval::get_logits\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -112.5}, {"color": "#E8684A", "fixed": true, "id": "v2.eval::get_loglikelihood", "label": "get_loglikelihood()", "shape": "dot", "title": "\u003cb\u003ev2.eval::get_loglikelihood\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1687.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::loglikelihood", "label": "loglikelihood()", "shape": "box", "title": "\u003cb\u003ev2.eval::loglikelihood\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7012.5}, {"color": "#E8684A", "fixed": true, "id": "v2.eval::generate_until", "label": "generate_until()", "shape": "dot", "title": "\u003cb\u003ev2.eval::generate_until\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7087.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.eval::_tokenize", "label": "_tokenize()", "shape": "box", "title": "\u003cb\u003ev2.eval::_tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.eval\u003cbr\u003eFile: v2/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7162.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.train_scripts.finetune::main", "label": "main()", "shape": "box", "title": "\u003cb\u003ev2.train_scripts.finetune::main\u003c/b\u003e\u003cbr\u003eModule: v2.train_scripts.finetune\u003cbr\u003eFile: v2/train_scripts/finetune.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14962.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::OptimizerNames", "label": "OptimizerNames()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::OptimizerNames\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -5662.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::ModelArguments", "label": "ModelArguments()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.args::ModelArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class ModelArguments using the dataclass decorator. \nThe class contains several optional parameters that can be used to configure a model. \n\nmodel_name_or_path : str\n    a string representing the path or name of a pretrained\n    model checkpoint for weights initialization. If None, a model \u2026", "x": 230.0, "y": -1612.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::VisModelArguments", "label": "VisModelArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::VisModelArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -5437.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::DatasetArguments", "label": "DatasetArguments()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.args::DatasetArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class DatasetArguments using the dataclass decorator.\nThe class contains several optional parameters that can be used to configure a dataset for a language model.\n\n\ndataset_path : str\n    a string representing the path of the dataset to use.\n\ndataset_name : str\n    a string representing the\u2026", "x": 1610.0, "y": -412.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::MultiModalDatasetArguments", "label": "MultiModalDatasetArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::MultiModalDatasetArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -5737.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::FinetunerArguments", "label": "FinetunerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::FinetunerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Adapt transformers.TrainingArguments", "x": 0.0, "y": -6037.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::RewardModelTunerArguments", "label": "RewardModelTunerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::RewardModelTunerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Arguments for reward modeling.", "x": 0.0, "y": -5512.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::EvaluatorArguments", "label": "EvaluatorArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::EvaluatorArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class EvaluatorArguments using the dataclass decorator. The class contains several optional\nparameters that can be used to configure a evaluator.\n\nlocal_rank : str\n    For distributed training: local_rank\n\nrandom_shuffle : bool\n\nuse_wandb : bool\n\nrandom_seed : int, default = 1\n\noutput_dir :\u2026", "x": 0.0, "y": -6112.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::InferencerArguments", "label": "InferencerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::InferencerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class InferencerArguments using the dataclass decorator. The class contains several optional\nparameters that can be used to configure a inferencer.\n\nlocal_rank : str\n    For distributed training: local_rank\nrandom_seed : int, default = 1\ninference_batch_size : int, default = 1\ndeepspeed :\n \u2026", "x": 0.0, "y": -5962.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::RaftAlignerArguments", "label": "RaftAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::RaftAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Define a class RaftAlignerArguments to configure raft aligner.", "x": 0.0, "y": -5587.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::BenchmarkingArguments", "label": "BenchmarkingArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::BenchmarkingArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -6337.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::DPOAlignerArguments", "label": "DPOAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::DPOAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The arguments for the DPO training script.", "x": 0.0, "y": -6262.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::DPOv2AlignerArguments", "label": "DPOv2AlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::DPOv2AlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The arguments for the DPOv2 training script.", "x": 0.0, "y": -6187.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::IterativeAlignerArguments", "label": "IterativeAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::IterativeAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Arguments for iterative aligners.", "x": 0.0, "y": -5887.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::IterativeDPOAlignerArguments", "label": "IterativeDPOAlignerArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::IterativeDPOAlignerArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Arguments for iterative DPO aligners.", "x": 0.0, "y": -5812.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::AutoArguments", "label": "AutoArguments()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::AutoArguments\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Automatically choose arguments from FinetunerArguments or EvaluatorArguments.", "x": 0.0, "y": -6412.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::split_args", "label": "split_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::split_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -5287.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::__post_init__", "label": "__post_init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.args::__post_init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -5362.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.args::get_pipeline_args_class", "label": "get_pipeline_args_class()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.args::get_pipeline_args_class\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.args\u003cbr\u003eFile: v2/src/lmflow/args.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1537.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset", "label": "get_paired_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load dataset and convert it to the necessary format.\n\n    The dataset is converted to a dictionary with the following structure:\n    {\n        \u0027prompt\u0027: List[str],\n        \u0027chosen\u0027: List[str],\n        \u0027rejected\u0027: List[str],\n    }\n\n    Prompts are structured as follows:\n      \"Question: \" + \u003cprompt\u003e \u2026", "x": 460.0, "y": 637.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "label": "DPOAligner()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::DPOAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 3562.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::return_prompt_and_responses", "label": "return_prompt_and_responses()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::return_prompt_and_responses\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3787.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3637.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer", "label": "_initialize_trainer()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2512.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset", "label": "_load_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::_load_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2587.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.dpo_aligner::align", "label": "align()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpo_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpo_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3712.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "label": "IterativeDPOAligner()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 5662.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 5737.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align", "label": "align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 3562.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "label": "_align_single_iteration()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 3412.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference", "label": "_do_target_model_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1312.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference", "label": "_do_reward_model_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1237.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "label": "_do_single_dpo_align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 3487.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args", "label": "_parse_target_model_inference_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 450.0}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args", "label": "_parse_reward_model_inference_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 375.0}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args", "label": "_parse_dpo_aligner_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1387.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args", "label": "__filter_args()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.iterative_dpo_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/iterative_dpo_aligner.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -225.0}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::BaseTuner", "label": "BaseTuner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::BaseTuner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A subclass of BasePipeline which is tunable.\n    ", "x": 0.0, "y": 3262.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3337.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::_check_if_tunable", "label": "_check_if_tunable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::_check_if_tunable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3412.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.base_tuner::tune", "label": "tune()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_tuner::tune\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_tuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3487.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::InferencerWithOffloading", "label": "InferencerWithOffloading()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::InferencerWithOffloading\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 9487.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "label": "VLLMInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 230.0, "y": 5062.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer", "label": "MemorySafeVLLMInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 690.0, "y": 1950.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9637.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::inference", "label": "inference()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9712.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::save_inference_results", "label": "save_inference_results()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::save_inference_results\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9862.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::load_inference_results", "label": "load_inference_results()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::load_inference_results\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9787.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params", "label": "parse_to_sampling_params()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2812.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::_inference", "label": "_inference()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2737.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference", "label": "_distributed_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2662.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::scheduling_strategy_fn", "label": "scheduling_strategy_fn()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::scheduling_strategy_fn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9937.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::DistributedPredictor", "label": "DistributedPredictor()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::DistributedPredictor\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 9412.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.vllm_inferencer::__call__", "label": "__call__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.vllm_inferencer::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.vllm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/vllm_inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: batch: Dict[str, np.ndarray], {\"item\": array([\u0027...\u0027, \u0027...\u0027, \u0027...\u0027, ...])}\n                ", "x": 0.0, "y": 9562.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::rstrip_partial_utf8", "label": "rstrip_partial_utf8()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::rstrip_partial_utf8\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 5512.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::Inferencer", "label": "Inferencer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::Inferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Inferencer` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\ninferencer_args : InferencerArg\u2026", "x": 0.0, "y": 5062.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "label": "SpeculativeInferencer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::SpeculativeInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Ref: [arXiv:2211.17192v2](https://arxiv.org/abs/2211.17192)\n\nParameters\n------------\ntarget_model_args : ModelArguments object.\n    Contains the arguments required to load the target model.\n    \ndraft_model_args : ModelArguments object.\n    Contains the arguments required to load the draft model.\n\nd\u2026", "x": 0.0, "y": 5137.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::ToolInferencer", "label": "ToolInferencer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::ToolInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `ToolInferencer` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\ninferencer_args : Inference\u2026", "x": 0.0, "y": 5212.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 5287.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "label": "create_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::create_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Batchlize dataset and format it to dataloader.\n\nArgs:\n    dataset (Dataset): the dataset object\n\nOutput:\n    dataloader (batchlize): the dataloader object\n    dataset_size (int): the length of the dataset", "x": 230.0, "y": 3262.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform inference for a model\n\nParameters\n------------\nmodel : TunableModel object.\n    TunableModel to perform inference\n\ndataset : Dataset object.\n\n\nReturns:\n\noutput_dataset: Dataset object.", "x": 0.0, "y": 5437.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::stream_inference", "label": "stream_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::stream_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 5587.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::score_to_prob", "label": "score_to_prob()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::score_to_prob\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Convert scores (NOT softmaxed tensor) to probabilities with support for temperature, top-p sampling, and argmax.\n\nParameters\n----------\nscores : torch.Tensor\n    Input scores.\ntemperature : float, optional\n    Temperature parameter for controlling randomness. Higher values make the distribution more\u2026", "x": 690.0, "y": 300.0}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::sample", "label": "sample()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::sample\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Sample from a tensor of probabilities\n        ", "x": 690.0, "y": 225.0}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::predict_next_token", "label": "predict_next_token()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::predict_next_token\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Predict the next token given the input_ids.\n        ", "x": 690.0, "y": 150.0}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "label": "autoregressive_sampling()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::autoregressive_sampling\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Ref: [arXiv:2211.17192v2](https://arxiv.org/abs/2211.17192) Section 2.2\n        ", "x": 460.0, "y": 1162.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::code_exec", "label": "code_exec()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::code_exec\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 5362.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "label": "speculative_sampling()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.inferencer::speculative_sampling\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Ref: [arXiv:2211.17192v2](https://arxiv.org/abs/2211.17192)\n\nParameters\n----------\ninput_ids : torch.Tensor\ndraft_model : TunableModel object\nmodel_list : List[TunableModel object]\n\nReturns\n-------\ntorch.Tensor", "x": 230.0, "y": 3337.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "label": "RaftAligner()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::RaftAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `RaftAligner` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nraft_aligner_args : RaftAligne\u2026", "x": 0.0, "y": 5812.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 5887.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "label": "_initialize_trainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_initialize_trainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function takes the model and tokenizer as the input and initialize the trainer.", "x": 230.0, "y": 3637.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "label": "_load_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_load_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function prepares the dataset for every iteration.", "x": 230.0, "y": 3712.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset", "label": "_load_input_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_load_input_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load input dataset (i.e. prompt/question dataset) for training.\n\nArgs:\n    dataset: A Dataset object.\n        The dataset to be loaded.\n\nReturns:\n    dataloader (`torch.utils.data.DataLoader`):\n        The dataloader for the dataset.", "x": 230.0, "y": 3787.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_clean_text", "label": "_clean_text()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_clean_text\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 5962.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_discard_sample", "label": "_discard_sample()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_discard_sample\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 6037.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_top", "label": "_get_batch_dataset_top()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_top\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: :param batch_input: input prompts", "x": 0.0, "y": 6187.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_local", "label": "_get_batch_dataset_local()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_local\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: :param batch_input: input prompts", "x": 0.0, "y": 6112.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::align", "label": "align()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform alignment for a model\n\nParameters\n------------\nmodel : BaseModel object.\ndataset: Dataset object.\n    Input dataset for model to generate outputs. The input and output\n        will then be feed into reward model to get the reward for\n        alignment.\nreward_model: RegressionModel object.", "x": 0.0, "y": 6262.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::tokenize_function", "label": "tokenize_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 6487.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::group_texts", "label": "group_texts()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::group_texts\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 6337.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.raft_aligner::tokenize", "label": "tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.raft_aligner::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.raft_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/raft_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 6412.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.auto_pipeline::AutoPipeline", "label": "AutoPipeline()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.auto_pipeline::AutoPipeline\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.auto_pipeline\u003cbr\u003eFile: v2/src/lmflow/pipeline/auto_pipeline.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The class designed to return a pipeline automatically based on its name.", "x": 0.0, "y": 2812.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.auto_pipeline::get_pipeline", "label": "get_pipeline()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.auto_pipeline::get_pipeline\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.auto_pipeline\u003cbr\u003eFile: v2/src/lmflow/pipeline/auto_pipeline.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2437.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "label": "RewardModelInferencer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Inferencer` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\ninferencer_args : InferencerArg\u2026", "x": 690.0, "y": 525.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 6712.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 75.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "label": "_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 0.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "label": "__inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -75.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "label": "__distributed_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__distributed_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -150.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__vllm_inference", "label": "__vllm_inference()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -75.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__post_process_model_output", "label": "__post_process_model_output()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__post_process_model_output\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -150.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::flatten_list", "label": "flatten_list()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::flatten_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 75.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::compress_list", "label": "compress_list()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::compress_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 0.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::scheduling_strategy_fn", "label": "scheduling_strategy_fn()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::scheduling_strategy_fn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 6787.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "label": "DistributedPredictor()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 6562.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_inferencer::__call__", "label": "__call__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_inferencer::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_inferencer\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_inferencer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: batch: Dict[str, np.ndarray]\nExample (batch size=2):\n{\u0027input\u0027: array([\u0027...\u0027,\u0027...\u0027], dtype=object),\n \u0027output\u0027: array([array([\"...\", \"...\"], dtype=object), array([\u0027...\u0027,\u0027...\u0027], dtype=object)], dtype=object),\n \u0027input_ids\u0027: array([[[128000, 128006,    882, ..., 128256, 128256, 128256],\n         [128000,\u2026", "x": 0.0, "y": 6637.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "label": "RewardModelTuner()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::RewardModelTuner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `RewardModelTuner` class.\n\nParameters\n----------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nfinetuner_args : RewardModelTunerArguments objec\u2026", "x": 0.0, "y": 6862.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 6937.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::tune", "label": "tune()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::tune\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7087.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback", "label": "DynamicLayerActivationCallback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Class", "x": 230.0, "y": 3862.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::freeze_all_layers", "label": "freeze_all_layers()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::freeze_all_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 600.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::on_step_begin", "label": "on_step_begin()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::on_step_begin\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7012.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers", "label": "switch_active_layers()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.rm_tuner::switch_active_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.rm_tuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/rm_tuner.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1462.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::BaseAligner", "label": "BaseAligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::BaseAligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A subclass of BasePipeline which is alignable.\n    ", "x": 0.0, "y": 2887.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 2962.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::_check_if_alignable", "label": "_check_if_alignable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::_check_if_alignable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3037.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.pipeline.base_aligner::align", "label": "align()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3112.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.base_pipeline::BasePipeline", "label": "BasePipeline()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.base_pipeline::BasePipeline\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.base_pipeline\u003cbr\u003eFile: v2/src/lmflow/pipeline/base_pipeline.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 3187.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "label": "DPOv2Aligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Class", "x": 230.0, "y": 2662.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "label": "MemorySafeDPOv2Aligner()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Class", "x": 460.0, "y": 712.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3862.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::align", "label": "align()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::align\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4012.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::__prepare_training_args", "label": "__prepare_training_args()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::__prepare_training_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 3937.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "label": "convert_to_paired_dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Convert a scored one to multiple (text_to_scored_textlist) to a paired dataset by rejection sampling.\n        ", "x": 460.0, "y": 787.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths", "label": "_calc_response_lengths()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -150.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty", "label": "_calc_reward_with_length_penalty()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: When length_penalty \u003e 0, penalize the longer sequence by subtracting \nlength_penalty * length from the reward. Vice versa when length_penalty \u003c 0.", "x": 690.0, "y": -75.0}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards", "label": "sampling_paired_idx_from_rewards()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare the dataset for DPO training by rejection sampling.\nWe implement different strategies to select pairs, including\nrandom: randomly select two instances\nmax_min: best v.s. worst\nmax_max: best v.s. second best\nmax_random: best v.s. random from the remaining", "x": 690.0, "y": 0.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards", "label": "_sampling_paired_idx_from_rewards()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -375.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards_fast", "label": "_sampling_paired_idx_from_rewards_fast()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards_fast\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.dpov2_aligner\u003cbr\u003eFile: v2/src/lmflow/pipeline/dpov2_aligner.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -300.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::Finetuner", "label": "Finetuner()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::Finetuner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Finetuner` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nfinetuner_args : FinetunerArgume\u2026", "x": 0.0, "y": 4462.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4537.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::group_text", "label": "group_text()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::group_text\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Groups texts together to form blocks of maximum length `model_max_length` and returns the processed data as\na dictionary.", "x": 230.0, "y": 3187.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer", "label": "create_customized_optimizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::create_customized_optimizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 3112.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::tune", "label": "tune()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::tune\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform tuning for a model\n\nParameters\n------------\nmodel : TunableModel object.\n    TunableModel to perform tuning.\n\ndataset:\n    dataset to train model.", "x": 0.0, "y": 4987.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::group_texts", "label": "group_texts()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::group_texts\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4762.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::CustomizedOptimTrainer", "label": "CustomizedOptimTrainer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::CustomizedOptimTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 4387.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs", "label": "get_optimizer_cls_and_kwargs()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1012.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::create_optimizer", "label": "create_optimizer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::create_optimizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4687.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::preprocess_logits_for_metrics", "label": "preprocess_logits_for_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::preprocess_logits_for_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4912.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::compute_metrics", "label": "compute_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::compute_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4612.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback", "label": "DynamicLayerActivationCallback()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Class", "x": 230.0, "y": 3037.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::freeze_all_layers", "label": "freeze_all_layers()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::freeze_all_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 75.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::on_step_begin", "label": "on_step_begin()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::on_step_begin\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4837.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.finetuner::switch_active_layers", "label": "switch_active_layers()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.finetuner::switch_active_layers\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.finetuner\u003cbr\u003eFile: v2/src/lmflow/pipeline/finetuner.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1087.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::Evaluator", "label": "Evaluator()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::Evaluator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the `Evaluator` class with given arguments.\n\nParameters\n------------\nmodel_args : ModelArguments object.\n    Contains the arguments required to load the model.\n\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nevaluator_args : EvaluatorArgume\u2026", "x": 0.0, "y": 4087.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4162.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::create_dataloader", "label": "create_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::create_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 862.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_match", "label": "_match()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_match\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 4237.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::evaluate", "label": "evaluate()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::evaluate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform Evaluation for a model\n\nParameters\n------------\nmodel : TunableModel object.\n    TunableModel to perform inference\n\ndataset : Dataset object.\n    ", "x": 0.0, "y": 4312.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator", "label": "_evaluate_acc_with_accelerator()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2737.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed", "label": "_evaluate_acc_with_deepspeed()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2812.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_ppl", "label": "_evaluate_ppl()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_ppl\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2962.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "label": "_evaluate_nll()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::_evaluate_nll\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Evaluates negative log likelihood of the model over a dataset.\n\nNLL = -1/N sum_{i=1}^N sum_{j=1}^|w_i| ln(p(w_{i,j}|context_window)),\n\nwhere N is the number of data samples, w_{i,j} is the j-th token in\ni-th sample. Here \"context_window\" = p(w_{i,start}, w_{i,start+1}, ...,\np_{i,j-1} with start = ma\u2026", "x": 230.0, "y": 2887.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.evaluator::get_nll", "label": "get_nll()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.evaluator::get_nll\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.evaluator\u003cbr\u003eFile: v2/src/lmflow/pipeline/evaluator.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 937.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding", "label": "PreferenceDataCollatorWithPadding()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Class", "x": 920.0, "y": 150.0}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element", "label": "tokenize_batch_element()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize a single batch element.\n\nAt this stage, we don\u0027t convert to PyTorch tensors yet; we just handle the truncation\n    in case the prompt + chosen or prompt + rejected responses is/are too long. First\n    we truncate the prompt; if we\u0027re still too long, we truncate the chosen/rejected.\n\nWe also\u2026", "x": 1150.0, "y": 225.0}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate", "label": "collate()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 150.0}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__", "label": "__call__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_dataprocessor.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7162.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding", "label": "RewardDataCollatorWithPadding()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_dataprocessor.py\u003cbr\u003eKind: Class", "x": 230.0, "y": 4912.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::__call__", "label": "__call__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_dataprocessor::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_dataprocessor\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_dataprocessor.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9037.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::compute_metrics", "label": "compute_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::compute_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9337.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss", "label": "rm_loss()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::rm_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 4987.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::RewardTrainer", "label": "RewardTrainer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::RewardTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 9187.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::PeftRewardTrainer", "label": "PeftRewardTrainer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::PeftRewardTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 9112.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.rm_trainer::compute_loss", "label": "compute_loss()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.rm_trainer::compute_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.rm_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/rm_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 9262.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "label": "DPOv2Trainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Class", "x": 460.0, "y": 1537.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 675.0}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "label": "dpo_loss()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Compute the DPO loss for a batch of policy and reference model log probabilities.\n\nArgs:\n    policy_chosen_logps: Log probabilities of the policy model for the chosen responses. Shape: (batch_size,)\n    policy_rejected_logps: Log probabilities of the policy model for the rejected responses. Shape: (\u2026", "x": 920.0, "y": 225.0}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_loss_metrics", "label": "get_batch_loss_metrics()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_loss_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7237.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics", "label": "get_batch_metrics()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.dpov2_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/dpov2_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Compute the DPO loss and other metrics for the given batch of inputs for train or test.", "x": 690.0, "y": 750.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer", "label": "PeftTrainer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 7537.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "label": "PeftSavingCallback()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Correctly save PEFT model and not full model ", "x": 0.0, "y": 7462.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint", "label": "_save_checkpoint()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Don\u0027t save base model, optimizer etc.\nbut create checkpoint folder (needed for saving adapter) ", "x": 0.0, "y": 7612.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::_save", "label": "_save()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::_save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 825.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end", "label": "on_train_end()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::on_train_end\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save final best model adapter ", "x": 460.0, "y": 1612.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::on_epoch_end", "label": "on_epoch_end()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::on_epoch_end\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save intermediate model adapters in case of interrupted training ", "x": 0.0, "y": 7687.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.peft_trainer::on_save", "label": "on_save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.peft_trainer::on_save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.peft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/peft_trainer.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 3937.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "label": "RaftTrainer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Trainer is a simple but feature-complete training and eval loop for PyTorch, optimized for \ud83e\udd17 Transformers.\nArgs:\n    model ([`PreTrainedModel`] or `torch.nn.Module`, *optional*):\n        The model to train, evaluate or use for predictions. If not provided, a `model_init` must be passed.\n        \u003cTip\u2026", "x": 460.0, "y": 1687.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7762.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback", "label": "add_callback()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::add_callback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add a callback to the current list of [`~transformer.TrainerCallback`].\nArgs:\n   callback (`type` or [`~transformer.TrainerCallback`]):\n       A [`~transformer.TrainerCallback`] class or an instance of a [`~transformer.TrainerCallback`]. In the\n       first case, will instantiate a member of that cl\u2026", "x": 690.0, "y": 1350.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::pop_callback", "label": "pop_callback()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::pop_callback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Remove a callback from the current list of [`~transformer.TrainerCallback`] and returns it.\nIf the callback is not found, returns `None` (and no error is raised).\nArgs:\n   callback (`type` or [`~transformer.TrainerCallback`]):\n       A [`~transformer.TrainerCallback`] class or an instance of a [`~tr\u2026", "x": 690.0, "y": 1575.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::remove_callback", "label": "remove_callback()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::remove_callback\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Remove a callback from the current list of [`~transformer.TrainerCallback`].\nArgs:\n   callback (`type` or [`~transformer.TrainerCallback`]):\n       A [`~transformer.TrainerCallback`] class or an instance of a [`~transformer.TrainerCallback`]. In the\n       first case, will remove the first member of\u2026", "x": 690.0, "y": 1725.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device", "label": "_move_model_to_device()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 450.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed", "label": "_set_signature_columns_if_needed()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 750.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns", "label": "_remove_unused_columns()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 1200.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns", "label": "_get_collator_with_removed_columns()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Wrap the data collator in a callable removing unused columns.", "x": 690.0, "y": 900.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler", "label": "_get_train_sampler()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 1050.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "label": "get_train_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the training [`~torch.utils.data.DataLoader`].\nWill use no sampler if `train_dataset` does not implement `__len__`, a random sampler (adapted to distributed\ntraining if necessary) otherwise.\nSubclass and override this method if you want to inject some custom behavior.", "x": 230.0, "y": 4612.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler", "label": "_get_eval_sampler()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 975.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "label": "get_eval_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the evaluation [`~torch.utils.data.DataLoader`].\nSubclass and override this method if you want to inject some custom behavior.\nArgs:\n    eval_dataset (`torch.utils.data.Dataset`, *optional*):\n        If provided, will override `self.eval_dataset`. If it is a [`~datasets.Dataset`], columns no\u2026", "x": 460.0, "y": 2362.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "label": "get_test_dataloader()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the test [`~torch.utils.data.DataLoader`].\nSubclass and override this method if you want to inject some custom behavior.\nArgs:\n    test_dataset (`torch.utils.data.Dataset`, *optional*):\n        The test dataset to use. If it is a [`~datasets.Dataset`], columns not accepted by the\n        `mo\u2026", "x": 230.0, "y": 4537.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler", "label": "create_optimizer_and_scheduler()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Setup the optimizer and the learning rate scheduler.\nWe provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\nTrainer\u0027s init through `optimizers`, or subclass and override this method (or `create_optimizer` and/or\n`create_scheduler`) in a subcla\u2026", "x": 230.0, "y": 4387.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer", "label": "create_optimizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Setup the optimizer.\nWe provide a reasonable default that works well. If you want to use something else, you can pass a tuple in the\nTrainer\u0027s init through `optimizers`, or subclass and override this method in a subclass.", "x": 460.0, "y": 2212.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::get_optimizer_cls_and_kwargs", "label": "get_optimizer_cls_and_kwargs()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::get_optimizer_cls_and_kwargs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the optimizer class and optimizer parameters based on the training arguments.\nArgs:\n    args (`transformers.training_args.TrainingArguments`):\n        The training arguments for the training session.", "x": 690.0, "y": 1500.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_scheduler", "label": "create_scheduler()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_scheduler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Setup the scheduler. The optimizer of the trainer must have been set up either before this method is called or\npassed as an argument.\nArgs:\n    num_training_steps (int): The number of training steps to do.", "x": 460.0, "y": 2287.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples", "label": "num_examples()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::num_examples\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Helper to get number of samples in a [`~torch.utils.data.DataLoader`] by accessing its dataset. When\ndataloader.dataset does not exist or has no length, estimates as best it can", "x": 230.0, "y": 4762.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_hp_search_setup", "label": "_hp_search_setup()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_hp_search_setup\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: HP search setup code", "x": 920.0, "y": 300.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "label": "_report_to_hp_search()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 4162.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint", "label": "_tune_save_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1987.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::call_model_init", "label": "call_model_init()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::call_model_init\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 825.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval", "label": "torch_jit_model_eval()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2587.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model", "label": "ipex_optimize_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2437.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model", "label": "_wrap_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 4312.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "label": "train()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Main training entry point.\nArgs:\n    resume_from_checkpoint (`str` or `bool`, *optional*):\n        If a `str`, local path to a saved checkpoint as saved by a previous instance of [`Trainer`]. If a\n        `bool` and equals `True`, load the last checkpoint in *args.output_dir* as saved by a previous \u2026", "x": 690.0, "y": 1875.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "label": "_one_train()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_one_train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 8212.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "label": "_inner_training_loop()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: 0 This function serves to train one time\n1 Update the self.train_dataset before calling this function", "x": 0.0, "y": 7837.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir", "label": "_get_output_dir()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1762.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint", "label": "_load_from_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 375.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model", "label": "_load_best_model()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7912.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load", "label": "_issue_warnings_after_load()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 375.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "label": "_maybe_log_save_evaluate()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 8137.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_rng_state", "label": "_load_rng_state()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_rng_state\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 8062.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "label": "_save_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 4237.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_optimizer_and_scheduler", "label": "_load_optimizer_and_scheduler()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_load_optimizer_and_scheduler\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: If optimizer and scheduler states exist, load them.", "x": 0.0, "y": 7987.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::hyperparameter_search", "label": "hyperparameter_search()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::hyperparameter_search\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Launch an hyperparameter search using `optuna` or `Ray Tune` or `SigOpt`. The optimized quantity is determined\nby `compute_objective`, which defaults to a function returning the evaluation loss when no metric is provided,\nthe sum of all metrics otherwise.\n\u003cTip warning={true}\u003e\nTo use this method, you\u2026", "x": 0.0, "y": 8587.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::log", "label": "log()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::log\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Log `logs` on the various objects watching training.\nSubclass and override this method to inject custom behavior.\nArgs:\n    logs (`Dict[str, float]`):\n        The values to log.", "x": 1150.0, "y": 450.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input", "label": "_prepare_input()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares one `data` before feeding it to the model, be it a tensor or a nested list/dictionary of tensors.", "x": 920.0, "y": 525.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs", "label": "_prepare_inputs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare `inputs` before feeding them to the model, converting them to tensors if they are not already and\nhandling potential state.", "x": 690.0, "y": 1125.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager", "label": "compute_loss_context_manager()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: A helper wrapper to group together context managers.", "x": 460.0, "y": 2137.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager", "label": "autocast_smart_context_manager()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: A helper wrapper that creates an appropriate context manager for `autocast` while feeding it the desired\narguments, depending on the situation.", "x": 690.0, "y": 1425.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "label": "training_step()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::training_step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform a training step on a batch of inputs.\nSubclass and override to inject custom behavior.\nArgs:\n    model (`nn.Module`):\n        The model to train.\n    inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n        The inputs and targets of the model.\n        The dictionary will be unpacked before be\u2026", "x": 0.0, "y": 8962.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss", "label": "compute_loss()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::compute_loss\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: How the loss is computed by Trainer. By default, all models return the loss in the first element.\nSubclass and override for custom behavior.", "x": 460.0, "y": 2062.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::is_local_process_zero", "label": "is_local_process_zero()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::is_local_process_zero\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Whether or not this process is the local (e.g., on one machine if training in a distributed fashion on several\nmachines) main process.", "x": 230.0, "y": 4687.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero", "label": "is_world_process_zero()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Whether or not this process is the global main process (when training in a distributed fashion on several\nmachines, this is only going to be `True` for one process).", "x": 1380.0, "y": 450.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "label": "save_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::save_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Will save the model, so you can reload it using `from_pretrained()`.\nWill only save from the main process.", "x": 690.0, "y": 1800.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_tpu", "label": "_save_tpu()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_save_tpu\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 675.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_save", "label": "_save()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 600.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos", "label": "store_flos()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::store_flos\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2512.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints", "label": "_sorted_checkpoints()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 690.0, "y": 1275.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints", "label": "_rotate_checkpoints()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1912.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "label": "evaluate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::evaluate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Run evaluation and returns metrics.\nThe calling script will be responsible for providing a method to compute metrics, as they are task-dependent\n(pass it to the init `compute_metrics` argument).\nYou can also subclass and override this method to inject custom behavior.\nArgs:\n    eval_dataset (`Datase\u2026", "x": 230.0, "y": 4462.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::predict", "label": "predict()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::predict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Run prediction and returns predictions and potential metrics.\nDepending on the dataset and your use case, your test dataset may contain labels. In that case, this method\nwill also return metrics, like in `evaluate()`.\nArgs:\n    test_dataset (`Dataset`):\n        Dataset to run the predictions on. If \u2026", "x": 0.0, "y": 8812.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop", "label": "evaluation_loop()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\nWorks both with or without labels.", "x": 0.0, "y": 8437.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather", "label": "_nested_gather()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Gather value of `tensors` (tensor or list/tuple of nested tensors) and convert them to numpy before\nconcatenating them to `gathered`", "x": 230.0, "y": 4087.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_pad_across_processes", "label": "_pad_across_processes()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_pad_across_processes\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\nthey can safely be gathered.", "x": 0.0, "y": 8287.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "label": "prediction_step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::prediction_step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform an evaluation step on `model` using `inputs`.\nSubclass and override to inject custom behavior.\nArgs:\n    model (`nn.Module`):\n        The model to evaluate.\n    inputs (`Dict[str, Union[torch.Tensor, Any]]`):\n        The inputs and targets of the model.\n        The dictionary will be unpacke\u2026", "x": 230.0, "y": 4837.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::floating_point_ops", "label": "floating_point_ops()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::floating_point_ops\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: For models that inherit from [`PreTrainedModel`], uses that method to compute the number of floating point\noperations for every backward + forward pass. If using another model, either implement such a method in the\nmodel or subclass and override this method.\nArgs:\n    inputs (`Dict[str, Union[torch.\u2026", "x": 0.0, "y": 8512.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo", "label": "init_git_repo()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a git repo in `self.args.hub_model_id`.\nArgs:\n    at_init (`bool`, *optional*, defaults to `False`):\n        Whether this function is called before any training or not. If `self.args.overwrite_output_dir` is\n        `True` and `at_init` is `True`, the path to the repo (which is `self.arg\u2026", "x": 920.0, "y": 975.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card", "label": "create_model_card()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::create_model_card\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Creates a draft of a model card using the information available to the `Trainer`.\nArgs:\n    language (`str`, *optional*):\n        The language of the model (if applicable)\n    license (`str`, *optional*):\n        The license of the model. Will default to the license of the pretrained model used, if \u2026", "x": 920.0, "y": 900.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "label": "_push_from_checkpoint()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 1837.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "label": "push_to_hub()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Upload *self.model* and *self.tokenizer* to the \ud83e\udd17 model hub on the repo *self.args.hub_model_id*.\nParameters:\n    commit_message (`str`, *optional*, defaults to `\"End of training\"`):\n        Message to commit while pushing.\n    blocking (`bool`, *optional*, defaults to `True`):\n        Whether the f\u2026", "x": 690.0, "y": 1650.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "label": "prediction_loop()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prediction/evaluation loop, shared by `Trainer.evaluate()` and `Trainer.predict()`.\nWorks both with or without labels.", "x": 0.0, "y": 8887.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_gather_and_numpify", "label": "_gather_and_numpify()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_gather_and_numpify\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Gather value of `tensors` (tensor or list/tuple of nested tensors) and convert them to numpy before\nconcatenating them to `gathered`", "x": 230.0, "y": 4012.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore", "label": "_add_sm_patterns_to_gitignore()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add SageMaker Checkpointing patterns to .gitignore file.", "x": 1150.0, "y": 300.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::patched_optimizer_step", "label": "patched_optimizer_step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::patched_optimizer_step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 8737.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::auto_wrapper_callable", "label": "auto_wrapper_callable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::auto_wrapper_callable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 8362.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.raft_trainer::opt_load_hook", "label": "opt_load_hook()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.raft_trainer::opt_load_hook\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.raft_trainer\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/raft_trainer.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 8662.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "label": "main()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/memory_safe_dpov2_align.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7312.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "label": "main()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference\u003cbr\u003eFile: v2/src/lmflow/pipeline/utils/memory_safe_vllm_inference.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 7387.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "label": "CustomMultiModalDataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Dataset for Multi Modal data", "x": 230.0, "y": -1462.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava", "label": "preprocess_multimodal_llava()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -600.0}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token", "label": "tokenizer_image_token()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -750.0}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "label": "preprocess_llama_from_llava_plain()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function just add the image in the front of text.\nAnd don\u0027t add any prompt.\nArgs:\n    sources: The input data with text and image.\n    tokenizer: The tokenizer to process text.\n    has_image: Whether the input data has image.\nReturns:\n    The input_ids and labels for the model.", "x": 920.0, "y": -750.0}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "label": "preprocess_llama_from_llava_v1()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This function add the prompt and then put the image after the prompt.\nSo it needs additional code to generate the target label.\nArgs:\n    sources: The input data with text and image.\n    tokenizer: The tokenizer to process text.\n    has_image: Whether the input data has image.\nReturns:\n    The input\u2026", "x": 920.0, "y": -675.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::DataCollatorForSupervisedDataset", "label": "DataCollatorForSupervisedDataset()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::DataCollatorForSupervisedDataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Collate examples for supervised fine-tuning.", "x": 0.0, "y": -4837.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__init__", "label": "__init__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 112.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__len__", "label": "__len__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__len__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -4687.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer", "label": "register_tokenizer()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1387.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "label": "__getitem__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__getitem__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -750.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::insert_separator", "label": "insert_separator()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::insert_separator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 1380.0, "y": -225.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::__call__", "label": "__call__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::__call__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -4762.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.datasets.multi_modal_dataset::expand2square", "label": "expand2square()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.multi_modal_dataset::expand2square\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.multi_modal_dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/multi_modal_dataset.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -825.0}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::Dataset", "label": "Dataset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::Dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes the Dataset object with the given parameters.\n\nParameters\n------------\ndata_args : DatasetArguments object.\n    Contains the arguments required to load the dataset.\n\nbackend : str,  default=\"huggingface\"\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nargs : Op\u2026", "x": 1380.0, "y": -525.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -5212.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::__len__", "label": "__len__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::__len__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -5137.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::_check_instance_format", "label": "_check_instance_format()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::_check_instance_format\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Checks if data (instances) have required fields. \nRaises messages with hints if not matched.", "x": 1840.0, "y": -225.0}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::_check_hf_json_format", "label": "_check_hf_json_format()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::_check_hf_json_format\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function", "x": 1610.0, "y": -337.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::from_dict", "label": "from_dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::from_dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Create a Dataset object from a dictionary.\n\nReturn a Dataset given a dict with format:\n    {\n        \"type\": TYPE,\n        \"instances\": [\n            {\n                \"key_1\": VALUE_1.1,\n                \"key_2\": VALUE_1.2,\n                ...\n            },\n            {\n                \"key_1\": VA\u2026", "x": 1610.0, "y": -262.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::create_from_dict", "label": "create_from_dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::create_from_dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n--------\n\nReturns a Dataset object given a dict.", "x": 1380.0, "y": -450.0}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::to_dict", "label": "to_dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::to_dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nReturn a dict represents the dataset:\n    {\n        \"type\": TYPE,\n        \"instances\": [\n            {\n                \"key_1\": VALUE_1.1,\n                \"key_2\": VALUE_1.2,\n                ...\n            },\n            {\n                \"key_1\": VALUE_2.1,\n                \"key_\u2026", "x": 1610.0, "y": 262.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::to_list", "label": "to_list()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::to_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns a list of instances.", "x": 460.0, "y": 37.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::map", "label": "map()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::map\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Parameters\n------------\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n---------\n\nself : Dataset object.", "x": 1610.0, "y": 187.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_backend", "label": "get_backend()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_backend\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.backend", "x": 1610.0, "y": -187.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_backend_dataset", "label": "get_backend_dataset()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_backend_dataset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.backend_dataset", "x": 1610.0, "y": -112.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_fingerprint", "label": "get_fingerprint()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_fingerprint\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nFingerprint of the backend_dataset which controls the cache", "x": 1610.0, "y": 37.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_data_args", "label": "get_data_args()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_data_args\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.data_args", "x": 1610.0, "y": -37.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::get_type", "label": "get_type()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::get_type\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns\n---------\n\nself.type", "x": 1840.0, "y": -150.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::save", "label": "save()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save the dataset to a json file.\n\nParameters\n------------\nfile_path : str.\n    The path to the file where the dataset will be saved.", "x": 0.0, "y": -4912.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::sample", "label": "sample()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::sample\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Sample n instances from the dataset.\n\nParameters\n------------\nn : int.\n    The number of instances to sample from the dataset.\n\nReturns\n---------\n\nsample_dataset : Dataset object.\n    A new dataset object containing the sampled instances.", "x": 0.0, "y": -4987.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::train_test_split", "label": "train_test_split()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::train_test_split\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Split the dataset into training and testing sets.\n\nParameters\n------------\ntest_size : float, default=0.2.\n    The proportion of the dataset that will be used for testing.\n\nReturns\n---------\n\ntrain_dataset : Dataset object.\n    A new dataset object containing the training instances.\n\ntest_dataset : \u2026", "x": 1380.0, "y": -300.0}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::drop_instances", "label": "drop_instances()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::drop_instances\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Drop instances from the dataset.\n\nParameters\n------------\nindices : list.\n    A list of indices of the instances to drop from the dataset.", "x": 0.0, "y": -5062.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::sanity_check", "label": "sanity_check()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::sanity_check\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform a sanity check on the dataset.", "x": 1380.0, "y": -375.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.datasets.dataset::hf_dataset_sanity_check", "label": "hf_dataset_sanity_check()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.datasets.dataset::hf_dataset_sanity_check\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.datasets.dataset\u003cbr\u003eFile: v2/src/lmflow/datasets/dataset.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform a sanity check on the HuggingFace dataset.", "x": 1610.0, "y": 112.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.lamb::Lamb", "label": "Lamb()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.lamb::Lamb\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lamb\u003cbr\u003eFile: v2/src/lmflow/optim/lamb.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements Lamb algorithm.\n\nIt has been proposed in `Large Batch Optimization for Deep Learning:\nTraining BERT in 76 minutes`\nhttps://arxiv.org/abs/1904.00962\n\nNote:\n    Reference code: https://github.com/cybertronai/pytorch-lamb", "x": 0.0, "y": 937.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.lamb::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lamb::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lamb\u003cbr\u003eFile: v2/src/lmflow/optim/lamb.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1162.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.lamb::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lamb::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lamb\u003cbr\u003eFile: v2/src/lmflow/optim/lamb.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": 1012.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::Adan", "label": "Adan()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::Adan\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements a pytorch variant of Adan.\n\nAdan was proposed in\nAdan : Adaptive Nesterov Momentum Algorithm for Faster Optimizing Deep Models.\nhttps://arxiv.org/abs/2208.06677", "x": 0.0, "y": 562.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::_single_tensor_adan", "label": "_single_tensor_adan()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::_single_tensor_adan\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1012.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::_multi_tensor_adan", "label": "_multi_tensor_adan()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::_multi_tensor_adan\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 937.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 787.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 862.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::restart_opt", "label": "restart_opt()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::restart_opt\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 637.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.adan::step", "label": "step()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adan::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adan\u003cbr\u003eFile: v2/src/lmflow/optim/adan.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.", "x": 0.0, "y": 712.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.lars::LARS", "label": "LARS()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::LARS\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Extends SGD in PyTorch with LARS scaling from the paper\n`Large batch training of Convolutional Networks`__.\n.. note::\n    The application of momentum in the SGD part is modified according to\n    the PyTorch standards. LARS scaling fits into the equation in the\n    following fashion.\n\n    .. math::\n \u2026", "x": 0.0, "y": 1087.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.lars::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1237.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.lars::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1312.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.optim.lars::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.lars::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.lars\u003cbr\u003eFile: v2/src/lmflow/optim/lars.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": 1162.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::Adamax", "label": "Adamax()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::Adamax\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -187.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 412.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 487.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamax::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamax::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamax\u003cbr\u003eFile: v2/src/lmflow/optim/adamax.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -112.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree", "label": "SGDScheduleFree()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Schedule-Free SGD\nAs the name suggests, no scheduler is needed with this optimizer. \nTo add warmup, rather than using a learning rate schedule you can just\nset the warmup_steps parameter.\n\nThis optimizer requires that .train() and .eval() be called before the\nbeginning of training and evaluation res\u2026", "x": 0.0, "y": 1837.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1987.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::eval", "label": "eval()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::eval\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 1912.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::train", "label": "train()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 2062.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.sgd_schedule_free::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgd_schedule_free::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgd_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/sgd_schedule_free.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": 0.0, "y": 1987.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::AdamP", "label": "AdamP()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::AdamP\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements AdamP algorithm.\n\nIt has been proposed in `Slowing Down the Weight Norm Increase in\nMomentum-based Optimizers`\nhttps://arxiv.org/abs/2006.08217\n\nNote:\n    Reference code: https://github.com/clovaai/AdamP", "x": 0.0, "y": -37.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 562.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_channel_view", "label": "_channel_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_channel_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 37.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_layer_view", "label": "_layer_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_layer_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 112.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_cosine_similarity", "label": "_cosine_similarity()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_cosine_similarity\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 487.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::_projection", "label": "_projection()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::_projection\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 637.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.optim.adamp::step", "label": "step()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adamp::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamp\u003cbr\u003eFile: v2/src/lmflow/optim/adamp.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": 187.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::AdaBelief", "label": "AdaBelief()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::AdaBelief\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements AdaBelief algorithm. Modified from Adam in PyTorch\nreference: AdaBelief Optimizer, adapting stepsizes by the belief in observed gradients, NeurIPS 2020", "x": 0.0, "y": -1012.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -112.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -37.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::reset", "label": "reset()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::reset\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -937.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adabelief::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabelief::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabelief\u003cbr\u003eFile: v2/src/lmflow/optim/adabelief.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": 0.0, "y": -862.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adagrad::AdaGrad", "label": "AdaGrad()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adagrad::AdaGrad\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adagrad\u003cbr\u003eFile: v2/src/lmflow/optim/adagrad.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -487.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adagrad::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adagrad::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adagrad\u003cbr\u003eFile: v2/src/lmflow/optim/adagrad.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 262.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adagrad::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adagrad::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adagrad\u003cbr\u003eFile: v2/src/lmflow/optim/adagrad.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -412.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.novograd::NovoGrad", "label": "NovoGrad()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::NovoGrad\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 1537.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.novograd::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1687.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.novograd::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1762.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.novograd::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.novograd::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.novograd\u003cbr\u003eFile: v2/src/lmflow/optim/novograd.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 1612.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.yogi::Yogi", "label": "Yogi()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.yogi::Yogi\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.yogi\u003cbr\u003eFile: v2/src/lmflow/optim/yogi.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements Yogi Optimizer Algorithm.\nIt has been proposed in `Adaptive methods for Nonconvex Optimization`.\n\nhttps://papers.nips.cc/paper/8186-adaptive-methods-for-nonconvex-optimization  # noqa\n\nNote:\n    Reference code: https://github.com/4rtemi5/Yogi-Optimizer_Keras", "x": 0.0, "y": 2662.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.yogi::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.yogi::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.yogi\u003cbr\u003eFile: v2/src/lmflow/optim/yogi.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2362.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.yogi::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.yogi::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.yogi\u003cbr\u003eFile: v2/src/lmflow/optim/yogi.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": 2737.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.radam::RAdam", "label": "RAdam()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::RAdam\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements RAdam optimization algorithm.\n\nNote:\n    Deprecated, please use version provided by PyTorch_.\n\nIt has been proposed in `On the Variance of the Adaptive Learning\nRate and Beyond`.\nhttps://arxiv.org/abs/1908.03265\n\nNote:\n    Reference code: https://github.com/LiyuanLucasLiu/RAdam", "x": 0.0, "y": 1687.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.radam::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1837.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.radam::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1912.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.radam::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.radam::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.radam\u003cbr\u003eFile: v2/src/lmflow/optim/radam.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": 1762.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.adam::Adam", "label": "Adam()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adam::Adam\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adam\u003cbr\u003eFile: v2/src/lmflow/optim/adam.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -337.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.adam::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adam::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adam\u003cbr\u003eFile: v2/src/lmflow/optim/adam.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 337.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.adam::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adam::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adam\u003cbr\u003eFile: v2/src/lmflow/optim/adam.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -262.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree", "label": "AdamWScheduleFree()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Schedule-Free AdamW\nAs the name suggests, no scheduler is needed with this optimizer. \nTo add warmup, rather than using a learning rate schedule you can just\nset the warmup_steps parameter.\n\nThis optimizer requires that .train() and .eval() be called before the\nbeginning of training and evaluation r\u2026", "x": 0.0, "y": 262.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 712.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::eval", "label": "eval()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::eval\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 337.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::train", "label": "train()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::train\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 487.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.optim.adamw_schedule_free::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adamw_schedule_free::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adamw_schedule_free\u003cbr\u003eFile: v2/src/lmflow/optim/adamw_schedule_free.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": 0.0, "y": 412.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.sophia::SophiaG", "label": "SophiaG()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::SophiaG\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training.\nCode from: https://github.com/Liuhong99/Sophia/", "x": 0.0, "y": 2437.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.sophia::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2212.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.sophia::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2287.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.sophia::update_hessian", "label": "update_hessian()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::update_hessian\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 2587.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.sophia::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sophia::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sophia\u003cbr\u003eFile: v2/src/lmflow/optim/sophia.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 2512.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabound::AdaBound", "label": "AdaBound()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::AdaBound\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements AdaBound algorithm.\n\nIt has been proposed in `Adaptive Gradient Methods with Dynamic Bound of\nLearning Rate\nhttps://arxiv.org/abs/1902.09843\nNote:\n    Reference code: https://github.com/Luolc/AdaBound", "x": 0.0, "y": -787.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabound::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 37.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabound::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 112.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adabound::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adabound::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adabound\u003cbr\u003eFile: v2/src/lmflow/optim/adabound.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": -712.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.nadam::NAdam", "label": "NAdam()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::NAdam\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 1387.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.nadam::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1537.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.nadam::__setstate__", "label": "__setstate__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::__setstate__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1612.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.nadam::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.nadam::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.nadam\u003cbr\u003eFile: v2/src/lmflow/optim/nadam.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 1462.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.muon::zeropower_via_newtonschulz5", "label": "zeropower_via_newtonschulz5()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::zeropower_via_newtonschulz5\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a\nquintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose\nof minimizing steps, it turns out to be empirically effective to keep increasing the slope at\nzero even beyon\u2026", "x": 230.0, "y": 1462.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.muon::Muon", "label": "Muon()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::Muon\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Adam optimizer with orthogonalization step.", "x": 0.0, "y": 1237.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.muon::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1387.5}, {"borderWidth": 2, "color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.optim.muon::step", "label": "step()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.muon::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.muon\u003cbr\u003eFile: v2/src/lmflow/optim/muon.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArgs:\n    closure (callable, optional): A closure that reevaluates the model\n        and returns the loss.", "x": 0.0, "y": 1312.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::SGDP", "label": "SGDP()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::SGDP\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Implements SGDP algorithm.\n\nIt has been proposed in `Slowing Down the Weight Norm Increase in\nMomentum-based Optimizers`.\nhttps://arxiv.org/abs/2006.08217\n\nNote:\n    Reference code: https://github.com/clovaai/AdamP", "x": 0.0, "y": 2137.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2062.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_channel_view", "label": "_channel_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_channel_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 2212.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_layer_view", "label": "_layer_view()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_layer_view\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 2287.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_cosine_similarity", "label": "_cosine_similarity()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_cosine_similarity\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 562.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::_projection", "label": "_projection()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::_projection\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 2137.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.sgdp::step", "label": "step()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.sgdp::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.sgdp\u003cbr\u003eFile: v2/src/lmflow/optim/sgdp.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure: A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": 2362.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.dummy::Dummy", "label": "Dummy()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.dummy::Dummy\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.dummy\u003cbr\u003eFile: v2/src/lmflow/optim/dummy.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: An dummy optimizer that does nothing.\n\nParameters:\n    params (:obj:`Iterable[nn.parameter.Parameter]`):\n        Iterable of parameters to optimize or dictionaries defining parameter groups.\n    lr (:obj:`float`, `optional`, defaults to 0):\n        The learning rate to use.", "x": 0.0, "y": 787.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.dummy::__init__", "label": "__init__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.optim.dummy::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.dummy\u003cbr\u003eFile: v2/src/lmflow/optim/dummy.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 1087.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.optim.dummy::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.dummy::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.dummy\u003cbr\u003eFile: v2/src/lmflow/optim/dummy.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs a single optimization step.\n\nArguments:\n    closure (:obj:`Callable`, `optional`): A closure that reevaluates the model and returns the loss.", "x": 0.0, "y": 862.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adadelta::Adadelta", "label": "Adadelta()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.optim.adadelta::Adadelta\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adadelta\u003cbr\u003eFile: v2/src/lmflow/optim/adadelta.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -637.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adadelta::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adadelta::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adadelta\u003cbr\u003eFile: v2/src/lmflow/optim/adadelta.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 187.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.optim.adadelta::step", "label": "step()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.optim.adadelta::step\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.optim.adadelta\u003cbr\u003eFile: v2/src/lmflow/optim/adadelta.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -562.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::SeparatorStyle", "label": "SeparatorStyle()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::SeparatorStyle\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Different separator style.", "x": 0.0, "y": 14212.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "label": "Conversation()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::Conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A class that keeps all conversation history.", "x": 1380.0, "y": 525.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt", "label": "get_prompt()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::get_prompt\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 750.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::append_message", "label": "append_message()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::append_message\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 600.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::get_images", "label": "get_images()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::get_images\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 1610.0, "y": 487.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::to_gradio_chatbot", "label": "to_gradio_chatbot()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::to_gradio_chatbot\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14287.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::copy", "label": "copy()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::copy\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 1380.0, "y": 600.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::dict", "label": "dict()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::dict\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 675.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.llava_conversation_lib::expand2square", "label": "expand2square()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.llava_conversation_lib::expand2square\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.llava_conversation_lib\u003cbr\u003eFile: v2/src/lmflow/utils/llava_conversation_lib.py\u003cbr\u003eKind: Function", "x": 1840.0, "y": 225.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.utils.multimodal::update_custom_config", "label": "update_custom_config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.multimodal::update_custom_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.multimodal\u003cbr\u003eFile: v2/src/lmflow/utils/multimodal.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6412.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.utils.multimodal::load_llava_pretrain_model", "label": "load_llava_pretrain_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.multimodal::load_llava_pretrain_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.multimodal\u003cbr\u003eFile: v2/src/lmflow/utils/multimodal.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6337.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.utils.multimodal::adapt_llava_model_to_lmflow_type", "label": "adapt_llava_model_to_lmflow_type()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.multimodal::adapt_llava_model_to_lmflow_type\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.multimodal\u003cbr\u003eFile: v2/src/lmflow/utils/multimodal.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 3262.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.model::check_homogeneity", "label": "check_homogeneity()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.model::check_homogeneity\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.model\u003cbr\u003eFile: v2/src/lmflow/utils/model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14362.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::set_random_seed", "label": "set_random_seed()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::set_random_seed\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Set the random seed for `random`, `numpy`, `torch`, `torch.cuda`.\n\nParameters\n------------\nseed : int\n    The default seed.\n    ", "x": 920.0, "y": 1125.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::load_data", "label": "load_data()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::load_data\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load data with file name.\n\nParameters\n------------\nfile_name : str.\n    The dataset file name.\n\nReturns\n------------\ninputs : list.\n    The input texts of the dataset.\noutputs : list.\n    The output texts file datasets.    \nlen : int.\n    The length of the dataset.", "x": 0.0, "y": 12262.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::batchlize", "label": "batchlize()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::batchlize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Convert examples to a dataloader.\n\nParameters\n------------\nexamples : list.\n    Data list.\nbatch_size : int.\n\nrandom_shuffle : bool\n    If true, the dataloader shuffle the training data.\n\nReturns\n------------\ndataloader:\n    Dataloader with batch generator.", "x": 1150.0, "y": 525.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::preview_file", "label": "preview_file()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::preview_file\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns the first and last specified number of characters from a file\nwithout loading the entire file into memory, working with any file type.\n\nArgs:\n    file_path (str): Path to the file to be previewed\n    chars (int, optional): Number of characters to show from start and end. Defaults to 100.\n\nRe\u2026", "x": 2070.0, "y": -37.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast", "label": "get_dataset_type_fast()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::get_dataset_type_fast\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Get the type values from the first and last n lines of a large json dataset.\n    ", "x": 1840.0, "y": 150.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast", "label": "check_dataset_instances_key_fast()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Check if the dataset instances key matches the instance_key.\n    ", "x": 1840.0, "y": 75.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::answer_extraction", "label": "answer_extraction()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::answer_extraction\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Use this funtion to extract answers from generated text\n\nParameters\n------------\nargs : \n    Arguments.\nresponse : str\n    plain string response.\n\n\nReturns\n------------\nanswer:\n    Decoded answer (such as A, B, C, D, E for mutiple-choice QA).", "x": 0.0, "y": 12187.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::process_image_flag", "label": "process_image_flag()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::process_image_flag\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12337.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::VLLMInferenceResultWithInput", "label": "VLLMInferenceResultWithInput()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::VLLMInferenceResultWithInput\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 12112.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.data_utils::RewardModelInferenceResultWithInput", "label": "RewardModelInferenceResultWithInput()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.data_utils::RewardModelInferenceResultWithInput\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.data_utils\u003cbr\u003eFile: v2/src/lmflow/utils/data_utils.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 12037.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass", "label": "make_shell_args_from_dataclass()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.common::make_shell_args_from_dataclass\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return a string or a list of strings that can be used as shell arguments.\n\nParameters\n----------\ndataclass_objects : List\n    A list of dataclass objects.\nformat : str, optional\n    Return format, can be \"shell\" or \"subprocess\", by default \"subprocess\".\nskip_default : bool, optional\n    Whether to s\u2026", "x": 920.0, "y": 1050.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.common::create_copied_dataclass", "label": "create_copied_dataclass()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.common::create_copied_dataclass\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Create a copied dataclass with new field names and default values.\n\nParameters\n----------\noriginal_dataclass : dataclass\nfield_prefix : str\n    The prefix to add to the **field** names of the copied dataclass.\nclass_prefix : str\n    The prefix to add to the **class** name of the copied dataclass.\nne\u2026", "x": 0.0, "y": 10462.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.common::remove_dataclass_attr_prefix", "label": "remove_dataclass_attr_prefix()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.common::remove_dataclass_attr_prefix\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Remove the prefix from the attribute names of a dataclass instance.\n\nParameters\n----------\ndata_instance : dataclass\nprefix : str\n    The prefix to remove from the attribute names of the dataclass instance.\n\nReturns\n-------\nDict", "x": 230.0, "y": 5437.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.common::add_dataclass_attr_prefix", "label": "add_dataclass_attr_prefix()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.common::add_dataclass_attr_prefix\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add the prefix to the attribute names of a dataclass instance.\n\nParameters\n----------\ndata_instance : dataclass\nprefix : str\n    The prefix to add to the attribute names of the dataclass instance.\n\nReturns\n-------\nDict", "x": 690.0, "y": 2025.0}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.common::print_banner", "label": "print_banner()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.common::print_banner\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.common\u003cbr\u003eFile: v2/src/lmflow/utils/common.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2887.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::get_python_version", "label": "get_python_version()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::get_python_version\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6562.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::_is_package_available", "label": "_is_package_available()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::_is_package_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 2070.0, "y": 37.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::_is_packages_available", "label": "_is_packages_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::_is_packages_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 3412.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_package_version_at_least", "label": "is_package_version_at_least()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_package_version_at_least\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14812.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_gradio_available", "label": "is_gradio_available()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_gradio_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14737.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_ray_available", "label": "is_ray_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_ray_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": 825.0}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_vllm_available", "label": "is_vllm_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_vllm_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 1840.0, "y": 300.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_flash_attn_available", "label": "is_flash_attn_available()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_flash_attn_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14587.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_flask_available", "label": "is_flask_available()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_flask_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14662.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_trl_available", "label": "is_trl_available()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_trl_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14887.5}, {"color": "#5D7092", "fixed": true, "id": "v2.src.lmflow.utils.versioning::is_multimodal_available", "label": "is_multimodal_available()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.versioning::is_multimodal_available\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.versioning\u003cbr\u003eFile: v2/src/lmflow/utils/versioning.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6637.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplate", "label": "Llama2ConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.llama\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/llama.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 11662.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplateForTool", "label": "Llama2ConversationTemplateForTool()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.llama::Llama2ConversationTemplateForTool\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.llama\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/llama.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 11737.5}, {"color": "#5AD8A6", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.llama::_encode", "label": "_encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.llama::_encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.llama\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/llama.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 11812.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.zephyr::ZephyrConversationTemplate", "label": "ZephyrConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.zephyr::ZephyrConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.zephyr\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/zephyr.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 11887.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.zephyr::_encode", "label": "_encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.zephyr::_encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.zephyr\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/zephyr.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 11962.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.gemma::GemmaConversationTemplate", "label": "GemmaConversationTemplate()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.gemma::GemmaConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.gemma\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/gemma.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 11437.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.gemma::encode_conversation", "label": "encode_conversation()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.gemma::encode_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.gemma\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/gemma.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5812.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::TemplateComponent", "label": "TemplateComponent()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::TemplateComponent\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The minimal unit of a template, which can be a token, a string, or a list of tools.\n\nParameters\n----------\ntype : Literal[\u0027token\u0027, \u0027token_id\u0027, \u0027string\u0027, \u0027tools\u0027]\n    - Type of the component.  \n    \n    - When the component is a token or a string, the content should be `string`. \n    The difference b\u2026", "x": 230.0, "y": 5512.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::Formatter", "label": "Formatter()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::Formatter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 10762.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::EmptyFormatter", "label": "EmptyFormatter()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::EmptyFormatter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 10687.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::StringFormatter", "label": "StringFormatter()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::StringFormatter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 10837.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "label": "ConversationTemplate()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::ConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 10537.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "label": "ConversationTemplateForTool()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 10612.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::__post_init__", "label": "__post_init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::__post_init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 10912.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::__repr__", "label": "__repr__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::__repr__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 10987.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::__str__", "label": "__str__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::__str__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 11062.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::format", "label": "format()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::format\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 11362.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::has_placeholder", "label": "has_placeholder()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::has_placeholder\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5662.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::encode_conversation", "label": "encode_conversation()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::encode_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Messages here should be guaranteed to be in pairs, with the first message being the user message and the second message being the system message.\nData example: \n```json\n{\n    \"conversation_id\": 2,\n    \"system\": \"sysinfo1\",\n    \"tools\": [\"tool_1_desc\"],\n    \"messages\": [\n        {\n            \"role\":\u2026", "x": 0.0, "y": 11287.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_encode", "label": "_encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 11137.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_encode_template", "label": "_encode_template()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_encode_template\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Encode template components into token ids.\n\nParameters\n----------\ntemplate : List[TemplateComponent]\n    Formatted template components.\ntokenizer : PreTrainedTokenizer\n    Tokenizer to convert tokens into token ids.\n\nReturns\n-------\nList[int]\n    Encoded token ids.", "x": 0.0, "y": 11212.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "label": "post_process_pairs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::post_process_pairs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5737.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator", "label": "remove_last_separator()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::remove_last_separator\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 3112.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::add_special_starter", "label": "add_special_starter()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::add_special_starter\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 2962.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper", "label": "add_special_stopper()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::add_special_stopper\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 3037.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list", "label": "_ensure_id_list()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_ensure_id_list\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Make sure the object is a list of integers. Useful for handling token ids.\n        ", "x": 690.0, "y": 2100.0}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.base::_handle_tools", "label": "_handle_tools()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.base::_handle_tools\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.base\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/base.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5587.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.hymba::HymbaConversationTemplate", "label": "HymbaConversationTemplate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.hymba::HymbaConversationTemplate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.hymba\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/hymba.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 11512.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.utils.conversation_template.hymba::_handle_tools", "label": "_handle_tools()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.conversation_template.hymba::_handle_tools\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.conversation_template.hymba\u003cbr\u003eFile: v2/src/lmflow/utils/conversation_template/hymba.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 11587.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::CondenseRotaryEmbedding", "label": "CondenseRotaryEmbedding()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::CondenseRotaryEmbedding\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 14437.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::replace_llama_with_condense", "label": "replace_llama_with_condense()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::replace_llama_with_condense\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 3337.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::__init__", "label": "__init__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6487.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch\u003cbr\u003eFile: v2/src/lmflow/utils/position_interpolation/llama_rope_scaled_monkey_patch.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14512.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt2_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt2_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt2_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt2_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13087.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt2_flash_attention::_prepare_decoder_attention_mask", "label": "_prepare_decoder_attention_mask()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt2_flash_attention::_prepare_decoder_attention_mask\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt2_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt2_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13012.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt2_flash_attention::replace_gpt2_attn_with_flash_attn", "label": "replace_gpt2_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt2_flash_attention::replace_gpt2_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt2_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt2_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13162.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::_attn", "label": "_attn()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt_neo_flash_attention.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5962.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::forward", "label": "forward()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt_neo_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13237.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::replace_gpt_neo_attn_with_flash_attn", "label": "replace_gpt_neo_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::replace_gpt_neo_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/gpt_neo_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13312.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.bloom_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.bloom_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.bloom_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/bloom_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12862.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.bloom_flash_attention::_prepare_attn_mask", "label": "_prepare_attn_mask()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.bloom_flash_attention::_prepare_attn_mask\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.bloom_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/bloom_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12787.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.bloom_flash_attention::replace_bloom_attn_with_flash_attn", "label": "replace_bloom_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.bloom_flash_attention::replace_bloom_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.bloom_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/bloom_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12937.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_fwd_kernel", "label": "_fwd_kernel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_fwd_kernel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13987.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_preprocess_do_o_dot", "label": "_bwd_preprocess_do_o_dot()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_preprocess_do_o_dot\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13912.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv", "label": "_bwd_store_dk_dv()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 460.0, "y": 3187.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block", "label": "_bwd_kernel_one_col_block()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6037.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero", "label": "init_to_zero()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6262.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "label": "_bwd_kernel()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13837.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward", "label": "_flash_attn_forward()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6187.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward", "label": "_flash_attn_backward()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 6112.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc", "label": "FlashAttnQKVPackedFunc()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 13762.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc", "label": "FlashAttnKVPackedFunc()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 13687.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc", "label": "FlashAttnFunc()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 13612.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::forward", "label": "forward()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: qkv: (batch, seqlen, 3, nheads, headdim)\nbias: optional, shape broadcastible to (batch, nheads, seqlen, seqlen).\n    For example, ALiBi mask for causal would have shape (1, nheads, 1, seqlen).\n    ALiBi mask for non-causal would have shape (1, nheads, seqlen, seqlen)", "x": 0.0, "y": 14137.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::backward", "label": "backward()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.triton_flash_attention::backward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.triton_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/triton_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 14062.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.llama_flash_attention::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.llama_flash_attention::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.llama_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/llama_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13462.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.llama_flash_attention::_prepare_decoder_attention_mask", "label": "_prepare_decoder_attention_mask()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.llama_flash_attention::_prepare_decoder_attention_mask\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.llama_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/llama_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13387.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.utils.flash_attention.llama_flash_attention::replace_llama_attn_with_flash_attn", "label": "replace_llama_attn_with_flash_attn()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.flash_attention.llama_flash_attention::replace_llama_attn_with_flash_attn\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.flash_attention.llama_flash_attention\u003cbr\u003eFile: v2/src/lmflow/utils/flash_attention/llama_flash_attention.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 13537.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::Timer", "label": "Timer()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::Timer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Class", "x": 0.0, "y": 12412.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12487.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::start", "label": "start()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::start\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 920.0, "y": 1200.0}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::end", "label": "end()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::end\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12562.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::get_runtime", "label": "get_runtime()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::get_runtime\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12637.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::show", "label": "show()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::show\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 12712.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.utils.debug.profiler::_to_readable", "label": "_to_readable()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.utils.debug.profiler::_to_readable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.utils.debug.profiler\u003cbr\u003eFile: v2/src/lmflow/utils/debug/profiler.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5887.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "label": "HFEncoderDecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a HFEncoderDecoderModel instance.\n\nParameters\n------------\n\nmodel_args :\n    Model arguments such as model name, path, revision, etc.\n\ntune_strategy : str or none,  default=\"normal\".\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nds_config :\n    Deepspeed conf\u2026", "x": 460.0, "y": 262.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFDecoderModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.\n:param tune_strategy: tuning strategy: normal, none, lora or adapter\n:param ds_config: deepspeed configuration for distributed training", "x": 0.0, "y": -3637.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::tokenize", "label": "tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize the full dataset.\n\nParameters\n------------\ndataset :\n    Text dataset.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\ntokenized_datasets :\n    The tokenized dataset.", "x": 0.0, "y": -3187.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::encode", "label": "encode()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform encoding process of the tokenizer.\n\nParameters\n------------\ninputs : str or list.\n    The text sequence.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The tokenized inputs.", "x": 0.0, "y": -3562.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::decode", "label": "decode()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::decode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform decoding process of the tokenizer.\n\nParameters\n------------\ninputs : list.\n    The token sequence.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The text decoded from the token inputs.", "x": 690.0, "y": -375.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "label": "inference()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The sequence used as a prompt for the generation or as model inputs to the model.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The generated se\u2026", "x": 0.0, "y": -3412.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::merge_lora_weights", "label": "merge_lora_weights()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::merge_lora_weights\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -3337.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::save", "label": "save()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ndir :\n    The directory to save model and tokenizer\n\nsave_full_model : Optional.\n    Whether to save full model.\n\nkwargs : Optional.\n    Keyword arguments.\n\nReturns\n------------\noutputs :\n    The generated sequence output", "x": 0.0, "y": -3262.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::get_max_length", "label": "get_max_length()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::get_max_length\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return max acceptable input length in terms of tokens.", "x": 0.0, "y": -3487.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer", "label": "get_tokenizer()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the tokenizer of the model.", "x": 690.0, "y": -300.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model", "label": "get_backend_model()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_encoder_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the backend model.", "x": 230.0, "y": -937.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::TextRegressionModel", "label": "TextRegressionModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::TextRegressionModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a TextRegressionModel instance.\n\nParameters\n------------\n\nmodel_args : \n    Model arguments such as model name, path, revision, etc.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    ", "x": 0.0, "y": -2287.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a TextRegressionModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.", "x": 0.0, "y": -2212.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::register_inference_function", "label": "register_inference_function()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::register_inference_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Registers a regression function.", "x": 0.0, "y": -2062.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.text_regression_model::inference", "label": "inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.text_regression_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Gets regression results of a given dataset.\n\n:inputs: Dataset object, only accept type \"text_only\".", "x": 0.0, "y": -2137.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.auto_model::AutoModel", "label": "AutoModel()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.auto_model::AutoModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.auto_model\u003cbr\u003eFile: v2/src/lmflow/models/auto_model.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -4612.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.auto_model::get_model", "label": "get_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.auto_model::get_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.auto_model\u003cbr\u003eFile: v2/src/lmflow/models/auto_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1312.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "label": "HFDecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::HFDecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a HFDecoderModel instance.\n\nParameters\n------------\n\nmodel_args : \n    Model arguments such as model name, path, revision, etc.\n\ntune_strategy : str or none,  default=\"normal\".\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nds_config :   \n    Deepspeed configu\u2026", "x": 460.0, "y": 187.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__init__", "label": "__init__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFDecoderModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.\n:param tune_strategy: tuning strategy: normal, none, lora or adapter\n:param ds_config: deepspeed configuration for distributed training", "x": 690.0, "y": -600.0}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::tokenize", "label": "tokenize()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize the full dataset.\n\nParameters\n------------\ndataset : lmflow.datasets.Dataset.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\ntokenized_datasets :\n    The tokenized dataset, without any leading or trailing special\n    tokens (\u2026", "x": 0.0, "y": -3712.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::encode", "label": "encode()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::encode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform encoding process of the tokenizer.\n\nParameters\n------------\ninputs : str or list.\n    The text sequence.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    if string input,return the tokenized inputs.\n    \"Hello,\u2026", "x": 230.0, "y": -1087.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::decode", "label": "decode()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::decode\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform decoding process of the tokenizer.\n\nParameters\n------------\ninputs : list or tensor.\n    The token sequence.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The text decoded from the token inputs.\n    if batch\u2026", "x": 690.0, "y": -450.0}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::inference", "label": "inference()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The sequence used as a prompt for the generation or as model inputs to the model.\n    When using vllm inference, this should be a string or a list of strings.\n    When using normal inference, this should be a tensor.\nrele\u2026", "x": 0.0, "y": -4087.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__inference", "label": "__inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The **tokenized** sequence used as a prompt for the generation or as model inputs to the model.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs \u2026", "x": 690.0, "y": -675.0}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference", "label": "__vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform VLLM inference process of the model.\n\nParameters\n----------\ninputs : Union[str, List[str]]\n    Prompt(s), string or a list of strings.\nsampling_params : Optional[SamplingParams], optional\n    vllm SamplingParams object, by default None.\n\nReturns\n-------\nList[VLLMInferenceResultWithInput]\n   \u2026", "x": 690.0, "y": -525.0}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "label": "prepare_inputs_for_inference()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare inputs for inference.\n\nParameters\n------------\ndataset : lmflow.datasets.Dataset.\n    The dataset used for inference.\n    \nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The prepared inputs for inference.", "x": 0.0, "y": -3937.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "label": "__prepare_inputs_for_vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1162.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_inference", "label": "__prepare_inputs_for_inference()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1237.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::merge_lora_weights", "label": "merge_lora_weights()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::merge_lora_weights\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -4012.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "label": "get_peft_without_qlora()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -1012.5}, {"color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::save", "label": "save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ndir :\n    The directory to save model and tokenizer\n    \nsave_full_model : Optional.\n    Whether to save full model.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The generated sequence output ", "x": 0.0, "y": -3787.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "v2.src.lmflow.models.hf_decoder_model::preprocess_conversation", "label": "preprocess_conversation()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_decoder_model::preprocess_conversation\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -3862.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.encoder_decoder_model::EncoderDecoderModel", "label": "EncoderDecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.encoder_decoder_model::EncoderDecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/encoder_decoder_model.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -4237.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.encoder_decoder_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.encoder_decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.encoder_decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/encoder_decoder_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -4162.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.base_model::BaseModel", "label": "BaseModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.base_model::BaseModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.base_model\u003cbr\u003eFile: v2/src/lmflow/models/base_model.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -4537.5}, {"color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.models.base_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.base_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.base_model\u003cbr\u003eFile: v2/src/lmflow/models/base_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -4462.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "label": "HFTextRegressionModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Initializes a HFTextRegressionModel instance.\n\nParameters\n------------\n\nmodel_args : \n    Model arguments such as model name, path, revision, etc.\n\ntune_strategy : str or none,  default=\"normal\".\n    A string representing the dataset backend. Defaults to \"huggingface\".\n\nds_config :   \n    Deepspeed \u2026", "x": 1150.0, "y": -675.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::__init__", "label": "__init__()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFTextRegressionModel instance.\n:param model_args: dictionary with model arguments such as model name, path, revision, etc.\n:param tune_strategy: tuning strategy: normal, none, lora or adapter\n:param ds_config: deepspeed configuration for distributed training", "x": 1380.0, "y": 75.0}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "label": "tokenize()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::tokenize\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize the full dataset.\n\nParameters\n------------\ndataset : lmflow.datasets.Dataset.\n\nargs : Optional.\n    Positional arguments.\n\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\ntokenized_datasets :\n    The tokenized dataset, without any leading or trailing special\n    tokens (\u2026", "x": 1380.0, "y": 225.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::inference", "label": "inference()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The sequence used as a prompt for the generation or as model inputs to the model.\n    When using vllm inference, this should be a string or a list of strings.\n    When using normal inference, this should be a tensor.\nrele\u2026", "x": 0.0, "y": -2737.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::__inference", "label": "__inference()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::__inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ninputs :\n    The **tokenized** sequence used as a prompt for the generation or as model inputs to the model.\nkwargs : Optional.\n    Keyword arguments.    \n\nReturns\n------------\noutputs :\n    The generated sequence output ", "x": 1380.0, "y": 0.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::__vllm_inference", "label": "__vllm_inference()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::__vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform VLLM inference process of the model.\n\nParameters\n----------\ninputs : Union[str, List[str]]\n    Prompt(s), string or a list of strings.\nsampling_params : Optional[SamplingParams], optional\n    vllm SamplingParams object, by default None.\n\nReturns\n-------", "x": 1380.0, "y": 150.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "label": "prepare_inputs_for_inference()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -2662.5}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "label": "postprocess_inference_outputs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -525.0}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs", "label": "postprocess_distributed_inference_outputs()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -600.0}, {"color": "#F6BD16", "fixed": true, "id": "v2.src.lmflow.models.hf_text_regression_model::save", "label": "save()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_text_regression_model::save\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/models/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Perform generation process of the model.\n\nParameters\n------------\ndir :\n    The directory to save model and tokenizer\n\nkwargs : Optional.\n    Keyword arguments.    ", "x": 0.0, "y": -2587.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "label": "HFModelMixin()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::HFModelMixin\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -3112.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initializes a HFModel instance.\n\nParameters\n----------\nmodel_args : \n    Dictionary with model arguments such as model name, path, revision, etc.\ndo_train : bool\n    To prepare the model for training or inference.\nds_config : optional\n    Deepspeed configuration for distributed training, by default \u2026", "x": 0.0, "y": -3037.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "label": "__prepare_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -412.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_dtype", "label": "__prepare_dtype()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_dtype\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -787.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config", "label": "__prepare_model_config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepare model configuration for hf auto register,\nParameters\n----------\nmodel_args : ModelArguments\n    LMFlow model arguments.\nhf_auto_model_additional_args : Optional[Dict], optional\n    Special configurations such as `num_labels` in `AutoModelForSequenceClassification` \n    (commonly used in rewa\u2026", "x": 230.0, "y": -712.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_quant_config", "label": "__prepare_quant_config()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_quant_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -487.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config", "label": "__prepare_peft_config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_peft_config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -562.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject", "label": "__model_module_inject()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__model_module_inject\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Override some model modules with custom implementations.\n\nCurrent implementations:\n- Position interpolation (model_args.do_rope_scaling): \n    replace llama embeddings with condense embeddings.", "x": 230.0, "y": -862.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "label": "__prepare_model_for_training()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -637.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "label": "__prepare_model_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 1610.0, "y": 337.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference", "label": "__prepare_model_for_vllm_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 1610.0, "y": 412.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process", "label": "__prepare_model_post_process()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 1840.0, "y": -75.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference", "label": "activate_model_for_inference()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::activate_model_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function", "x": 1380.0, "y": -150.0}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference", "label": "deactivate_model_for_inference()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Deactivate the model and release the resources.\n\nNOTE: Currently, VLLM doesn\u0027t have an official way to do this, and the\nimplementation below cannot release all gpu resources by our observation.\nThus this method is just a placeholder for future implementation. See: \n[Github issue](https://github.com/\u2026", "x": 1380.0, "y": -75.0}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::get_max_length", "label": "get_max_length()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::get_max_length\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return max acceptable input length in terms of tokens.", "x": 0.0, "y": -2887.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::get_tokenizer", "label": "get_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::get_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the tokenizer of the model.", "x": 0.0, "y": -2812.5}, {"color": "#269A99", "fixed": true, "id": "v2.src.lmflow.models.hf_model_mixin::get_backend_model", "label": "get_backend_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.hf_model_mixin::get_backend_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.hf_model_mixin\u003cbr\u003eFile: v2/src/lmflow/models/hf_model_mixin.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return the backend model.", "x": 0.0, "y": -2962.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.regression_model::RegressionModel", "label": "RegressionModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.regression_model::RegressionModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.regression_model\u003cbr\u003eFile: v2/src/lmflow/models/regression_model.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -2437.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.regression_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.regression_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.regression_model\u003cbr\u003eFile: v2/src/lmflow/models/regression_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -2362.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "label": "CustomAutoVision2SeqModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -337.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: TODO update the docs\nArgs:\n    config:\n    # the below varaible are used to overwrite the model in config\n    image_encoder_name_or_path:\n    qformer_name_or_path:\n    language_model_name_or_path:\nReturns:", "x": 460.0, "y": 337.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::get_backend_model", "label": "get_backend_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::get_backend_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1912.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::vision_model_from_pretrained", "label": "vision_model_from_pretrained()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::vision_model_from_pretrained\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1462.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::qformer_from_pretrained", "label": "qformer_from_pretrained()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::qformer_from_pretrained\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1687.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained", "label": "language_model_from_pretrained()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::language_model_from_pretrained\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -262.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::vision_feature_select", "label": "vision_feature_select()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::vision_feature_select\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1537.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::register_prompt_cache", "label": "register_prompt_cache()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::register_prompt_cache\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Udpate the prompt id and embedding for reuse in the future\n\nArgs:\n    prompt_ids (torch.LongTensor): The id of the prompt.\n    prompt_keys_values (torch.FloatTensor): The embedding of the prompt.\n\nReturns:\n    None", "x": 460.0, "y": 412.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::save_prompt_cache", "label": "save_prompt_cache()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::save_prompt_cache\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Save prompt embedding and id.\n\nArgs:\n    path: The path to save the prompt embedding and id.\n\nReturns:\n    None", "x": 0.0, "y": -1612.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::load_prompt_cache", "label": "load_prompt_cache()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::load_prompt_cache\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Load prompt embedding and id.\nArgs:\n    path: The path to load the prompt embedding and id.\n\nReturns:\n    None", "x": 0.0, "y": -1762.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::get_tokenizer", "label": "get_tokenizer()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::get_tokenizer\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1837.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::forward", "label": "forward()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1987.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4", "label": "processor_image_token_in_minigpt4()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -450.0}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.vision2seq_model::generate", "label": "generate()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision2seq_model::generate\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision2seq_model\u003cbr\u003eFile: v2/src/lmflow/models/vision2seq_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Overrides `generate` function to be able to use the model as a conditional generator.\n\nArgs:\n    pixel_values (`torch.FloatTensor` of shape (batch_size, num_channels, height, width)):\n        Input images to be processed.\n    input_ids (`torch.LongTensor` of shape (batch_size, sequence_length), *opt\u2026", "x": 920.0, "y": -525.0}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.decoder_model::DecoderModel", "label": "DecoderModel()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.decoder_model::DecoderModel\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/decoder_model.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -4387.5}, {"color": "#9270CA", "fixed": true, "id": "v2.src.lmflow.models.decoder_model::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.decoder_model::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.decoder_model\u003cbr\u003eFile: v2/src/lmflow/models/decoder_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -4312.5}, {"color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.models.interfaces.tunable::Tunable", "label": "Tunable()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.interfaces.tunable::Tunable\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.interfaces.tunable\u003cbr\u003eFile: v2/src/lmflow/models/interfaces/tunable.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -2512.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower", "label": "build_vision_tower()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -225.0}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "label": "CLIPVisionTower()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Class", "x": 920.0, "y": -450.0}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::__init__\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -375.0}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model", "label": "load_model()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::load_model\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 1380.0, "y": 375.0}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images", "label": "encode_images()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::encode_images\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 1380.0, "y": 300.0}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::feature_select", "label": "feature_select()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::feature_select\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -187.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::forward", "label": "forward()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::forward\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1237.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::dummy_feature", "label": "dummy_feature()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::dummy_feature\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1312.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::dtype", "label": "dtype()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::dtype\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 1150.0, "y": -300.0}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::device", "label": "device()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::device\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 1840.0, "y": 0.0}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::config", "label": "config()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::config\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1387.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::hidden_size", "label": "hidden_size()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::hidden_size\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1162.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::num_patches", "label": "num_patches()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::num_patches\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -1087.5}, {"color": "#6DC8EC", "fixed": true, "id": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal", "label": "prepare_inputs_labels_for_multimodal()", "shape": "dot", "title": "\u003cb\u003ev2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.models.vision_encoder.clip_encoder\u003cbr\u003eFile: v2/src/lmflow/models/vision_encoder/clip_encoder.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Copy from the LLAVA code base.\nShould be polished.", "x": 1150.0, "y": -225.0}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_decoder_model::blocking", "label": "blocking()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_decoder_model::blocking\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_decoder_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5137.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_decoder_model::tokenize_function", "label": "tokenize_function()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_decoder_model::tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels text_only and text2text datasets tokenization", "x": 0.0, "y": 10087.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function", "label": "conversation_tokenize_function()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_decoder_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_decoder_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels conversation datasets tokenization", "x": 0.0, "y": 10012.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_paired", "label": "blocking_paired()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::blocking_paired\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5287.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking", "label": "blocking()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::blocking\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5212.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_text_to_textlist", "label": "blocking_text_to_textlist()", "shape": "triangle", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::blocking_text_to_textlist\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 230.0, "y": 5362.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::paired_conversation_tokenize_function", "label": "paired_conversation_tokenize_function()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::paired_conversation_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function", "x": 0.0, "y": 10237.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::conversation_tokenize_function", "label": "conversation_tokenize_function()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::conversation_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels conversation datasets tokenization\n    ", "x": 0.0, "y": 10162.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function", "label": "tokenize_function()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Handels text_only and text2text datasets tokenization\n    ", "x": 0.0, "y": 10387.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "v2.src.lmflow.tokenization.hf_text_regression_model::text_to_textlist_tokenize_function", "label": "text_to_textlist_tokenize_function()", "shape": "box", "title": "\u003cb\u003ev2.src.lmflow.tokenization.hf_text_regression_model::text_to_textlist_tokenize_function\u003c/b\u003e\u003cbr\u003eModule: v2.src.lmflow.tokenization.hf_text_regression_model\u003cbr\u003eFile: v2/src/lmflow/tokenization/hf_text_regression_model.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: For rm inference, and don\u0027t need attn mask and labels.\nNOTE: input_ids here refers to the tokenized input_ids of the input **and** output", "x": 0.0, "y": 10312.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::set_seed", "label": "set_seed()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::set_seed\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -10687.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.eval_llada::LLaDAEvalHarness", "label": "LLaDAEvalHarness()", "shape": "box", "title": "\u003cb\u003ellada.eval_llada::LLaDAEvalHarness\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -11137.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::__init__\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Args:\n    model_path: LLaDA-8B-Base model path.\n    mask_id: The token id of [MASK] is 126336.\n    max_length: the max sequence length.\n    batch_size: mini batch size.\n    mc_num: Monte Carlo estimation iterations\n    is_check_greedy: For certain metrics like LAMBADA, the evaluation requires the mo\u2026", "x": 230.0, "y": -4087.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::rank", "label": "rank()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::rank\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -10762.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::world_size", "label": "world_size()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::world_size\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -10612.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.eval_llada::_forward_process", "label": "_forward_process()", "shape": "triangle", "title": "\u003cb\u003ellada.eval_llada::_forward_process\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1687.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.eval_llada::get_logits", "label": "get_logits()", "shape": "triangle", "title": "\u003cb\u003ellada.eval_llada::get_logits\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1612.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::get_loglikelihood", "label": "get_loglikelihood()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::get_loglikelihood\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -3937.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::suffix_greedy_prediction", "label": "suffix_greedy_prediction()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::suffix_greedy_prediction\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -3862.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.eval_llada::_encode_pair", "label": "_encode_pair()", "shape": "triangle", "title": "\u003cb\u003ellada.eval_llada::_encode_pair\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4012.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.eval_llada::loglikelihood", "label": "loglikelihood()", "shape": "box", "title": "\u003cb\u003ellada.eval_llada::loglikelihood\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -10912.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::loglikelihood_rolling", "label": "loglikelihood_rolling()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::loglikelihood_rolling\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -10837.5}, {"color": "#5D7092", "fixed": true, "id": "llada.eval_llada::generate_until", "label": "generate_until()", "shape": "dot", "title": "\u003cb\u003ellada.eval_llada::generate_until\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -10987.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.eval_llada::_tokenize", "label": "_tokenize()", "shape": "box", "title": "\u003cb\u003ellada.eval_llada::_tokenize\u003c/b\u003e\u003cbr\u003eModule: llada.eval_llada\u003cbr\u003eFile: llada/eval_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11062.5}, {"color": "#269A99", "fixed": true, "id": "llada.postprocess_code::pass_at_1", "label": "pass_at_1()", "shape": "dot", "title": "\u003cb\u003ellada.postprocess_code::pass_at_1\u003c/b\u003e\u003cbr\u003eModule: llada.postprocess_code\u003cbr\u003eFile: llada/postprocess_code.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7912.5}, {"color": "#269A99", "fixed": true, "id": "llada.postprocess_code::read_jsonl", "label": "read_jsonl()", "shape": "dot", "title": "\u003cb\u003ellada.postprocess_code::read_jsonl\u003c/b\u003e\u003cbr\u003eModule: llada.postprocess_code\u003cbr\u003eFile: llada/postprocess_code.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7837.5}, {"color": "#269A99", "fixed": true, "id": "llada.postprocess_code::write_jsonl", "label": "write_jsonl()", "shape": "dot", "title": "\u003cb\u003ellada.postprocess_code::write_jsonl\u003c/b\u003e\u003cbr\u003eModule: llada.postprocess_code\u003cbr\u003eFile: llada/postprocess_code.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7762.5}, {"color": "#5D7092", "fixed": true, "id": "llada.generate::add_gumbel_noise", "label": "add_gumbel_noise()", "shape": "dot", "title": "\u003cb\u003ellada.generate::add_gumbel_noise\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: The Gumbel max is a method for sampling categorical distributions.\nAccording to arXiv:2409.02908, for MDM, low-precision Gumbel Max improves perplexity score but reduces generation quality.\nThus, we use float64.", "x": 690.0, "y": -1200.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.generate::get_num_transfer_tokens", "label": "get_num_transfer_tokens()", "shape": "triangle", "title": "\u003cb\u003ellada.generate::get_num_transfer_tokens\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: block_mask_index: (B, L) bool \u2013 which positions are masked in the current block\nreturns: (B, steps) int \u2013 how many tokens to transfer at each step per batch item", "x": 460.0, "y": -1537.5}, {"color": "#5D7092", "fixed": true, "id": "llada.generate::generate", "label": "generate()", "shape": "dot", "title": "\u003cb\u003ellada.generate::generate\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Args:\n    model: Mask predictor.\n    prompt: A tensor of shape (1, L).\n    steps: Sampling steps, less than or equal to gen_length.\n    gen_length: Generated answer length.\n    block_length: Block length, less than or equal to gen_length. If less than gen_length, it means using semi_autoregressive r\u2026", "x": 230.0, "y": -3787.5}, {"color": "#5D7092", "fixed": true, "id": "llada.generate::generate_with_prefix_cache", "label": "generate_with_prefix_cache()", "shape": "dot", "title": "\u003cb\u003ellada.generate::generate_with_prefix_cache\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Args:\n    model: Mask predictor.\n    prompt: A tensor of shape (1, L).\n    steps: Sampling steps, less than or equal to gen_length.\n    gen_length: Generated answer length.\n    block_length: Block length, less than or equal to gen_length. If less than gen_length, it means using semi_autoregressive r\u2026", "x": 230.0, "y": -3637.5}, {"color": "#5D7092", "fixed": true, "id": "llada.generate::generate_with_dual_cache", "label": "generate_with_dual_cache()", "shape": "dot", "title": "\u003cb\u003ellada.generate::generate_with_dual_cache\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -3712.5}, {"color": "#5D7092", "fixed": true, "id": "llada.generate::get_transfer_index", "label": "get_transfer_index()", "shape": "dot", "title": "\u003cb\u003ellada.generate::get_transfer_index\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns:\n    x0: (B, L) long \u2014 proposed tokens\n    transfer_index: (B, L) bool \u2014 which positions to update this step", "x": 460.0, "y": -1462.5}, {"color": "#5D7092", "fixed": true, "id": "llada.generate::get_transfer_index_dynamic", "label": "get_transfer_index_dynamic()", "shape": "dot", "title": "\u003cb\u003ellada.generate::get_transfer_index_dynamic\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1387.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "llada.generate::main", "label": "main()", "shape": "box", "title": "\u003cb\u003ellada.generate::main\u003c/b\u003e\u003cbr\u003eModule: llada.generate\u003cbr\u003eFile: llada/generate.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -10537.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.chat::chat", "label": "chat()", "shape": "box", "title": "\u003cb\u003ellada.chat::chat\u003c/b\u003e\u003cbr\u003eModule: llada.chat\u003cbr\u003eFile: llada/chat.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11212.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "llada.app::parse_constraints", "label": "parse_constraints()", "shape": "triangle", "title": "\u003cb\u003ellada.app::parse_constraints\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Parse constraints in format: \u0027position:word, position:word, ...\u0027", "x": 230.0, "y": -4162.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "llada.app::format_chat_history", "label": "format_chat_history()", "shape": "triangle", "title": "\u003cb\u003ellada.app::format_chat_history\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Format chat history for the LLaDA model\n\nArgs:\n    history: List of [user_message, assistant_message] pairs\n    \nReturns:\n    Formatted conversation for the model", "x": 230.0, "y": -4387.5}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::add_gumbel_noise", "label": "add_gumbel_noise()", "shape": "dot", "title": "\u003cb\u003ellada.app::add_gumbel_noise\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: The Gumbel max is a method for sampling categorical distributions.\nAccording to arXiv:2409.02908, for MDM, low-precision Gumbel Max improves perplexity score but reduces generation quality.\nThus, we use float64.", "x": 690.0, "y": -1275.0}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "llada.app::get_num_transfer_tokens", "label": "get_num_transfer_tokens()", "shape": "triangle", "title": "\u003cb\u003ellada.app::get_num_transfer_tokens\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: In the reverse process, the interval [0, 1] is uniformly discretized into steps intervals.\nFurthermore, because LLaDA employs a linear noise schedule (as defined in Eq. (8)),\nthe expected number of tokens transitioned at each step should be consistent.\n\nThis function is designed to precompute the nu\u2026", "x": 460.0, "y": -1837.5}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::generate_response_with_visualization_cache_and_parallel", "label": "generate_response_with_visualization_cache_and_parallel()", "shape": "dot", "title": "\u003cb\u003ellada.app::generate_response_with_visualization_cache_and_parallel\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate text with LLaDA model with visualization using the same sampling as in generate.py\n\nArgs:\n    messages: List of message dictionaries with \u0027role\u0027 and \u0027content\u0027\n    gen_length: Length of text to generate\n    steps: Number of denoising steps\n    constraints: Dictionary mapping positions to wor\u2026", "x": 230.0, "y": -4237.5}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::get_transfer_index", "label": "get_transfer_index()", "shape": "dot", "title": "\u003cb\u003ellada.app::get_transfer_index\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1762.5}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::generate_response_with_visualization", "label": "generate_response_with_visualization()", "shape": "dot", "title": "\u003cb\u003ellada.app::generate_response_with_visualization\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate text with LLaDA model with visualization using the same sampling as in generate.py\n\nArgs:\n    messages: List of message dictionaries with \u0027role\u0027 and \u0027content\u0027\n    gen_length: Length of text to generate\n    steps: Number of denoising steps\n    constraints: Dictionary mapping positions to wor\u2026", "x": 230.0, "y": -4312.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "llada.app::create_chatbot_demo", "label": "create_chatbot_demo()", "shape": "box", "title": "\u003cb\u003ellada.app::create_chatbot_demo\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11362.5}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::add_message", "label": "add_message()", "shape": "dot", "title": "\u003cb\u003ellada.app::add_message\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Add a message pair to the history and return the updated history", "x": 230.0, "y": -4462.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "llada.app::user_message_submitted", "label": "user_message_submitted()", "shape": "box", "title": "\u003cb\u003ellada.app::user_message_submitted\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Process a submitted user message", "x": 0.0, "y": -11287.5}, {"borderWidth": 2, "color": "#5B8FF9", "fixed": true, "id": "llada.app::bot_response", "label": "bot_response()", "shape": "box", "title": "\u003cb\u003ellada.app::bot_response\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Generate bot response for the latest message", "x": 0.0, "y": -11512.5}, {"color": "#5B8FF9", "fixed": true, "id": "llada.app::clear_conversation", "label": "clear_conversation()", "shape": "dot", "title": "\u003cb\u003ellada.app::clear_conversation\u003c/b\u003e\u003cbr\u003eModule: llada.app\u003cbr\u003eFile: llada/app.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Clear the conversation history", "x": 0.0, "y": -11437.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.sanitize::refine_text", "label": "refine_text()", "shape": "triangle", "title": "\u003cb\u003ellada.sanitize::refine_text\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -2137.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.sanitize::syntax_check", "label": "syntax_check()", "shape": "triangle", "title": "\u003cb\u003ellada.sanitize::syntax_check\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -337.5}, {"color": "#9270CA", "fixed": true, "id": "llada.sanitize::extract_longest_valid_code", "label": "extract_longest_valid_code()", "shape": "dot", "title": "\u003cb\u003ellada.sanitize::extract_longest_valid_code\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -2512.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.sanitize::get_deps", "label": "get_deps()", "shape": "triangle", "title": "\u003cb\u003ellada.sanitize::get_deps\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -2362.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.sanitize::get_function_dependency", "label": "get_function_dependency()", "shape": "triangle", "title": "\u003cb\u003ellada.sanitize::get_function_dependency\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -2287.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.sanitize::get_definition_name", "label": "get_definition_name()", "shape": "triangle", "title": "\u003cb\u003ellada.sanitize::get_definition_name\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -2437.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.sanitize::has_return_statement", "label": "has_return_statement()", "shape": "triangle", "title": "\u003cb\u003ellada.sanitize::has_return_statement\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -2212.5}, {"borderWidth": 2, "color": "#9270CA", "fixed": true, "id": "llada.sanitize::sanitize", "label": "sanitize()", "shape": "box", "title": "\u003cb\u003ellada.sanitize::sanitize\u003c/b\u003e\u003cbr\u003eModule: llada.sanitize\u003cbr\u003eFile: llada/sanitize.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7687.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::scaled_dot_product_attention", "label": "scaled_dot_product_attention()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::scaled_dot_product_attention\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 920.0, "y": -975.0}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::ModuleType", "label": "ModuleType()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::ModuleType\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -8962.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::init_weights", "label": "init_weights()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::init_weights\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Initialize weights of a linear or embedding module.\n\n:param config: The model config.\n:param module: The linear or embedding submodule to initialize.\n:param d: The effective input dimensionality of the weights. This could be smaller than the actual dimensions\n    for fused layers.\n:param layer_id: W\u2026", "x": 460.0, "y": -412.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::ensure_finite_", "label": "ensure_finite_()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::ensure_finite_\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Modify ``x`` in place to replace ``float(\"-inf\")`` with the minimum value of the dtype when ``check_neg_inf``\nis ``True`` and to replace ``float(\"inf\")`` with the maximum value of the dtype when ``check_pos_inf`` is ``True``.", "x": 920.0, "y": -1050.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::activation_checkpoint_function", "label": "activation_checkpoint_function()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::activation_checkpoint_function\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -937.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::BufferCache", "label": "BufferCache()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::BufferCache\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Cache for attention biases and other things that would normally be stored as buffers.\nWe avoid using buffers because we\u0027ve run into various issues doing so with FSDP.\nIn general it appears the way FSDP handles buffers is not well-defined.\nIt doesn\u0027t shard them but apparently it does synchronize them\u2026", "x": 460.0, "y": -1237.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::_non_meta_init_device", "label": "_non_meta_init_device()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::_non_meta_init_device\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1012.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::Dropout", "label": "Dropout()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::Dropout\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -3487.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LayerNormBase", "label": "LayerNormBase()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::LayerNormBase\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -9037.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LayerNorm", "label": "LayerNorm()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LayerNorm\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: The default :class:`LayerNorm` implementation which can optionally run in low precision.", "x": 230.0, "y": -3037.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::RMSLayerNorm", "label": "RMSLayerNorm()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::RMSLayerNorm\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: RMS layer norm, a simplified :class:`LayerNorm` implementation", "x": 230.0, "y": -2962.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::GemmaRMSLayerNorm", "label": "GemmaRMSLayerNorm()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::GemmaRMSLayerNorm\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Gemma RMS layer norm, a simplified :class:`LayerNorm` implementation", "x": 230.0, "y": -3337.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::RotaryEmbedding", "label": "RotaryEmbedding()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::RotaryEmbedding\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: [Rotary positional embeddings (RoPE)](https://arxiv.org/abs/2104.09864).", "x": 230.0, "y": -2812.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::Activation", "label": "Activation()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::Activation\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -9487.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::GELU", "label": "GELU()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::GELU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -3412.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::ReLU", "label": "ReLU()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::ReLU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -2887.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::SiLU", "label": "SiLU()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::SiLU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -2737.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::SwiGLU", "label": "SwiGLU()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::SwiGLU\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -2662.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::causal_attention_bias", "label": "causal_attention_bias()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::causal_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -900.0}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::get_causal_attention_bias", "label": "get_causal_attention_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_causal_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -562.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::alibi_attention_bias", "label": "alibi_attention_bias()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::alibi_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -975.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDABlock", "label": "LLaDABlock()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDABlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: A base class for transformer block implementations.", "x": 0.0, "y": -9412.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDASequentialBlock", "label": "LLaDASequentialBlock()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDASequentialBlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is a typical transformer block where the output is computed as ``MLP(LN(x + Attention(LN(x))))``\n(plus another skip connection).", "x": 230.0, "y": -3112.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDALlamaBlock", "label": "LLaDALlamaBlock()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDALlamaBlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is a transformer block where the output is computed as ``MLP(LN(x + Attention(LN(x))))``\n(plus another skip connection). This block is similar to `LLaDASequentialBlock`\nbut some operations have slightly different implementations to imitate the\nbehavior of Llama.", "x": 230.0, "y": -3262.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDABlockDiffBlock", "label": "LLaDABlockDiffBlock()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDABlockDiffBlock\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is a transformer block where the output is computed as ``MLP(LN(x + Attention(LN(x))))``\n(plus another skip connection). This block is similar to `LLaDASequentialBlock`\nbut some operations have slightly different implementations to imitate the\nbehavior of Llama.", "x": 0.0, "y": -9337.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDAOutput", "label": "LLaDAOutput()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAOutput\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -1162.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDAGenerateOutput", "label": "LLaDAGenerateOutput()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAGenerateOutput\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -9187.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDABlockGroup", "label": "LLaDABlockGroup()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDABlockGroup\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -9262.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDAModel", "label": "LLaDAModel()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAModel\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -3187.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::create_model_config_from_pretrained_config", "label": "create_model_config_from_pretrained_config()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::create_model_config_from_pretrained_config\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Utility function", "x": 230.0, "y": -2587.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::LLaDAModelLM", "label": "LLaDAModelLM()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::LLaDAModelLM\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Extremely barebones HF model wrapper.", "x": 0.0, "y": -9112.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::forward", "label": "forward()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::forward\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8587.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::__init__\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8887.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::build", "label": "build()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::build\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8812.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::_cast_if_autocast_enabled", "label": "_cast_if_autocast_enabled()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::_cast_if_autocast_enabled\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1087.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::reset_parameters", "label": "reset_parameters()", "shape": "box", "title": "\u003cb\u003ellada.model.modeling_llada::reset_parameters\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8212.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::get_rotary_embedding", "label": "get_rotary_embedding()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::get_rotary_embedding\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -487.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::rotate_half", "label": "rotate_half()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::rotate_half\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -825.0}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::apply_rotary_pos_emb", "label": "apply_rotary_pos_emb()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::apply_rotary_pos_emb\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -862.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::output_multiplier", "label": "output_multiplier()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::output_multiplier\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8362.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::set_activation_checkpointing", "label": "set_activation_checkpointing()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::set_activation_checkpointing\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8137.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::_cast_attn_bias", "label": "_cast_attn_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::_cast_attn_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -1125.0}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::_scaled_dot_product_attention", "label": "_scaled_dot_product_attention()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::_scaled_dot_product_attention\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Computes scaled dot product attention on query, key and value tensors, using an optional\nattention mask if passed, and applying dropout if a probability greater than 0.0 is specified.", "x": 690.0, "y": -1050.0}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::attention", "label": "attention()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::attention\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -787.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::cross_attn_flex", "label": "cross_attn_flex()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::cross_attn_flex\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8662.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::device", "label": "device()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::device\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -712.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::get_alibi_attention_bias", "label": "get_alibi_attention_bias()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_alibi_attention_bias\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -637.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::can_generate", "label": "can_generate()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::can_generate\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8737.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::prepare_inputs_for_generation", "label": "prepare_inputs_for_generation()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::prepare_inputs_for_generation\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8287.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::get_input_embeddings", "label": "get_input_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8512.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::set_input_embeddings", "label": "set_input_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::set_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8062.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::get_output_embeddings", "label": "get_output_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::get_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -8437.5}, {"color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::set_output_embeddings", "label": "set_output_embeddings()", "shape": "dot", "title": "\u003cb\u003ellada.model.modeling_llada::set_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -7987.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "llada.model.modeling_llada::tie_weights", "label": "tie_weights()", "shape": "triangle", "title": "\u003cb\u003ellada.model.modeling_llada::tie_weights\u003c/b\u003e\u003cbr\u003eModule: llada.model.modeling_llada\u003cbr\u003eFile: llada/model/modeling_llada.py\u003cbr\u003eKind: Function", "x": 1380.0, "y": -600.0}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::StrEnum", "label": "StrEnum()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::StrEnum\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: This is equivalent to Python\u0027s :class:`enum.StrEnum` since version 3.11.\nWe include this here for compatibility with older version of Python.", "x": 0.0, "y": -10012.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::LayerNormType", "label": "LayerNormType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::LayerNormType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -10087.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::ActivationType", "label": "ActivationType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::ActivationType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -10387.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::BlockType", "label": "BlockType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::BlockType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -10312.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::InitFnType", "label": "InitFnType()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::InitFnType\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -10237.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::ModelConfig", "label": "ModelConfig()", "shape": "triangle", "title": "\u003cb\u003ellada.model.configuration_llada::ModelConfig\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: LLaDA (model) configuration.", "x": 460.0, "y": -1312.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::ActivationCheckpointingStrategy", "label": "ActivationCheckpointingStrategy()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::ActivationCheckpointingStrategy\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -10462.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::LLaDAConfig", "label": "LLaDAConfig()", "shape": "box", "title": "\u003cb\u003ellada.model.configuration_llada::LLaDAConfig\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -10162.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::__str__", "label": "__str__()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::__str__\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -9862.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::__repr__", "label": "__repr__()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::__repr__\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -9937.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::effective_n_kv_heads", "label": "effective_n_kv_heads()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::effective_n_kv_heads\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -9787.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::__init__\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -3562.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::num_attention_heads", "label": "num_attention_heads()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::num_attention_heads\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -9637.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::num_hidden_layers", "label": "num_hidden_layers()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::num_hidden_layers\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -9562.5}, {"color": "#6DC8EC", "fixed": true, "id": "llada.model.configuration_llada::hidden_size", "label": "hidden_size()", "shape": "dot", "title": "\u003cb\u003ellada.model.configuration_llada::hidden_size\u003c/b\u003e\u003cbr\u003eModule: llada.model.configuration_llada\u003cbr\u003eFile: llada/model/configuration_llada.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -9712.5}, {"color": "#E8684A", "fixed": true, "id": "dream.postprocess_code::pass_at_1", "label": "pass_at_1()", "shape": "dot", "title": "\u003cb\u003edream.postprocess_code::pass_at_1\u003c/b\u003e\u003cbr\u003eModule: dream.postprocess_code\u003cbr\u003eFile: dream/postprocess_code.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11812.5}, {"color": "#E8684A", "fixed": true, "id": "dream.postprocess_code::read_jsonl", "label": "read_jsonl()", "shape": "dot", "title": "\u003cb\u003edream.postprocess_code::read_jsonl\u003c/b\u003e\u003cbr\u003eModule: dream.postprocess_code\u003cbr\u003eFile: dream/postprocess_code.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11737.5}, {"color": "#E8684A", "fixed": true, "id": "dream.postprocess_code::write_jsonl", "label": "write_jsonl()", "shape": "dot", "title": "\u003cb\u003edream.postprocess_code::write_jsonl\u003c/b\u003e\u003cbr\u003eModule: dream.postprocess_code\u003cbr\u003eFile: dream/postprocess_code.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11662.5}, {"color": "#5D7092", "fixed": true, "id": "dream.demo_multiturn_chat::generation_tokens_hook_func", "label": "generation_tokens_hook_func()", "shape": "dot", "title": "\u003cb\u003edream.demo_multiturn_chat::generation_tokens_hook_func\u003c/b\u003e\u003cbr\u003eModule: dream.demo_multiturn_chat\u003cbr\u003eFile: dream/demo_multiturn_chat.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -3412.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::Dream", "label": "Dream()", "shape": "box", "title": "\u003cb\u003edream.eval::Dream\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -14962.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.eval::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -6637.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::batch_size", "label": "batch_size()", "shape": "dot", "title": "\u003cb\u003edream.eval::batch_size\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14812.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::device", "label": "device()", "shape": "triangle", "title": "\u003cb\u003edream.eval::device\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -3112.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::rank", "label": "rank()", "shape": "dot", "title": "\u003cb\u003edream.eval::rank\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14437.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::world_size", "label": "world_size()", "shape": "dot", "title": "\u003cb\u003edream.eval::world_size\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14137.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::_create_model_and_tokenizer", "label": "_create_model_and_tokenizer()", "shape": "dot", "title": "\u003cb\u003edream.eval::_create_model_and_tokenizer\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -3337.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::tok_decode", "label": "tok_decode()", "shape": "box", "title": "\u003cb\u003edream.eval::tok_decode\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14362.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::tok_encode", "label": "tok_encode()", "shape": "dot", "title": "\u003cb\u003edream.eval::tok_encode\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14287.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::create_from_arg_string", "label": "create_from_arg_string()", "shape": "dot", "title": "\u003cb\u003edream.eval::create_from_arg_string\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Creates an instance of the LM class using the given argument string and additional config.\n\nParameters:\n- arg_string: A string containing arguments in the format key1=value1,key2=value2.\n- additional_config: Optional dictionary containing additional configuration parameters.\n\nReturns:\n- Instance of \u2026", "x": 0.0, "y": -14737.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::apply_chat_template", "label": "apply_chat_template()", "shape": "triangle", "title": "\u003cb\u003edream.eval::apply_chat_template\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Method to apply a chat template to a list of chat history between user and model.", "x": 460.0, "y": -3187.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::tokenizer_name", "label": "tokenizer_name()", "shape": "dot", "title": "\u003cb\u003edream.eval::tokenizer_name\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14212.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::_generate_batch", "label": "_generate_batch()", "shape": "dot", "title": "\u003cb\u003edream.eval::_generate_batch\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -6337.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::generate_until", "label": "generate_until()", "shape": "box", "title": "\u003cb\u003edream.eval::generate_until\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14662.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::_forward_process", "label": "_forward_process()", "shape": "triangle", "title": "\u003cb\u003edream.eval::_forward_process\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -3262.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::get_logits", "label": "get_logits()", "shape": "triangle", "title": "\u003cb\u003edream.eval::get_logits\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: prompt_index : 1D bool tensor, length=batch.shape[1]", "x": 460.0, "y": -3037.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::_eval_target_nll_mc", "label": "_eval_target_nll_mc()", "shape": "dot", "title": "\u003cb\u003edream.eval::_eval_target_nll_mc\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -6412.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::_eval_target_nll_ar", "label": "_eval_target_nll_ar()", "shape": "dot", "title": "\u003cb\u003edream.eval::_eval_target_nll_ar\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -6487.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::_encode_pair", "label": "_encode_pair()", "shape": "triangle", "title": "\u003cb\u003edream.eval::_encode_pair\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -6562.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::loglikelihood", "label": "loglikelihood()", "shape": "box", "title": "\u003cb\u003edream.eval::loglikelihood\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14587.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.eval::loglikelihood_rolling", "label": "loglikelihood_rolling()", "shape": "dot", "title": "\u003cb\u003edream.eval::loglikelihood_rolling\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14512.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.eval::_tokenize", "label": "_tokenize()", "shape": "box", "title": "\u003cb\u003edream.eval::_tokenize\u003c/b\u003e\u003cbr\u003eModule: dream.eval\u003cbr\u003eFile: dream/eval.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -14887.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "dream.sanitize::refine_text", "label": "refine_text()", "shape": "triangle", "title": "\u003cb\u003edream.sanitize::refine_text\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4537.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "dream.sanitize::syntax_check", "label": "syntax_check()", "shape": "triangle", "title": "\u003cb\u003edream.sanitize::syntax_check\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1912.5}, {"color": "#269A99", "fixed": true, "id": "dream.sanitize::extract_longest_valid_code", "label": "extract_longest_valid_code()", "shape": "dot", "title": "\u003cb\u003edream.sanitize::extract_longest_valid_code\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4912.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "dream.sanitize::get_deps", "label": "get_deps()", "shape": "triangle", "title": "\u003cb\u003edream.sanitize::get_deps\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4762.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "dream.sanitize::get_function_dependency", "label": "get_function_dependency()", "shape": "triangle", "title": "\u003cb\u003edream.sanitize::get_function_dependency\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4687.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "dream.sanitize::get_definition_name", "label": "get_definition_name()", "shape": "triangle", "title": "\u003cb\u003edream.sanitize::get_definition_name\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4837.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "dream.sanitize::has_return_statement", "label": "has_return_statement()", "shape": "triangle", "title": "\u003cb\u003edream.sanitize::has_return_statement\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4612.5}, {"borderWidth": 2, "color": "#269A99", "fixed": true, "id": "dream.sanitize::sanitize", "label": "sanitize()", "shape": "box", "title": "\u003cb\u003edream.sanitize::sanitize\u003c/b\u003e\u003cbr\u003eModule: dream.sanitize\u003cbr\u003eFile: dream/sanitize.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11587.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::BaseModelOutputWithPast", "label": "BaseModelOutputWithPast()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::BaseModelOutputWithPast\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -2362.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::MaskedLMOutputWithPastKeyValues", "label": "MaskedLMOutputWithPastKeyValues()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::MaskedLMOutputWithPastKeyValues\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 230.0, "y": -5212.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamRMSNorm", "label": "DreamRMSNorm()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::DreamRMSNorm\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 690.0, "y": -1575.0}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamRotaryEmbedding", "label": "DreamRotaryEmbedding()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamRotaryEmbedding\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -2212.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::rotate_half", "label": "rotate_half()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::rotate_half\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Rotates half the hidden dims of the input.", "x": 1150.0, "y": -825.0}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::apply_rotary_pos_emb", "label": "apply_rotary_pos_emb()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::apply_rotary_pos_emb\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Applies Rotary Position Embedding to the query and key tensors.\n\nArgs:\n    q (`torch.Tensor`): The query tensor.\n    k (`torch.Tensor`): The key tensor.\n    cos (`torch.Tensor`): The cosine part of the rotary embedding.\n    sin (`torch.Tensor`): The sine part of the rotary embedding.\n    position_id\u2026", "x": 920.0, "y": -1200.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamMLP", "label": "DreamMLP()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::DreamMLP\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 690.0, "y": -1650.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::repeat_kv", "label": "repeat_kv()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::repeat_kv\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: This is the equivalent of torch.repeat_interleave(x, dim=1, repeats=n_rep). The hidden states go from (batch,\nnum_key_value_heads, seqlen, head_dim) to (batch, num_attention_heads, seqlen, head_dim)", "x": 920.0, "y": -1125.0}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamAttention", "label": "DreamAttention()", "shape": "box", "title": "\u003cb\u003edream.model.modeling_dream::DreamAttention\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Multi-headed attention from \u0027Attention Is All You Need\u0027 paper. Modified to use sliding window attention: Longformer\nand \"Generating Long Sequences with Sparse Transformers\".", "x": 0.0, "y": -13462.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamSdpaAttention", "label": "DreamSdpaAttention()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamSdpaAttention\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Dream attention module using torch.nn.functional.scaled_dot_product_attention. This module inherits from\n`DreamAttention` as the weights of the module stays untouched. The only changes are on the forward pass to adapt to\nSDPA API.", "x": 690.0, "y": -1500.0}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamDecoderLayer", "label": "DreamDecoderLayer()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamDecoderLayer\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -2287.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamPreTrainedModel", "label": "DreamPreTrainedModel()", "shape": "box", "title": "\u003cb\u003edream.model.modeling_dream::DreamPreTrainedModel\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -13312.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamBaseModel", "label": "DreamBaseModel()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::DreamBaseModel\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Transformer decoder consisting of *config.num_hidden_layers* layers. Each layer is a [`DreamDecoderLayer`]\n\nArgs:\n    config: DreamConfig", "x": 230.0, "y": -5287.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::DreamModel", "label": "DreamModel()", "shape": "box", "title": "\u003cb\u003edream.model.modeling_dream::DreamModel\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -13387.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003edream.model.modeling_dream::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13237.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::forward", "label": "forward()", "shape": "box", "title": "\u003cb\u003edream.model.modeling_dream::forward\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13012.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::extra_repr", "label": "extra_repr()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::extra_repr\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13087.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::reset_parameters", "label": "reset_parameters()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::reset_parameters\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -5137.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::_dynamic_frequency_update", "label": "_dynamic_frequency_update()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::_dynamic_frequency_update\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: dynamic RoPE layers should recompute `inv_freq` in the following situations:\n1 - growing beyond the cached sequence length (allow scaling)\n2 - the current sequence length is in the original scale (avoid losing precision with small sequences)", "x": 690.0, "y": -1425.0}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::_init_weights", "label": "_init_weights()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::_init_weights\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13162.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::from_pretrained", "label": "from_pretrained()", "shape": "triangle", "title": "\u003cb\u003edream.model.modeling_dream::from_pretrained\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 1840.0, "y": -300.0}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::get_input_embeddings", "label": "get_input_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::get_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12862.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::set_input_embeddings", "label": "set_input_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::set_input_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12562.5}, {"borderWidth": 2, "color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::reset_rope_parameters", "label": "reset_rope_parameters()", "shape": "box", "title": "\u003cb\u003edream.model.modeling_dream::reset_rope_parameters\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12712.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::get_output_embeddings", "label": "get_output_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::get_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12787.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::set_output_embeddings", "label": "set_output_embeddings()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::set_output_embeddings\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12487.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::set_decoder", "label": "set_decoder()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::set_decoder\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12637.5}, {"color": "#5D7092", "fixed": true, "id": "dream.model.modeling_dream::get_decoder", "label": "get_decoder()", "shape": "dot", "title": "\u003cb\u003edream.model.modeling_dream::get_decoder\u003c/b\u003e\u003cbr\u003eModule: dream.model.modeling_dream\u003cbr\u003eFile: dream/model/modeling_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12937.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::top_p_logits", "label": "top_p_logits()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::top_p_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -2025.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::top_k_logits", "label": "top_k_logits()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::top_k_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -2100.0}, {"color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::sample_tokens", "label": "sample_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::sample_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -2737.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::DreamModelOutput", "label": "DreamModelOutput()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::DreamModelOutput\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -2887.5}, {"color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::DreamGenerationConfig", "label": "DreamGenerationConfig()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::DreamGenerationConfig\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -2962.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::DreamGenerationMixin", "label": "DreamGenerationMixin()", "shape": "box", "title": "\u003cb\u003edream.model.generation_utils::DreamGenerationMixin\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -13987.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003edream.model.generation_utils::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13912.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::validate", "label": "validate()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::validate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -1950.0}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::_expand_inputs_for_generation", "label": "_expand_inputs_for_generation()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::_expand_inputs_for_generation\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Expands tensors from [batch_size, ...] to [batch_size * expand_size, ...]", "x": 230.0, "y": -6187.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::_validate_generated_length", "label": "_validate_generated_length()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::_validate_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs validation related to the resulting generated length", "x": 230.0, "y": -5812.5}, {"color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::_prepare_generated_length", "label": "_prepare_generated_length()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_prepare_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepared max and min length in generation configs to avoid clashes between similar attributes", "x": 230.0, "y": -6112.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::_prepare_generation_config", "label": "_prepare_generation_config()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::_prepare_generation_config\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the base generation config, then applies any generation configuration options from kwargs. This\nfunction handles retrocompatibility with respect to configuration files.", "x": 230.0, "y": -6037.5}, {"color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::_prepare_special_tokens", "label": "_prepare_special_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_prepare_special_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the special tokens for generation, overwriting the generation config with their processed versions\nconverted to tensor.\nNote that `generation_config` is changed in place and stops being serializable after this method is called.\nThat is no problem if called within `generate` (`generation_con\u2026", "x": 230.0, "y": -5962.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::diffusion_generate", "label": "diffusion_generate()", "shape": "box", "title": "\u003cb\u003edream.model.generation_utils::diffusion_generate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13837.5}, {"color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::_sample", "label": "_sample()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils::_sample\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -5887.5}, {"borderWidth": 2, "color": "#E8684A", "fixed": true, "id": "dream.model.generation_utils::_tensor_or_none", "label": "_tensor_or_none()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils::_tensor_or_none\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils\u003cbr\u003eFile: dream/model/generation_utils.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -2812.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::bytes_to_unicode", "label": "bytes_to_unicode()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::bytes_to_unicode\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Returns list of utf-8 byte and a mapping to unicode strings. We specifically avoids mapping to whitespace/control\ncharacters the bpe code barfs on.\n\nThe reversible bpe codes work on unicode strings. This means you need a large # of unicode characters in your vocab\nif you want to avoid UNKs. When you\u2026", "x": 460.0, "y": -2137.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::get_pairs", "label": "get_pairs()", "shape": "triangle", "title": "\u003cb\u003edream.model.tokenization_dream::get_pairs\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Return set of symbol pairs in a word.\n\nWord is represented as tuple of symbols (symbols being variable-length strings).", "x": 460.0, "y": -2062.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::DreamTokenizer", "label": "DreamTokenizer()", "shape": "box", "title": "\u003cb\u003edream.model.tokenization_dream::DreamTokenizer\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Class\u003cbr\u003eDocstring: Construct a Dream tokenizer. Based on byte-level Byte-Pair-Encoding.\n\nSame with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will\nbe encoded differently whether it is at the beginning of the sentence (without space) or not:\n\n```python\n\u003e\u003e\u003e from tra\u2026", "x": 0.0, "y": -12412.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::__init__", "label": "__init__()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -5062.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::vocab_size", "label": "vocab_size()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::vocab_size\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11887.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::get_vocab", "label": "get_vocab()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::get_vocab\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -1987.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::bpe", "label": "bpe()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::bpe\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -4987.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::_tokenize", "label": "_tokenize()", "shape": "box", "title": "\u003cb\u003edream.model.tokenization_dream::_tokenize\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Tokenize a string.", "x": 0.0, "y": -12187.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::_convert_token_to_id", "label": "_convert_token_to_id()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::_convert_token_to_id\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Converts a token (str) in an id using the vocab.", "x": 0.0, "y": -12262.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::_convert_id_to_token", "label": "_convert_id_to_token()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::_convert_id_to_token\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Converts an index (integer) in a token (str) using the vocab.", "x": 0.0, "y": -12337.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::convert_tokens_to_string", "label": "convert_tokens_to_string()", "shape": "box", "title": "\u003cb\u003edream.model.tokenization_dream::convert_tokens_to_string\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Converts a sequence of tokens (string) in a single string.", "x": 0.0, "y": -12112.5}, {"borderWidth": 2, "color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::decode", "label": "decode()", "shape": "triangle", "title": "\u003cb\u003edream.model.tokenization_dream::decode\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -1350.0}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::save_vocabulary", "label": "save_vocabulary()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::save_vocabulary\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -11962.5}, {"color": "#FF9D4D", "fixed": true, "id": "dream.model.tokenization_dream::prepare_for_tokenization", "label": "prepare_for_tokenization()", "shape": "dot", "title": "\u003cb\u003edream.model.tokenization_dream::prepare_for_tokenization\u003c/b\u003e\u003cbr\u003eModule: dream.model.tokenization_dream\u003cbr\u003eFile: dream/model/tokenization_dream.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -12037.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::get_num_transfer_tokens", "label": "get_num_transfer_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::get_num_transfer_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: In the reverse process, the interval [0, 1] is uniformly discretized into steps intervals.\nFurthermore, because LLaDA employs a linear noise schedule (as defined in Eq. (8)),\nthe expected number of tokens transitioned at each step should be consistent.\n\nThis function is designed to precompute the nu\u2026", "x": 0.0, "y": -13537.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::top_p_logits", "label": "top_p_logits()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::top_p_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -1800.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::top_k_logits", "label": "top_k_logits()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::top_k_logits\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -1875.0}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::sample_tokens", "label": "sample_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::sample_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -2437.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::DreamModelOutput", "label": "DreamModelOutput()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::DreamModelOutput\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -2587.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::DreamGenerationConfig", "label": "DreamGenerationConfig()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::DreamGenerationConfig\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Class", "x": 460.0, "y": -2662.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::DreamGenerationMixin", "label": "DreamGenerationMixin()", "shape": "box", "title": "\u003cb\u003edream.model.generation_utils_block::DreamGenerationMixin\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -13762.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::__init__", "label": "__init__()", "shape": "box", "title": "\u003cb\u003edream.model.generation_utils_block::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13687.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::validate", "label": "validate()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::validate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 690.0, "y": -1725.0}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::_expand_inputs_for_generation", "label": "_expand_inputs_for_generation()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::_expand_inputs_for_generation\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Expands tensors from [batch_size, ...] to [batch_size * expand_size, ...]", "x": 230.0, "y": -5737.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::_validate_generated_length", "label": "_validate_generated_length()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::_validate_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Performs validation related to the resulting generated length", "x": 230.0, "y": -5362.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::_prepare_generated_length", "label": "_prepare_generated_length()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_prepare_generated_length\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepared max and min length in generation configs to avoid clashes between similar attributes", "x": 230.0, "y": -5662.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::_prepare_generation_config", "label": "_prepare_generation_config()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::_prepare_generation_config\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the base generation config, then applies any generation configuration options from kwargs. This\nfunction handles retrocompatibility with respect to configuration files.", "x": 230.0, "y": -5587.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::_prepare_special_tokens", "label": "_prepare_special_tokens()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_prepare_special_tokens\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function\u003cbr\u003eDocstring: Prepares the special tokens for generation, overwriting the generation config with their processed versions\nconverted to tensor.\nNote that `generation_config` is changed in place and stops being serializable after this method is called.\nThat is no problem if called within `generate` (`generation_con\u2026", "x": 230.0, "y": -5512.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::diffusion_generate", "label": "diffusion_generate()", "shape": "box", "title": "\u003cb\u003edream.model.generation_utils_block::diffusion_generate\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 0.0, "y": -13612.5}, {"color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::_sample", "label": "_sample()", "shape": "dot", "title": "\u003cb\u003edream.model.generation_utils_block::_sample\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -5437.5}, {"borderWidth": 2, "color": "#F6BD16", "fixed": true, "id": "dream.model.generation_utils_block::_tensor_or_none", "label": "_tensor_or_none()", "shape": "triangle", "title": "\u003cb\u003edream.model.generation_utils_block::_tensor_or_none\u003c/b\u003e\u003cbr\u003eModule: dream.model.generation_utils_block\u003cbr\u003eFile: dream/model/generation_utils_block.py\u003cbr\u003eKind: Function", "x": 460.0, "y": -2512.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "dream.model.configuration_dream::DreamConfig", "label": "DreamConfig()", "shape": "box", "title": "\u003cb\u003edream.model.configuration_dream::DreamConfig\u003c/b\u003e\u003cbr\u003eModule: dream.model.configuration_dream\u003cbr\u003eFile: dream/model/configuration_dream.py\u003cbr\u003eKind: Class", "x": 0.0, "y": -14062.5}, {"borderWidth": 2, "color": "#6DC8EC", "fixed": true, "id": "dream.model.configuration_dream::__init__", "label": "__init__()", "shape": "triangle", "title": "\u003cb\u003edream.model.configuration_dream::__init__\u003c/b\u003e\u003cbr\u003eModule: dream.model.configuration_dream\u003cbr\u003eFile: dream/model/configuration_dream.py\u003cbr\u003eKind: Function", "x": 230.0, "y": -6262.5}]);
                  edges = new vis.DataSet([{"arrows": "to", "from": "v2.app::generate_response_with_visualization_fast_dllm", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.app::generate_response_with_visualization_fast_dllm", "to": "v2.generation_functions::mdm_sample_with_visualization"}, {"arrows": "to", "from": "v2.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::create_chatbot_demo", "to": "v2.app::add_message"}, {"arrows": "to", "from": "v2.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::add_message", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::user_message_submitted", "to": "v2.app::add_message"}, {"arrows": "to", "from": "v2.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.app::accelerated_response", "to": "v2.app::format_chat_history"}, {"arrows": "to", "from": "v2.app::accelerated_response", "to": "v2.app::generate_response_with_visualization_fast_dllm"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::__init__"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::_forward_process"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.eval::get_logits"}, {"arrows": "to", "from": "v2.eval::Fast_dLLM_v2EvalHarness", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.eval::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.eval::get_loglikelihood", "to": "v2.eval::_forward_process"}, {"arrows": "to", "from": "v2.eval::get_loglikelihood", "to": "v2.eval::get_logits"}, {"arrows": "to", "from": "v2.eval::loglikelihood", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.eval::loglikelihood", "to": "v2.eval::_encode_pair"}, {"arrows": "to", "from": "v2.eval::loglikelihood", "to": "v2.eval::get_loglikelihood"}, {"arrows": "to", "from": "v2.eval::_tokenize", "to": "v2.eval::_encode_pair"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.args::get_pipeline_args_class"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.pipeline.auto_pipeline::get_pipeline"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.train_scripts.finetune::main", "to": "v2.src.lmflow.models.auto_model::get_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::DPOAligner", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset", "to": "v2.src.lmflow.pipeline.dpo_aligner::get_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::align", "to": "v2.src.lmflow.pipeline.dpo_aligner::_load_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::align", "to": "v2.src.lmflow.pipeline.dpo_aligner::_initialize_trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpo_aligner::align", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::IterativeDPOAligner", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.utils.common::print_banner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_align_single_iteration", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference", "to": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_target_model_inference", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_reward_model_inference", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "to": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::align"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_do_single_dpo_align", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_target_model_inference_args", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_reward_model_inference_args", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.iterative_dpo_aligner::_parse_dpo_aligner_args", "to": "v2.src.lmflow.pipeline.iterative_dpo_aligner::__filter_args"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::InferencerWithOffloading", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::parse_to_sampling_params"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.pipeline.vllm_inferencer::_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::MemorySafeVLLMInferencer", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::inference", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::inference", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::_distributed_inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::scheduling_strategy_fn", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.vllm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.pipeline.inferencer::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.args::DatasetArguments"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::Inferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::predict_next_token"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::sample"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::SpeculativeInferencer", "to": "v2.src.lmflow.pipeline.inferencer::speculative_sampling"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::ToolInferencer", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::__init__", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::to_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "to": "v2.src.lmflow.pipeline.inferencer::predict_next_token"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling", "to": "v2.src.lmflow.pipeline.inferencer::sample"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::autoregressive_sampling"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::sample"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.inferencer::speculative_sampling", "to": "v2.src.lmflow.pipeline.inferencer::score_to_prob"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::RaftAligner", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_top", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::_get_batch_dataset_local", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.src.lmflow.pipeline.raft_aligner::_load_input_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.src.lmflow.pipeline.raft_aligner::_initialize_trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::align", "to": "v2.src.lmflow.pipeline.raft_aligner::_load_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.raft_aligner::group_texts", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::RewardModelInferencer", "to": "v2.src.lmflow.pipeline.rm_inferencer::flatten_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__init__", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::_inference", "to": "v2.src.lmflow.utils.versioning::is_ray_available"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::flatten_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::__post_process_model_output"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::compress_list"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__distributed_inference", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::scheduling_strategy_fn", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::DistributedPredictor", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_inferencer::__call__", "to": "v2.src.lmflow.pipeline.rm_inferencer::inference"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::RewardModelTuner", "to": "v2.src.lmflow.pipeline.finetuner::group_text"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.rm_dataprocessor::RewardDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::tune", "to": "v2.src.lmflow.pipeline.finetuner::group_text"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.rm_tuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::on_step_begin", "to": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.rm_tuner::switch_active_layers", "to": "v2.src.lmflow.pipeline.rm_tuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner", "to": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::MemorySafeDPOv2Aligner", "to": "v2.src.lmflow.utils.common::add_dataclass_attr_prefix"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::__init__", "to": "v2.src.lmflow.utils.common::add_dataclass_attr_prefix"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::align", "to": "v2.src.lmflow.utils.common::make_shell_args_from_dataclass"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::align", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_response_lengths"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_calc_reward_with_length_penalty"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::convert_to_paired_dataset", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards_fast"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.dpov2_aligner::sampling_paired_idx_from_rewards", "to": "v2.src.lmflow.pipeline.dpov2_aligner::_sampling_paired_idx_from_rewards"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::Finetuner", "to": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::group_text", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::group_text", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer", "to": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.multi_modal_dataset::register_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.finetuner::create_customized_optimizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::tune", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::CustomizedOptimTrainer", "to": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::create_optimizer", "to": "v2.src.lmflow.pipeline.finetuner::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.finetuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::DynamicLayerActivationCallback", "to": "v2.src.lmflow.pipeline.finetuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::on_step_begin", "to": "v2.src.lmflow.pipeline.finetuner::switch_active_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.finetuner::switch_active_layers", "to": "v2.src.lmflow.pipeline.finetuner::freeze_all_layers"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::Evaluator", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::__init__", "to": "v2.src.lmflow.utils.data_utils::set_random_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::create_dataloader", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::create_dataloader", "to": "v2.src.lmflow.utils.data_utils::batchlize"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_ppl"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::evaluate", "to": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_accelerator", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_acc_with_deepspeed", "to": "v2.src.lmflow.pipeline.evaluator::create_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_ppl", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.pipeline.evaluator::get_nll"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.evaluator::_evaluate_nll", "to": "v2.src.lmflow.pipeline.evaluator::get_nll"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::collate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::__call__", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::tokenize_batch_element"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.rm_trainer::RewardTrainer", "to": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.rm_trainer::PeftRewardTrainer", "to": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.rm_trainer::compute_loss", "to": "v2.src.lmflow.pipeline.utils.rm_trainer::rm_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::DPOv2Trainer", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::__init__", "to": "v2.src.lmflow.pipeline.utils.dpov2_dataprocessor::PreferenceDataCollatorWithPadding"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_loss_metrics", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.dpov2_trainer::get_batch_metrics", "to": "v2.src.lmflow.pipeline.utils.dpov2_trainer::dpo_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::PeftSavingCallback", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::on_epoch_end", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.peft_trainer::on_save", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::pop_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::remove_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::RaftTrainer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::add_callback"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::__init__", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device", "to": "llada.model.modeling_llada::tie_weights"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_set_signature_columns_if_needed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_train_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_eval_sampler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_remove_unused_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_collator_with_removed_columns"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_scheduler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_optimizer_cls_and_kwargs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_tune_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::train"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::ipex_optimize_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::torch_jit_model_eval"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_hp_search_setup"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::call_model_init"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.eval::set_seed"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_move_model_to_device"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_local_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_one_train", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::on_train_end"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_train_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_optimizer_and_scheduler"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_inner_training_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_load_best_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_issue_warnings_after_load", "to": "llada.model.modeling_llada::tie_weights"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_report_to_hp_search"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.peft_trainer::on_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_maybe_log_save_evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_get_output_dir"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::store_flos"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::dtype"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_input"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::autocast_smart_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::train"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::training_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero", "to": "v2.eval::rank"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save_tpu"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_save"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_rotate_checkpoints", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_sorted_checkpoints"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_eval_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluate", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::predict", "to": "v2.src.lmflow.utils.debug.profiler::start"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::predict", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::get_test_dataloader"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::evaluation_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_pad_across_processes", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_nested_gather"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_prepare_inputs"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss_context_manager"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::compute_loss"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_push_from_checkpoint", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::save_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::init_git_repo"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::push_to_hub", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::create_model_card"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_wrap_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::num_examples"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_step"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::prediction_loop", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::_gather_and_numpify"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.raft_trainer::_add_sm_patterns_to_gitignore", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::is_world_process_zero"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.utils.common::remove_dataclass_attr_prefix"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.args::ModelArguments"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_dpov2_align::main", "to": "v2.src.lmflow.pipeline.dpov2_aligner::DPOv2Aligner"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.args::get_pipeline_args_class"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.models.auto_model::get_model"}, {"arrows": "to", "from": "v2.src.lmflow.pipeline.utils.memory_safe_vllm_inference::main", "to": "v2.src.lmflow.pipeline.vllm_inferencer::VLLMInferencer"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset", "to": "v2.src.lmflow.datasets.multi_modal_dataset::expand2square"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token", "to": "v2.src.lmflow.datasets.multi_modal_dataset::insert_separator"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::append_message"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1", "to": "v2.src.lmflow.datasets.multi_modal_dataset::tokenizer_image_token"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::DataCollatorForSupervisedDataset", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_multimodal_llava"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_plain"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::preprocess_llama_from_llava_v1"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::expand2square"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.multi_modal_dataset::__call__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.args::DatasetArguments"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::_check_hf_json_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::train_test_split"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::Dataset", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.datasets.dataset::_check_hf_json_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.datasets.multi_modal_dataset::CustomMultiModalDataset"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::__init__", "to": "v2.src.lmflow.utils.versioning::is_multimodal_available"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::_check_hf_json_format", "to": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::_check_hf_json_format", "to": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::from_dict", "to": "v2.src.lmflow.datasets.dataset::_check_instance_format"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::create_from_dict", "to": "v2.src.lmflow.args::DatasetArguments"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::create_from_dict", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::create_from_dict", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::to_dict", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::to_list", "to": "v2.src.lmflow.datasets.multi_modal_dataset::__getitem__"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::save", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::sample", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::sample", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::create_from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::train_test_split", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.datasets.dataset::sanity_check", "to": "v2.src.lmflow.datasets.dataset::hf_dataset_sanity_check"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lamb::Lamb", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lamb::Lamb", "to": "v2.src.lmflow.optim.lamb::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lamb::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.optim.adan::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.optim.adan::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::Adan", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::step", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::step", "to": "v2.src.lmflow.optim.adan::_multi_tensor_adan"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adan::step", "to": "v2.src.lmflow.optim.adan::_single_tensor_adan"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::LARS", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::LARS", "to": "v2.src.lmflow.optim.lars::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::LARS", "to": "v2.src.lmflow.optim.lars::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.lars::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::Adamax", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::Adamax", "to": "v2.src.lmflow.optim.adamax::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::Adamax", "to": "v2.src.lmflow.optim.adamax::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamax::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgd_schedule_free::SGDScheduleFree", "to": "v2.src.lmflow.optim.sgd_schedule_free::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgd_schedule_free::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::AdamP", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::AdamP", "to": "v2.src.lmflow.optim.adamp::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::AdamP", "to": "v2.src.lmflow.optim.adamp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::_projection", "to": "v2.src.lmflow.optim.adamp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamp::step", "to": "v2.src.lmflow.optim.adamp::_projection"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::AdaBelief", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::AdaBelief", "to": "v2.src.lmflow.optim.adabelief::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::AdaBelief", "to": "v2.src.lmflow.optim.adabelief::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabelief::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adagrad::AdaGrad", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adagrad::AdaGrad", "to": "v2.src.lmflow.optim.adagrad::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adagrad::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::NovoGrad", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::NovoGrad", "to": "v2.src.lmflow.optim.novograd::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::NovoGrad", "to": "v2.src.lmflow.optim.novograd::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.novograd::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.yogi::Yogi", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.yogi::Yogi", "to": "v2.src.lmflow.optim.yogi::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.yogi::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::RAdam", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::RAdam", "to": "v2.src.lmflow.optim.radam::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::RAdam", "to": "v2.src.lmflow.optim.radam::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.radam::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adam::Adam", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adam::Adam", "to": "v2.src.lmflow.optim.adam::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adam::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamw_schedule_free::AdamWScheduleFree", "to": "v2.src.lmflow.optim.adamw_schedule_free::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adamw_schedule_free::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::SophiaG", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::SophiaG", "to": "v2.src.lmflow.optim.sophia::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::SophiaG", "to": "v2.src.lmflow.optim.sophia::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sophia::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::AdaBound", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::AdaBound", "to": "v2.src.lmflow.optim.adabound::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::AdaBound", "to": "v2.src.lmflow.optim.adabound::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adabound::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::NAdam", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::NAdam", "to": "v2.src.lmflow.optim.nadam::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::NAdam", "to": "v2.src.lmflow.optim.nadam::__setstate__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.nadam::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::Muon", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::Muon", "to": "v2.src.lmflow.optim.muon::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::Muon", "to": "v2.src.lmflow.optim.muon::zeropower_via_newtonschulz5"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.muon::step", "to": "v2.src.lmflow.optim.muon::zeropower_via_newtonschulz5"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::SGDP", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::SGDP", "to": "v2.src.lmflow.optim.sgdp::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::SGDP", "to": "v2.src.lmflow.optim.sgdp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::_projection", "to": "v2.src.lmflow.optim.sgdp::_cosine_similarity"}, {"arrows": "to", "from": "v2.src.lmflow.optim.sgdp::step", "to": "v2.src.lmflow.optim.sgdp::_projection"}, {"arrows": "to", "from": "v2.src.lmflow.optim.dummy::Dummy", "to": "v2.src.lmflow.optim.dummy::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adadelta::Adadelta", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adadelta::Adadelta", "to": "v2.src.lmflow.optim.adadelta::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.optim.adadelta::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::Conversation", "to": "v2.src.lmflow.utils.llava_conversation_lib::get_images"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::get_prompt", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::get_images", "to": "v2.src.lmflow.utils.llava_conversation_lib::expand2square"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::copy", "to": "v2.src.lmflow.utils.llava_conversation_lib::Conversation"}, {"arrows": "to", "from": "v2.src.lmflow.utils.llava_conversation_lib::dict", "to": "v2.src.lmflow.utils.llava_conversation_lib::get_images"}, {"arrows": "to", "from": "v2.src.lmflow.utils.multimodal::update_custom_config", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.utils.multimodal::load_llava_pretrain_model", "to": "v2.src.lmflow.utils.multimodal::adapt_llava_model_to_lmflow_type"}, {"arrows": "to", "from": "v2.src.lmflow.utils.model::check_homogeneity", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.utils.data_utils::get_dataset_type_fast", "to": "v2.src.lmflow.utils.data_utils::preview_file"}, {"arrows": "to", "from": "v2.src.lmflow.utils.data_utils::check_dataset_instances_key_fast", "to": "v2.src.lmflow.utils.data_utils::preview_file"}, {"arrows": "to", "from": "v2.src.lmflow.utils.common::create_copied_dataclass", "to": "v2.src.lmflow.utils.versioning::get_python_version"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::_is_packages_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::_is_packages_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_gradio_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_ray_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_vllm_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_flash_attn_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_flask_available", "to": "v2.src.lmflow.utils.versioning::_is_packages_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_trl_available", "to": "v2.src.lmflow.utils.versioning::_is_package_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.versioning::is_multimodal_available", "to": "v2.src.lmflow.utils.versioning::_is_packages_available"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.gemma::GemmaConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.gemma::encode_conversation"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::EmptyFormatter", "to": "v2.src.lmflow.utils.conversation_template.base::has_placeholder"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::StringFormatter", "to": "v2.src.lmflow.utils.conversation_template.base::has_placeholder"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::StringFormatter", "to": "v2.src.lmflow.utils.conversation_template.base::TemplateComponent"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_starter"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplate", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "to": "v2.src.lmflow.utils.conversation_template.base::_handle_tools"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "to": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::ConversationTemplateForTool", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::format", "to": "v2.src.lmflow.utils.conversation_template.base::TemplateComponent"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::encode_conversation", "to": "v2.src.lmflow.utils.conversation_template.base::_handle_tools"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::encode_conversation", "to": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::_encode_template", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::_encode_template", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "to": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_starter"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::post_process_pairs", "to": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::remove_last_separator", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_starter", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_starter", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.conversation_template.base::add_special_stopper", "to": "v2.src.lmflow.utils.conversation_template.base::_ensure_id_list"}, {"arrows": "to", "from": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::CondenseRotaryEmbedding", "to": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::forward", "to": "v2.src.lmflow.utils.flash_attention.gpt_neo_flash_attention::_attn"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_store_dk_dv"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel_one_col_block"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_bwd_kernel", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::init_to_zero"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnQKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnKVPackedFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::FlashAttnFunc", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::forward", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_forward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::backward", "to": "v2.src.lmflow.utils.flash_attention.triton_flash_attention::_flash_attn_backward"}, {"arrows": "to", "from": "v2.src.lmflow.utils.debug.profiler::Timer", "to": "v2.src.lmflow.utils.debug.profiler::_to_readable"}, {"arrows": "to", "from": "v2.src.lmflow.utils.debug.profiler::show", "to": "v2.src.lmflow.utils.debug.profiler::_to_readable"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::decode"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.multimodal::load_llava_pretrain_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.utils.multimodal::update_custom_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::merge_lora_weights", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::save", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_encoder_decoder_model::save", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::get_backend_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::AutoModel", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::AutoModel", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::AutoModel", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::get_model", "to": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::get_model", "to": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.auto_model::get_model", "to": "v2.src.lmflow.models.hf_encoder_decoder_model::HFEncoderDecoderModel"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::decode"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_decoder_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::HFDecoderModel", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.models.hf_decoder_model::encode"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_fingerprint"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_decoder_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::inference", "to": "v2.src.lmflow.utils.versioning::is_vllm_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__vllm_inference", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.utils.versioning::is_ray_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::__prepare_inputs_for_vllm_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::merge_lora_weights", "to": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::get_peft_without_qlora", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_decoder_model::preprocess_conversation", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::tokenize"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_text_regression_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::HFTextRegressionModel", "to": "v2.src.lmflow.datasets.dataset::sanity_check"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_data_args"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_backend"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::tokenize", "to": "v2.src.lmflow.datasets.dataset::get_fingerprint"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::__vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_text_regression_model::__inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::inference", "to": "v2.src.lmflow.models.hf_model_mixin::deactivate_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.models.hf_text_regression_model::tokenize"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.datasets.dataset::sanity_check"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::prepare_inputs_for_inference", "to": "v2.src.lmflow.utils.versioning::is_ray_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::get_backend_dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::get_type"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::Dataset"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_text_regression_model::postprocess_distributed_inference_outputs", "to": "v2.src.lmflow.datasets.dataset::from_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_dtype"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_quant_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::HFModelMixin", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_dtype"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_quant_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__init__", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_tokenizer", "to": "dream.model.tokenization_dream::get_vocab"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_config", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_peft_config", "to": "v2.src.lmflow.datasets.dataset::to_dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__model_module_inject", "to": "v2.src.lmflow.utils.position_interpolation.llama_rope_scaled_monkey_patch::replace_llama_with_condense"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_training", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_post_process"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::device"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference", "to": "v2.src.lmflow.utils.versioning::is_vllm_available"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_vllm_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.hf_model_mixin::activate_model_for_inference", "to": "v2.src.lmflow.models.hf_model_mixin::__prepare_model_for_inference"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision2seq_model::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision2seq_model::register_prompt_cache"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision2seq_model::generate"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::CustomAutoVision2SeqModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::vision_model_from_pretrained", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::qformer_from_pretrained", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::language_model_from_pretrained", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::save_prompt_cache", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::load_prompt_cache", "to": "v2.src.lmflow.models.vision2seq_model::register_prompt_cache"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::forward", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::forward", "to": "v2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::generate", "to": "v2.src.lmflow.models.vision2seq_model::processor_image_token_in_minigpt4"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision2seq_model::generate", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::build_vision_tower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::CLIPVisionTower", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::load_model", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::forward", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::feature_select"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::forward", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::feature_select"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.models.vision_encoder.clip_encoder::prepare_inputs_labels_for_multimodal", "to": "v2.src.lmflow.models.vision_encoder.clip_encoder::encode_images"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::tokenize_function", "to": "v2.src.lmflow.tokenization.hf_decoder_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::tokenize_function", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_decoder_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_decoder_model::conversation_tokenize_function", "to": "v2.eval::apply_chat_template"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::paired_conversation_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_paired"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::conversation_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::tokenize_function", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "v2.src.lmflow.tokenization.hf_text_regression_model::text_to_textlist_tokenize_function", "to": "v2.src.lmflow.tokenization.hf_text_regression_model::blocking_text_to_textlist"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "llada.eval_llada::__init__"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::LLaDAEvalHarness", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.eval_llada::__init__", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.eval_llada::get_loglikelihood", "to": "llada.eval_llada::_forward_process"}, {"arrows": "to", "from": "llada.eval_llada::get_loglikelihood", "to": "llada.eval_llada::get_logits"}, {"arrows": "to", "from": "llada.eval_llada::suffix_greedy_prediction", "to": "llada.eval_llada::get_logits"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "llada.eval_llada::_encode_pair"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "llada.eval_llada::get_loglikelihood"}, {"arrows": "to", "from": "llada.eval_llada::loglikelihood", "to": "llada.eval_llada::suffix_greedy_prediction"}, {"arrows": "to", "from": "llada.eval_llada::_tokenize", "to": "llada.eval_llada::_encode_pair"}, {"arrows": "to", "from": "llada.generate::add_gumbel_noise", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "llada.generate::generate", "to": "llada.generate::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.generate::generate", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::add_gumbel_noise"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_prefix_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index"}, {"arrows": "to", "from": "llada.generate::generate_with_dual_cache", "to": "llada.generate::get_transfer_index_dynamic"}, {"arrows": "to", "from": "llada.generate::get_transfer_index", "to": "llada.generate::add_gumbel_noise"}, {"arrows": "to", "from": "llada.generate::get_transfer_index_dynamic", "to": "llada.generate::add_gumbel_noise"}, {"arrows": "to", "from": "llada.generate::main", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.generate::main", "to": "llada.generate::generate_with_dual_cache"}, {"arrows": "to", "from": "llada.generate::main", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.chat::chat", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.chat::chat", "to": "llada.generate::generate"}, {"arrows": "to", "from": "llada.chat::chat", "to": "llada.generate::generate_with_dual_cache"}, {"arrows": "to", "from": "llada.chat::chat", "to": "llada.generate::generate_with_prefix_cache"}, {"arrows": "to", "from": "llada.chat::chat", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "llada.app::add_gumbel_noise", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::get_transfer_index"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::add_gumbel_noise"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization_cache_and_parallel", "to": "llada.app::get_transfer_index"}, {"arrows": "to", "from": "llada.app::get_transfer_index", "to": "llada.app::add_gumbel_noise"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization", "to": "llada.app::get_num_transfer_tokens"}, {"arrows": "to", "from": "llada.app::generate_response_with_visualization", "to": "llada.app::add_gumbel_noise"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::create_chatbot_demo", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::add_message", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "llada.app::add_message"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::user_message_submitted", "to": "v2.src.lmflow.utils.llava_conversation_lib::copy"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::format_chat_history"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::parse_constraints"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::generate_response_with_visualization"}, {"arrows": "to", "from": "llada.app::bot_response", "to": "llada.app::generate_response_with_visualization_cache_and_parallel"}, {"arrows": "to", "from": "llada.sanitize::extract_longest_valid_code", "to": "llada.sanitize::syntax_check"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::refine_text"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::extract_longest_valid_code"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::get_deps"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::get_function_dependency"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::has_return_statement"}, {"arrows": "to", "from": "llada.sanitize::sanitize", "to": "llada.sanitize::get_definition_name"}, {"arrows": "to", "from": "llada.model.modeling_llada::_non_meta_init_device", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.model.modeling_llada::_non_meta_init_device", "to": "llada.model.modeling_llada::device"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::LayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::LayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::RMSLayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNormBase", "to": "llada.model.modeling_llada::GemmaRMSLayerNorm"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNorm", "to": "llada.model.modeling_llada::_cast_if_autocast_enabled"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNorm", "to": "llada.model.modeling_llada::_cast_if_autocast_enabled"}, {"arrows": "to", "from": "llada.model.modeling_llada::LayerNorm", "to": "llada.model.modeling_llada::_cast_if_autocast_enabled"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::get_rotary_embedding"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::_non_meta_init_device"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::get_rotary_embedding"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::apply_rotary_pos_emb"}, {"arrows": "to", "from": "llada.model.modeling_llada::RotaryEmbedding", "to": "llada.model.modeling_llada::apply_rotary_pos_emb"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::GELU"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::ReLU"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::SiLU"}, {"arrows": "to", "from": "llada.model.modeling_llada::Activation", "to": "llada.model.modeling_llada::SwiGLU"}, {"arrows": "to", "from": "llada.model.modeling_llada::get_causal_attention_bias", "to": "llada.model.modeling_llada::causal_attention_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::Dropout"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::_scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::RotaryEmbedding"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::activation_checkpoint_function"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::ensure_finite_"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlock", "to": "llada.model.modeling_llada::scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDASequentialBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDASequentialBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDASequentialBlock", "to": "llada.model.modeling_llada::attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDALlamaBlock", "to": "llada.model.modeling_llada::attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockDiffBlock", "to": "llada.model.modeling_llada::attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDABlockGroup", "to": "llada.model.modeling_llada::activation_checkpoint_function"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::BufferCache"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::activation_checkpoint_function"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::LLaDAOutput"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::get_causal_attention_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::get_alibi_attention_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::_non_meta_init_device"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModel", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::create_model_config_from_pretrained_config", "to": "llada.model.configuration_llada::ModelConfig"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModelLM", "to": "llada.model.modeling_llada::create_model_config_from_pretrained_config"}, {"arrows": "to", "from": "llada.model.modeling_llada::LLaDAModelLM", "to": "llada.model.modeling_llada::LLaDAModel"}, {"arrows": "to", "from": "llada.model.modeling_llada::__init__", "to": "llada.model.modeling_llada::create_model_config_from_pretrained_config"}, {"arrows": "to", "from": "llada.model.modeling_llada::__init__", "to": "llada.model.modeling_llada::LLaDAModel"}, {"arrows": "to", "from": "llada.model.modeling_llada::build", "to": "llada.model.modeling_llada::LLaDASequentialBlock"}, {"arrows": "to", "from": "llada.model.modeling_llada::build", "to": "llada.model.modeling_llada::LLaDALlamaBlock"}, {"arrows": "to", "from": "llada.model.modeling_llada::reset_parameters", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::reset_parameters", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::reset_parameters", "to": "llada.model.modeling_llada::init_weights"}, {"arrows": "to", "from": "llada.model.modeling_llada::apply_rotary_pos_emb", "to": "llada.model.modeling_llada::rotate_half"}, {"arrows": "to", "from": "llada.model.modeling_llada::_cast_attn_bias", "to": "llada.model.modeling_llada::ensure_finite_"}, {"arrows": "to", "from": "llada.model.modeling_llada::_scaled_dot_product_attention", "to": "llada.model.modeling_llada::scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::attention", "to": "llada.model.modeling_llada::_scaled_dot_product_attention"}, {"arrows": "to", "from": "llada.model.modeling_llada::attention", "to": "llada.model.modeling_llada::_cast_attn_bias"}, {"arrows": "to", "from": "llada.model.modeling_llada::device", "to": "llada.model.modeling_llada::_non_meta_init_device"}, {"arrows": "to", "from": "llada.model.modeling_llada::get_alibi_attention_bias", "to": "llada.model.modeling_llada::alibi_attention_bias"}, {"arrows": "to", "from": "llada.model.configuration_llada::LLaDAConfig", "to": "llada.model.configuration_llada::ModelConfig"}, {"arrows": "to", "from": "llada.model.configuration_llada::LLaDAConfig", "to": "llada.model.configuration_llada::__init__"}, {"arrows": "to", "from": "llada.model.configuration_llada::__init__", "to": "llada.model.configuration_llada::ModelConfig"}, {"arrows": "to", "from": "dream.demo_multiturn_chat::generation_tokens_hook_func", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.eval::__init__"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.eval::_create_model_and_tokenizer"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::Dream", "to": "dream.eval::apply_chat_template"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::_create_model_and_tokenizer"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::__init__", "to": "dream.eval::device"}, {"arrows": "to", "from": "dream.eval::_create_model_and_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.eval::_create_model_and_tokenizer", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.eval::tok_decode", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::_generate_batch", "to": "dream.eval::apply_chat_template"}, {"arrows": "to", "from": "dream.eval::_generate_batch", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.eval::generate_until", "to": "dream.eval::_generate_batch"}, {"arrows": "to", "from": "dream.eval::_eval_target_nll_mc", "to": "dream.eval::_forward_process"}, {"arrows": "to", "from": "dream.eval::_eval_target_nll_mc", "to": "dream.eval::get_logits"}, {"arrows": "to", "from": "dream.eval::_eval_target_nll_ar", "to": "dream.eval::get_logits"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "v2.src.lmflow.datasets.dataset::map"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "dream.eval::_encode_pair"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "dream.eval::_eval_target_nll_mc"}, {"arrows": "to", "from": "dream.eval::loglikelihood", "to": "dream.eval::_eval_target_nll_ar"}, {"arrows": "to", "from": "dream.eval::_tokenize", "to": "dream.eval::_encode_pair"}, {"arrows": "to", "from": "dream.sanitize::extract_longest_valid_code", "to": "dream.sanitize::syntax_check"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::refine_text"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::extract_longest_valid_code"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::get_deps"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::get_function_dependency"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::has_return_statement"}, {"arrows": "to", "from": "dream.sanitize::sanitize", "to": "dream.sanitize::get_definition_name"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamRotaryEmbedding", "to": "dream.model.modeling_dream::_dynamic_frequency_update"}, {"arrows": "to", "from": "dream.model.modeling_dream::apply_rotary_pos_emb", "to": "dream.model.modeling_dream::rotate_half"}, {"arrows": "to", "from": "dream.model.modeling_dream::apply_rotary_pos_emb", "to": "dream.model.modeling_dream::rotate_half"}, {"arrows": "to", "from": "dream.model.modeling_dream::apply_rotary_pos_emb", "to": "dream.model.modeling_dream::rotate_half"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::DreamRotaryEmbedding"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::apply_rotary_pos_emb"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::repeat_kv"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "llada.model.modeling_llada::scaled_dot_product_attention"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::apply_rotary_pos_emb"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamSdpaAttention", "to": "dream.model.modeling_dream::apply_rotary_pos_emb"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamSdpaAttention"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamMLP"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamRMSNorm"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamDecoderLayer", "to": "dream.model.modeling_dream::DreamRMSNorm"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamPreTrainedModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamPreTrainedModel", "to": "dream.model.modeling_dream::from_pretrained"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::DreamRMSNorm"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::DreamRotaryEmbedding"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::BaseModelOutputWithPast"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamBaseModel", "to": "dream.model.modeling_dream::DreamDecoderLayer"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::DreamBaseModel"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::MaskedLMOutputWithPastKeyValues"}, {"arrows": "to", "from": "dream.model.modeling_dream::DreamModel", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.modeling_dream::__init__", "to": "dream.model.modeling_dream::DreamBaseModel"}, {"arrows": "to", "from": "dream.model.modeling_dream::forward", "to": "dream.model.modeling_dream::MaskedLMOutputWithPastKeyValues"}, {"arrows": "to", "from": "dream.model.modeling_dream::reset_rope_parameters", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.modeling_dream::reset_rope_parameters", "to": "dream.model.modeling_dream::reset_parameters"}, {"arrows": "to", "from": "dream.model.generation_utils::sample_tokens", "to": "dream.model.generation_utils::top_p_logits"}, {"arrows": "to", "from": "dream.model.generation_utils::sample_tokens", "to": "dream.model.generation_utils::top_k_logits"}, {"arrows": "to", "from": "dream.model.generation_utils::sample_tokens", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationConfig", "to": "dream.model.generation_utils::validate"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.model.generation_utils::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils::DreamGenerationMixin", "to": "dream.demo_multiturn_chat::generation_tokens_hook_func"}, {"arrows": "to", "from": "dream.model.generation_utils::__init__", "to": "dream.model.generation_utils::validate"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_generated_length", "to": "dream.model.generation_utils::DreamGenerationConfig"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::_prepare_special_tokens", "to": "dream.model.generation_utils::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils::diffusion_generate", "to": "dream.model.generation_utils::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.demo_multiturn_chat::generation_tokens_hook_func"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.demo_multiturn_chat::generation_tokens_hook_func"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.model.generation_utils::DreamModelOutput"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.model.generation_utils::sample_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils::_sample", "to": "dream.model.generation_utils::sample_tokens"}, {"arrows": "to", "from": "dream.model.tokenization_dream::bytes_to_unicode", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::bytes_to_unicode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::__init__"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::get_pairs"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::DreamTokenizer", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::__init__", "to": "dream.model.tokenization_dream::bytes_to_unicode"}, {"arrows": "to", "from": "dream.model.tokenization_dream::__init__", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::get_vocab", "to": "v2.src.lmflow.utils.llava_conversation_lib::dict"}, {"arrows": "to", "from": "dream.model.tokenization_dream::bpe", "to": "dream.model.tokenization_dream::get_pairs"}, {"arrows": "to", "from": "dream.model.tokenization_dream::bpe", "to": "dream.model.tokenization_dream::get_pairs"}, {"arrows": "to", "from": "dream.model.tokenization_dream::_tokenize", "to": "dream.model.tokenization_dream::bpe"}, {"arrows": "to", "from": "dream.model.tokenization_dream::convert_tokens_to_string", "to": "dream.model.tokenization_dream::decode"}, {"arrows": "to", "from": "dream.model.generation_utils_block::sample_tokens", "to": "dream.model.generation_utils_block::top_p_logits"}, {"arrows": "to", "from": "dream.model.generation_utils_block::sample_tokens", "to": "dream.model.generation_utils_block::top_k_logits"}, {"arrows": "to", "from": "dream.model.generation_utils_block::sample_tokens", "to": "v2.src.lmflow.pipeline.utils.raft_trainer::log"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationConfig", "to": "dream.model.generation_utils_block::validate"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils_block::DreamGenerationMixin", "to": "dream.model.generation_utils_block::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils_block::__init__", "to": "dream.model.generation_utils_block::validate"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_generated_length", "to": "dream.model.generation_utils_block::DreamGenerationConfig"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_prepare_special_tokens", "to": "dream.model.generation_utils_block::_tensor_or_none"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_prepare_generation_config"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_prepare_special_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_prepare_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_validate_generated_length"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_expand_inputs_for_generation"}, {"arrows": "to", "from": "dream.model.generation_utils_block::diffusion_generate", "to": "dream.model.generation_utils_block::_sample"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::sample_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::DreamModelOutput"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::sample_tokens"}, {"arrows": "to", "from": "dream.model.generation_utils_block::_sample", "to": "dream.model.generation_utils_block::sample_tokens"}, {"arrows": "to", "from": "dream.model.configuration_dream::DreamConfig", "to": "dream.model.configuration_dream::__init__"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"physics": {"enabled": false}, "interaction": {"dragNodes": true, "navigationButtons": true, "multiselect": true}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>