# ğŸ“ MATH-500 å•ç‹¬è¯„ä¼°æŒ‡å—

## ğŸ¯ å¿«é€Ÿä½¿ç”¨

### è¯„ä¼°å¾®è°ƒæ¨¡å‹ï¼ˆcheckpoint-6000ï¼‰

```bash
cd /home/sour/LLaMA-Factory
conda activate llama_factory
python eval_math500.py --model-type finetuned
```

### è¯„ä¼°åŸºç¡€æ¨¡å‹ï¼ˆæœªå¾®è°ƒï¼‰

```bash
python eval_math500.py --model-type base
```

### æŒ‡å®šå…¶ä»– checkpoint

```bash
python eval_math500.py --model-type finetuned --checkpoint saves/path/to/checkpoint-XXXX
```

---

## ğŸ“Š å…³äº MATH-500

**MATH-500** æ˜¯ MATH æ•°æ®é›†çš„ç²¾é€‰å­é›†ï¼š
- æ¥æºï¼šHuggingFaceH4/MATH-500
- é¢˜ç›®æ•°é‡ï¼š500 é“é¢˜
- è¦†ç›–ï¼šä»£æ•°ã€å‡ ä½•ã€æ•°è®ºã€é¢„å¾®ç§¯åˆ†ç­‰
- ç”¨é€”ï¼šå¿«é€Ÿè¯„ä¼°æ•°å­¦æ¨ç†èƒ½åŠ›

---

## âš™ï¸ å‘½ä»¤è¡Œå‚æ•°

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--model-type` | `finetuned` | æ¨¡å‹ç±»å‹ï¼š`finetuned` æˆ– `base` |
| `--checkpoint` | `checkpoint-6000` | LoRA checkpoint è·¯å¾„ |
| `--base-model` | `Qwen/Qwen2.5-Coder-0.5B` | åŸºç¡€æ¨¡å‹è·¯å¾„ |

---

## ğŸ“‚ ç»“æœä¿å­˜ä½ç½®

### å¾®è°ƒæ¨¡å‹
```
saves/qwen25_0.5B_coder/eval_results_6000/math500_finetuned_<timestamp>.json
```

### åŸºç¡€æ¨¡å‹
```
saves/qwen25_0.5B_coder/eval_results_base_model/math500_base_<timestamp>.json
```

---

## â±ï¸ é¢„è®¡æ—¶é—´

- **å®Œæ•´ 500 é¢˜è¯„ä¼°**ï¼šçº¦ 10-15 åˆ†é’Ÿï¼ˆRTX 4070ï¼‰
- æ¯”å®Œæ•´ MATH æ•°æ®é›†å¿«å¾ˆå¤šï¼

---

## ğŸ“ˆ å¯¹æ¯” MATH-500 ç»“æœ

è¯„ä¼°å®Œä¸¤ä¸ªæ¨¡å‹åï¼Œå¯ä»¥å¯¹æ¯”ï¼š

```bash
# æŸ¥çœ‹å¾®è°ƒæ¨¡å‹ç»“æœ
cat saves/qwen25_0.5B_coder/eval_results_6000/math500_finetuned_*.json | jq .results

# æŸ¥çœ‹åŸºç¡€æ¨¡å‹ç»“æœ
cat saves/qwen25_0.5B_coder/eval_results_base_model/math500_base_*.json | jq .results
```

---

## ğŸ”§ æŠ€æœ¯è¯´æ˜

### è¯„ä¼°æŒ‡æ ‡

MATH-500 ä½¿ç”¨ä»¥ä¸‹æŒ‡æ ‡ï¼š
- **exact_match**: ç²¾ç¡®åŒ¹é…ç­”æ¡ˆæ ¼å¼ï¼ˆä¸¥æ ¼ï¼‰
- **math_verify**: æ•°å­¦éªŒè¯ï¼ˆæ¨èï¼Œæ›´åˆç†ï¼‰

### Few-shot è®¾ç½®

- é»˜è®¤ä½¿ç”¨ **4-shot**ï¼ˆMATH æ ‡å‡†è®¾ç½®ï¼‰
- å¯ä»¥åœ¨è„šæœ¬ä¸­ä¿®æ”¹ `num_fewshot` å‚æ•°

---

## ğŸ’¡ ä¸ºä»€ä¹ˆå•ç‹¬è¯„ä¼° MATH-500ï¼Ÿ

1. **æ›´å¿«**ï¼š500 é¢˜ vs 5000+ é¢˜
2. **æ ‡å‡†åŒ–**ï¼šHuggingFace å®˜æ–¹ç²¾é€‰å­é›†
3. **å¯å¤ç°**ï¼šç¤¾åŒºå¹¿æ³›ä½¿ç”¨çš„åŸºå‡†
4. **ç‹¬ç«‹è¿è¡Œ**ï¼šä¸éœ€è¦é‡æ–°è¯„ä¼°å…¶ä»–å·²å®Œæˆçš„ä»»åŠ¡

---

## ğŸ¯ ç¤ºä¾‹å®Œæ•´å·¥ä½œæµ

```bash
# 1. æ¿€æ´»ç¯å¢ƒ
cd /home/sour/LLaMA-Factory
conda activate llama_factory

# 2. è¯„ä¼°å¾®è°ƒæ¨¡å‹
python eval_math500.py --model-type finetuned

# 3. è¯„ä¼°åŸºç¡€æ¨¡å‹
python eval_math500.py --model-type base

# 4. æŸ¥çœ‹å’Œå¯¹æ¯”ç»“æœ
ls -lh saves/qwen25_0.5B_coder/eval_results_6000/math500_*.json
ls -lh saves/qwen25_0.5B_coder/eval_results_base_model/math500_*.json
```

---

## ğŸ“ ç»“æœæ–‡ä»¶æ ¼å¼

```json
{
  "model_type": "finetuned" or "base",
  "dataset": "MATH-500",
  "base_model": "Qwen/Qwen2.5-Coder-0.5B",
  "checkpoint": "path/to/checkpoint" (if finetuned),
  "results": {
    "task_name": {
      "exact_match": 0.1234,
      "math_verify": 0.2345,
      ...
    }
  }
}
```

---

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æ•°æ®é›†ä¸‹è½½**ï¼šé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½ MATH-500 æ•°æ®é›†ï¼ˆçº¦ 50MBï¼‰
2. **æ‰¹é‡å¤§å°**ï¼šé»˜è®¤ batch_size=8ï¼Œå¦‚æœå†…å­˜ä¸è¶³å¯ä»¥å‡å°
3. **è¯„ä¼°æ¨¡å¼**ï¼šä½¿ç”¨ 4-shotï¼ˆç¬¦åˆ MATH æ ‡å‡†ï¼‰
4. **ç»“æœä¿å­˜**ï¼šæ¯æ¬¡è¿è¡Œéƒ½ä¼šç”Ÿæˆæ–°çš„ç»“æœæ–‡ä»¶ï¼ˆä¸ä¼šè¦†ç›–ï¼‰

---

**ç¥è¯„ä¼°é¡ºåˆ©ï¼** ğŸ“âœ¨

