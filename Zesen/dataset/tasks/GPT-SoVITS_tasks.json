{
  "tasks": [
    {
      "task_title": "音频切片",
      "task_description": "该任务将原始音频文件或目录中的音频分割成多个子音频片段，支持根据音量阈值、最小长度和最小间隔等参数进行切割。",
      "example_code": null,
      "running_command": "python audio_slicer.py",
      "expected_input": "<path_to_original_audio_file_or_directory>, <directory_where_subdivided_audio_clips_will_be_saved>, <volume_threshold>, <minimum_duration_of_each_subclip>, <shortest_time_gap_between_adjacent_subclips>, <step_size_for_computing_volume_curve>",
      "expected_output": "保存到指定目录的多个子音频片段"
    },
    {
      "task_title": "语音识别（ASR） - FunASR",
      "task_description": "该任务使用 FunASR 进行音频的自动语音识别，将输入音频转换为文本输出。",
      "example_code": null,
      "running_command": "python tools/asr/funasr_asr.py",
      "expected_input": "<input>",
      "expected_output": "<output_text>"
    },
    {
      "task_title": "语音识别（ASR） - FasterWhisper",
      "task_description": "该任务使用 FasterWhisper 进行音频的自动语音识别，支持指定语言和精度。",
      "example_code": null,
      "running_command": "python ./tools/asr/fasterwhisper_asr.py",
      "expected_input": "<input>",
      "expected_output": "<output_text>"
    }
  ],
  "setup": {
    "setup_commands": [],
    "docker_commands": [],
    "docker_files": {
      "Dockerfile": "ARG CUDA_VERSION=12.6\nARG TORCH_BASE=full\n\nFROM xxxxrt666/torch-base:cu${CUDA_VERSION}-${TORCH_BASE}\n\nLABEL maintainer=\"XXXXRT\"\nLABEL version=\"V4\"\nLABEL description=\"Docker image for GPT-SoVITS\"\n\nARG CUDA_VERSION=12.6\n\nENV CUDA_VERSION=${CUDA_VERSION}\n\nSHELL [\"/bin/bash\", \"-c\"]\n\nWORKDIR /workspace/GPT-SoVITS\n\nCOPY Docker /workspace/GPT-SoVITS/Docker/\n\nARG LITE=false\nENV LITE=${LITE}\n\nARG WORKFLOW=false\nENV WORKFLOW=${WORKFLOW}\n\nARG TARGETPLATFORM\nENV TARGETPLATFORM=${TARGETPLATFORM}\n\nRUN bash Docker/miniconda_install.sh\n\nCOPY extra-req.txt /workspace/GPT-SoVITS/\n\nCOPY requirements.txt /workspace/GPT-SoVITS/\n\nCOPY install.sh /workspace/GPT-SoVITS/\n\nRUN bash Docker/install_wrapper.sh\n\nEXPOSE 9871 9872 9873 9874 9880\n\nENV PYTHONPATH=\"/workspace/GPT-SoVITS\"\n\nRUN conda init bash && echo \"conda activate base\" >> ~/.bashrc\n\nWORKDIR /workspace\n\nRUN rm -rf /workspace/GPT-SoVITS\n\nWORKDIR /workspace/GPT-SoVITS\n\nCOPY . /workspace/GPT-SoVITS\n\nCMD [\"/bin/bash\", \"-c\", \"\\\n  rm -rf /workspace/GPT-SoVITS/GPT_SoVITS/pretrained_models && \\\n  rm -rf /workspace/GPT-SoVITS/GPT_SoVITS/text/G2PWModel && \\\n  rm -rf /workspace/GPT-SoVITS/tools/asr/models && \\\n  rm -rf /workspace/GPT-SoVITS/tools/uvr5/uvr5_weights && \\\n  ln -s /workspace/models/pretrained_models /workspace/GPT-SoVITS/GPT_SoVITS/pretrained_models && \\\n  ln -s /workspace/models/G2PWModel /workspace/GPT-SoVITS/GPT_SoVITS/text/G2PWModel && \\\n  ln -s /workspace/models/asr_models /workspace/GPT-SoVITS/tools/asr/models && \\\n  ln -s /workspace/models/uvr5_weights /workspace/GPT-SoVITS/tools/uvr5/uvr5_weights && \\\n  exec bash\"]",
      "docker-compose.yaml": "version: \"3.8\"\n\nservices:\n  GPT-SoVITS-CU126:\n    image: xxxxrt666/gpt-sovits:latest-cu126\n    container_name: GPT-SoVITS-CU126\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia\n  GPT-SoVITS-CU126-Lite:\n    image: xxxxrt666/gpt-sovits:latest-cu126-lite\n    container_name: GPT-SoVITS-CU126-Lite\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n      - tools/asr/models:/workspace/models/asr_models\n      - tools/uvr5/uvr5_weights:/workspace/models/uvr5_weights\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia\n  GPT-SoVITS-CU128:\n    image: xxxxrt666/gpt-sovits:latest-cu128\n    container_name: GPT-SoVITS-CU128\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia\n  GPT-SoVITS-CU128-Lite:\n    image: xxxxrt666/gpt-sovits:latest-cu128-lite\n    container_name: GPT-SoVITS-CU128-Lite\n    ports:\n      - \"9871:9871\"\n      - \"9872:9872\"\n      - \"9873:9873\"\n      - \"9874:9874\"\n      - \"9880:9880\"\n    volumes:\n      - .:/workspace/GPT-SoVITS\n      - tools/asr/models:/workspace/models/asr_models\n      - tools/uvr5/uvr5_weights:/workspace/models/uvr5_weights\n    environment:\n      - is_half=true\n    tty: true\n    stdin_open: true\n    shm_size: \"16g\"\n    restart: unless-stopped\n    runtime: nvidia",
      ".dockerignore": "GPT_SoVITS/pretrained_models/*\ntools/asr/models/*\ntools/uvr5/uvr5_weights/*\n\n.git\n.DS_Store\n.vscode\n*.pyc\nenv\nruntime\n.idea\noutput\nlogs\nSoVITS_weights*/\nGPT_weights*/\nTEMP\nweight.json\nffmpeg*\nffprobe*\ncfg.json\nspeakers.json\nref_audios\n\n# Byte-compiled / optimized / DLL files\n__pycache__/\n**/__pycache__/\n*.py[cod]\n*$py.class\n\n# C extensions\n*.so\n\n# Distribution / packaging\n.Python\nbuild/\ndevelop-eggs/\ndist/\ndownloads/\neggs/\n.eggs/\nlib/\nlib64/\nparts/\nsdist/\nvar/\nwheels/\nshare/python-wheels/\n*.egg-info/\n.installed.cfg\n*.egg\nMANIFEST\n\n# PyInstaller\n#  Usually these files are written by a python script from a template\n#  before PyInstaller builds the exe, so as to inject date/other infos into it.\n*.manifest\n*.spec\n\n# Installer logs\npip-log.txt\npip-delete-this-directory.txt\n\n# Unit test / coverage reports\nhtmlcov/\n.tox/\n.nox/\n.coverage\n.coverage.*\n.cache\nnosetests.xml\ncoverage.xml\n*.cover\n*.py,cover\n.hypothesis/\n.pytest_cache/\ncover/\n\n# Translations\n*.mo\n*.pot\n\n# Django stuff:\n*.log\nlocal_settings.py\ndb.sqlite3\ndb.sqlite3-journal\n\n# Flask stuff:\ninstance/\n.webassets-cache\n\n# Scrapy stuff:\n.scrapy\n\n# Sphinx documentation\ndocs/_build/\n\n# PyBuilder\n.pybuilder/\ntarget/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n\n# IPython\nprofile_default/\nipython_config.py\n\n# pyenv\n#   For a library or package, you might want to ignore these files since the code is\n#   intended to run in multiple environments; otherwise, check them in:\n.python-version\n\n# pipenv\n#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.\n#   However, in case of collaboration, if having platform-specific dependencies or dependencies\n#   having no cross-platform support, pipenv may install dependencies that don't work, or not\n#   install all needed dependencies.\nPipfile.lock\n\n# UV\n#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\nuv.lock\n\n# poetry\n#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.\n#   This is especially recommended for binary packages to ensure reproducibility, and is more\n#   commonly ignored for libraries.\n#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control\npoetry.lock\n\n# pdm\n#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.\n#pdm.lock\n#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it\n#   in version control.\n#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control\n.pdm.toml\n.pdm-python\n.pdm-build/\n\n# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm\n__pypackages__/\n\n# Celery stuff\ncelerybeat-schedule\ncelerybeat.pid\n\n# SageMath parsed files\n*.sage.py\n\n# Environments\n.env\n.venv\nenv/\nvenv/\nENV/\nenv.bak/\nvenv.bak/\n\n# Spyder project settings\n.spyderproject\n.spyproject\n\n# Rope project settings\n.ropeproject\n\n# mkdocs documentation\n/site\n\n# mypy\n.mypy_cache/\n.dmypy.json\ndmypy.json\n\n# Pyre type checker\n.pyre/\n\n# pytype static type analyzer\n.pytype/\n\n# Cython debug symbols\ncython_debug/\n\n# PyCharm\n#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can\n#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore\n#  and can be added to the global gitignore or merged into this file.  For a more nuclear\n#  option (not recommended) you can uncomment the following to ignore the entire idea folder.\n.idea/\n\n# Ruff stuff:\n.ruff_cache/\n\n# PyPI configuration file\n.pypirc\n"
    },
    "docker_setup_descriptions": {
      "Dockerfile": "### Building and Running Docker for GPT-SoVITS\n\nTo build and run the Docker container for the GPT-SoVITS project from the repository `RVC-Boss/GPT-SoVITS`, follow these steps:\n\n1. **Clone the Repository**:\n   ```bash\n   git clone https://github.com/RVC-Boss/GPT-SoVITS.git\n   cd GPT-SoVITS\n   ```\n\n2. **Build the Docker Image**:\n   Use the following command to build the Docker image. This command will utilize the `Dockerfile` in the repository.\n   ```bash\n   docker build -t gpt-sovits .\n   ```\n\n3. **Run the Docker Container**:\n   Start a container from the built image. Adjust the ports as necessary for your application.\n   ```bash\n   docker run -it -p 9871:9871 -p 9872:9872 -p 9873:9873 -p 9874:9874 -p 9880:9880 gpt-sovits\n   ```\n\n### Semantic Meaning of the Dockerfile\n\n- **Base Image**: The Dockerfile starts with a base image `xxxxrt666/torch-base:cu${CUDA_VERSION}-${TORCH_BASE}`, which is a pre-configured environment for PyTorch with CUDA support, specified by the `CUDA_VERSION` and `TORCH_BASE` arguments.\n\n- **Environment Variables**: It sets up several environment variables, including `CUDA_VERSION`, `LITE`, `WORKFLOW`, and `TARGETPLATFORM`, which can be used to customize the build and runtime behavior of the container.\n\n- **Working Directory**: The `WORKDIR` directive sets the working directory to `/workspace/GPT-SoVITS`, where all subsequent commands will be executed.\n\n- **Dependency Installation**: The `RUN` commands execute scripts to install Miniconda and additional Python dependencies specified in `requirements.txt` and `extra-req.txt`.\n\n- **Exposed Ports**: The `EXPOSE` directive indicates that the container will listen on ports 9871 to 9880, which are likely used for the application’s services.\n\n- **Python Path**: The `PYTHONPATH` environment variable is set to ensure that Python can find the necessary modules within the workspace.\n\n- **Cleanup and Symlinks**: The `CMD` instruction includes a series of commands to clean up unnecessary files and create symbolic links to model directories, ensuring that the application can access the required resources at runtime.\n\nThis Dockerfile effectively sets up a reproducible environment for running the GPT-SoVITS project, ensuring all dependencies and configurations are in place.",
      "docker-compose.yaml": "### Building and Running Docker with `docker-compose.yaml` for RVC-Boss/GPT-SoVITS\n\nTo build and run the Docker containers defined in the `docker-compose.yaml` file from the RVC-Boss/GPT-SoVITS repository, follow these steps:\n\n#### Step 1: Install Docker and Docker Compose\nEnsure you have Docker and Docker Compose installed on your machine. You can download them from the official [Docker website](https://www.docker.com/get-started).\n\n#### Step 2: Clone the Repository\nClone the RVC-Boss/GPT-SoVITS repository to your local machine:\n```bash\ngit clone https://github.com/RVC-Boss/GPT-SoVITS.git\ncd GPT-SoVITS\n```\n\n#### Step 3: Review the `docker-compose.yaml` File\nThe `docker-compose.yaml` file defines multiple services for running different versions of the GPT-SoVITS application. Each service is configured with the following key attributes:\n\n- **version**: Specifies the version of the Docker Compose file format (3.8 in this case).\n- **services**: Contains definitions for multiple containers:\n  - **Container Names**: Each service has a unique name (e.g., `GPT-SoVITS-CU126`, `GPT-SoVITS-CU128`).\n  - **Image**: Specifies the Docker image to use for each service, indicating different versions (e.g., `latest-cu126`, `latest-cu128`).\n  - **Ports**: Maps container ports (9871-9880) to the host, allowing access to the application.\n  - **Volumes**: Mounts the current directory and specific model directories to the container for persistent storage and access to necessary files.\n  - **Environment Variables**: Sets `is_half=true`, which may configure the model to use half-precision for performance.\n  - **tty and stdin_open**: Allows interaction with the container's terminal.\n  - **shm_size**: Allocates 16GB of shared memory, which is useful for applications requiring large memory space.\n  - **restart**: Configured to restart the container unless it is explicitly stopped.\n  - **runtime**: Specifies the use of the NVIDIA runtime for GPU support.\n\n#### Step 4: Build and Run the Containers\nExecute the following command in the terminal to build and run the services defined in the `docker-compose.yaml` file:\n```bash\ndocker-compose up -d\n```\nThis command will start all defined services in detached mode.\n\n#### Step 5: Access the Application\nOnce the containers are running, you can access the application through the mapped ports (e.g., `http://localhost:9871`, `http://localhost:9872`, etc.).\n\n#### Step 6: Stopping the Containers\nTo stop the running containers, use:\n```bash\ndocker-compose down\n```\n\n### Additional Notes\n- Ensure your Docker installation supports NVIDIA GPUs if you plan to use the `runtime: nvidia` option.\n- Check the README file in the repository for any additional commands or configurations specific to your use case.\n\nBy following these steps, you will successfully build and run the GPT-SoVITS application using Docker.",
      ".dockerignore": "### Building and Running Docker with .dockerignore for RVC-Boss/GPT-SoVITS\n\n#### Overview of `.dockerignore`\nThe `.dockerignore` file is used to specify files and directories that should be excluded from the Docker build context. This helps reduce the size of the build context sent to the Docker daemon, improving build performance and security by preventing sensitive or unnecessary files from being included in the Docker image.\n\n#### Semantic Meaning of the Provided `.dockerignore`\n1. **Model Weights and Output**: \n   - `GPT_SoVITS/pretrained_models/*`, `tools/asr/models/*`, `tools/uvr5/uvr5_weights/*`: Excludes pre-trained models and weights that are not needed for building the image.\n   \n2. **Development Artifacts**:\n   - `.git`, `.DS_Store`, `.vscode`, `*.pyc`, `env`, `runtime`, `output`, `logs`, etc.: Excludes version control files, IDE configurations, and temporary files that are not relevant to the application runtime.\n\n3. **Python Specific Files**:\n   - `__pycache__/`, `*.py[cod]`, `*.so`: Excludes compiled Python files and C extensions which are not necessary for the Docker image.\n\n4. **Build Artifacts**:\n   - Directories like `build/`, `dist/`, and files like `*.egg-info/`: Excludes packaging and distribution artifacts.\n\n5. **Testing and Coverage Reports**:\n   - Excludes directories and files related to testing, such as `.tox/`, `.coverage`, and `nosetests.xml`.\n\n6. **Environment and Configuration Files**:\n   - Excludes environment files (`.env`, `venv/`) and configuration files that may contain sensitive information.\n\n7. **Documentation and Caches**:\n   - Excludes documentation build directories and cache files from various tools (e.g., `docs/_build/`, `.mypy_cache/`).\n\n#### Steps to Build and Run Docker\n\n1. **Build the Docker Image**:\n   Navigate to the root directory of the repository where the `Dockerfile` is located and run the following command:\n   ```bash\n   docker build -t gpt-sovits .\n   ```\n\n2. **Run the Docker Container**:\n   After the image is built, run the container using:\n   ```bash\n   docker run -d --name gpt-sovits-container gpt-sovits\n   ```\n\n3. **Verify the Container is Running**:\n   Check the status of the running container:\n   ```bash\n   docker ps\n   ```\n\n4. **Access Logs (if needed)**:\n   To view logs from the container, use:\n   ```bash\n   docker logs gpt-sovits-container\n   ```\n\n5. **Stop and Remove the Container**:\n   When done, stop and remove the container with:\n   ```bash\n   docker stop gpt-sovits-container\n   docker rm gpt-sovits-container\n   ```\n\nBy following these steps and utilizing the `.dockerignore` effectively, you can ensure a clean, efficient Docker build process for the RVC-Boss/GPT-SoVITS project."
    }
  },
  "input_to_gpt": {
    "repo_name": "RVC-Boss/GPT-SoVITS",
    "num_code_blocks": 3,
    "total_length": 533,
    "code_blocks": [
      "python audio_slicer.py \\\n    --input_path \"<path_to_original_audio_file_or_directory>\" \\\n    --output_root \"<directory_where_subdivided_audio_clips_will_be_saved>\" \\\n    --threshold <volume_threshold> \\\n    --min_length <minimum_duration_of_each_subclip> \\\n    --min_interval <shortest_time_gap_between_adjacent_subclips>\n    --hop_size <step_size_for_computing_volume_curve>",
      "python tools/asr/funasr_asr.py -i <input> -o <output>",
      "python ./tools/asr/fasterwhisper_asr.py -i <input> -o <output> -l <language> -p <precision>"
    ]
  }
}